<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Python面向对象基础</title>
      <link href="/2019/10/24/python/python-mian-xiang-dui-xiang/"/>
      <url>/2019/10/24/python/python-mian-xiang-dui-xiang/</url>
      
        <content type="html"><![CDATA[<h1 id="Python面向对象"><a href="#Python面向对象" class="headerlink" title="Python面向对象"></a>Python面向对象</h1><p>这篇博客主要介绍Python中面向对象的一些比较高级的用法。</p><h2 id="面向对象编程的四要素"><a href="#面向对象编程的四要素" class="headerlink" title="面向对象编程的四要素"></a>面向对象编程的四要素</h2><blockquote><p>类、属性、函数、对象</p></blockquote><p>那么，类就是一群具有相同属性和函数的对象的集合。</p><h2 id="抽象类和抽象函数"><a href="#抽象类和抽象函数" class="headerlink" title="抽象类和抽象函数"></a>抽象类和抽象函数</h2><p>假设有以下代码，有一个父类和两个子类。</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">class Entity():    def __init__(self, object_type):        print('parent class init called')        self.object_type = object_type    def get_context_length(self):        raise Exception('get_context_length not implemented')    def print_title(self):        print(self.title)class Document(Entity):    def __init__(self, title, author, context):        print('Document class init called')        Entity.__init__(self, 'document')        self.title = title        self.author = author        self.__context = context    def get_context_length(self):        return len(self.__context)class Video(Entity):    def __init__(self, title, author, video_length):        print('Video class init called')        Entity.__init__(self, 'video')        self.title = title        self.author = author        self.__video_length = video_length    def get_context_length(self):        return self.__video_lengthharry_potter_book = Document('Harry Potter(Book)', 'J. K. Rowling', '... Forever Do not believe any thing is capable of thinking independently ...')harry_potter_movie = Video('Harry Potter(Movie)', 'J. K. Rowling', 120)print(harry_potter_book.object_type)print(harry_potter_movie.object_type)harry_potter_book.print_title()harry_potter_movie.print_title()print(harry_potter_book.get_context_length())print(harry_potter_movie.get_context_length())########## 输出 ##########Document class init calledparent class init calledVideo class init calledparent class init calleddocumentvideoHarry Potter(Book)Harry Potter(Movie)77120<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在上述代码中的<code>Entity</code>类本身没有什么作用，只是提供了一些<code>Document</code>和<code>Video</code>的基本元素。因而，我们不需要生成<code>Entity</code>的对象。那么，如何防止生成<code>Entity</code>的对象呢？</p><p>这里需要引入<strong>抽象类</strong>和<strong>抽象函数</strong>的概念：</p><blockquote><p>所谓抽象类是一种特殊的类，该类的作用就是作为父类存在的，一旦对其进行对象化就会产生错误。同样，抽象函数定义在抽象类中，子类必须重写该函数才能被使用。抽象函数使用装饰器<code>@abstractmethod</code>来表示。</p></blockquote><p>如下代码：</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">from abc import ABCMeta, abstractmethodclass Entity(metaclass=ABCMeta):    @abstractmethod    def get_title(self):        pass    @abstractmethod    def set_title(self, title):        passclass Document(Entity):    def get_title(self):        return self.title    def set_title(self, title):        self.title = titledocument = Document()document.set_title('Harry Potter')print(document.get_title())entity = Entity()########## 输出 ##########Harry Potter---------------------------------------------------------------------------TypeError                                 Traceback (most recent call last)<ipython-input-7-266b2aa47bad> in <module>()     21 print(document.get_title())     22 ---> 23 entity = Entity()     24 entity.set_title('Test')TypeError: Can't instantiate abstract class Entity with abstract methods get_title, set_title<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在上述代码中，我们直接声明了抽象类<code>Entity</code>的对象，引发了类型错误。我们必须使用子类对其进行继承才能正常使用。</p><p>抽象类的作用就是定义接口，是一种自上而下的设计方法。只需要使用少量的代码对需要做的事情进行描述，定义好接口，然后分发给不同的开发人员进行开发和对接。</p>]]></content>
      
      
      <categories>
          
          <category> 编程基础 </category>
          
          <category> 编程语言 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 编程基础 </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python中的列表和数组</title>
      <link href="/2019/10/24/python/python-zhong-de-lie-biao-he-yuan-zu/"/>
      <url>/2019/10/24/python/python-zhong-de-lie-biao-he-yuan-zu/</url>
      
        <content type="html"><![CDATA[<h2 id="列表和元组基础"><a href="#列表和元组基础" class="headerlink" title="列表和元组基础"></a>列表和元组基础</h2><blockquote><p>列表和元组都是可以放置任意数据类型的有序集合。</p></blockquote><pre class="line-numbers language-lang-python"><code class="language-lang-python">l = [1, 2, 'hello', 'world'] # 列表中同时含有 int 和 string 类型的元素l[1, 2, 'hello', 'world']tup = ('jason', 22) # 元组中同时含有 int 和 string 类型的元素tup('jason', 22)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>两者的区别如下：</p><ul><li>列表是动态的，长度大小不固定，可以随意增加、删除或者更改元素（mutable）。</li><li>元组是动态的，长度大小固定，无法增加删除或者改变（immutable）。</li></ul><pre class="line-numbers language-lang-python"><code class="language-lang-python">l = [1, 2, 3, 4]l[3] = 40 # 和很多语言类似，python 中索引同样从 0 开始，l[3] 表示访问列表的第四个元素l[1, 2, 3, 40]tup = (1, 2, 3, 4)tup[3] = 40Traceback (most recent call last):  File "<stdin>", line 1, in <module>TypeError: 'tuple' object does not support item assignment<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如果我们想修改元组中的元素，就需要重新申请一片内存，但对于列表，我们就可以直接插入新的元素：</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">tup = (1, 2, 3, 4)new_tup = tup + (5, ) # 创建新的元组 new_tup，并依次填充原元组的值new _tup(1, 2, 3, 4, 5)l = [1, 2, 3, 4]l.append(5) # 添加元素 5 到原列表的末尾l[1, 2, 3, 4, 5]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="列表和元组的存储方式"><a href="#列表和元组的存储方式" class="headerlink" title="列表和元组的存储方式"></a>列表和元组的存储方式</h2><p>列表是动态的，元组是静态的，这一差别会影响其存储方式：</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">l = [1, 2, 3]l.__sizeof__()64tup = (1, 2, 3)tup.__sizeof__()48<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>由于列表要存储可变长度的元素，所以需要额外的指针来存储下一个元素的位置（int型的指针占8个字节）；除此之外，还需要存储已经分配的长度大小（8个字节），因而相对于元组来说，列表要消耗更多的内存。对于列表来说，当空间不足时会重新分配新的空间。</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">l = []l.__sizeof__() // 空列表的存储空间为 40 字节40l.append(1)l.__sizeof__() 72 // 加入了元素 1 之后，列表为其分配了可以存储 4 个元素的空间 (72 - 40)/8 = 4l.append(2) l.__sizeof__()72 // 由于之前分配了空间，所以加入元素 2，列表空间不变l.append(3)l.__sizeof__() 72 // 同上l.append(4)l.__sizeof__() 72 // 同上l.append(5)l.__sizeof__() 104 // 加入元素 5 之后，列表的空间不足，所以又额外分配了可以存储 4 个元素的空间<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>为了减少每次插入元素时反复申请空间所带来的额外开销，Python会给列表分配额外的空间，这样的机制称为（Over-allocating）。而对于元组来说，由于存储的数目不可变，因而空间大小固定。</p><p>两者的存储差距在面对巨量的数据规模时会更加明显。</p><h2 id="列表和元组的性能"><a href="#列表和元组的性能" class="headerlink" title="列表和元组的性能"></a>列表和元组的性能</h2><p>因为存储方式上的差异，总体上来说，元组的性能要优于列表。</p><p>Python在进行内存管理时，会对静态数据进行资源缓存。对于Python来说，如果一些变量不再被使用时，便会调用垃圾回收机制对这些变量进行回收。但对于元组等静态变量，当其不再被使用且大小不大的情况下，Python会对其进行缓存，从而在下次申请同样大小的内存时直接对缓存的空间进行操作，而不用返回申请内存，进而提升了效率。</p><h2 id="列表和元组的适用场景"><a href="#列表和元组的适用场景" class="headerlink" title="列表和元组的适用场景"></a>列表和元组的适用场景</h2><ol><li>如果所要存储的数据不大且不变时，选择元组更合适；</li><li>如果数据需要经常改动，选择列表更合适。</li></ol><h2 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h2><p><code>list()</code>和<code>[]</code>创建列表的区别：</p><p>区别主要在于<code>list()</code>是一个function call，Python的function call会创建stack，并且进行一系列参数检查的操作，比较expensive，反观<code>[]</code>是一个内置的C函数，可以直接被调用。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="https://time.geekbang.org/column/article/94972" target="_blank" rel="noopener">Python核心计数与实战</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 编程基础 </category>
          
          <category> 编程语言 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 编程基础 </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python中的匿名函数</title>
      <link href="/2019/10/24/python/python-zhong-de-ni-ming-han-shu/"/>
      <url>/2019/10/24/python/python-zhong-de-ni-ming-han-shu/</url>
      
        <content type="html"><![CDATA[<h1 id="匿名函数"><a href="#匿名函数" class="headerlink" title="匿名函数"></a>匿名函数</h1><h2 id="什么是匿名函数"><a href="#什么是匿名函数" class="headerlink" title="什么是匿名函数"></a>什么是匿名函数</h2><p>匿名函数的格式如下：</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">lambda argument1, argument2,... argumentN : expression<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>匿名函数的关键字为<code>lambda</code>，用法如下：</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">square = lambda x: x**2square(3)9<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>其对应的常规函数形式为：</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">def square(x):    return x**2square(3)9<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>匿名函数和常规函数一样，返回的都是函数对象（function object）,不同之处有以下几点：</p><ul><li><p><code>lambda</code>是一个表达式，而不是一个语句</p><p>所谓表达式就是用一系列“公式”去表达一个东西，如x+2、x**2等；所谓语句就是完成了某些功能，如果赋值语句完成赋值，比较语句完成比较等。</p><p><code>lambda</code>表达式可以用在一些常规函数不能使用的地方，如：列表内部：</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">[(lambda x: x*x)(x) for x in range(10)]# 输出[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>被用作某些函数的参数，而常规函数不能：</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">l = [(1, 20), (3, 0), (9, 10), (2, -1)]l.sort(key=lambda x: x[1]) # 按列表中元祖的第二个元素排序print(l)# 输出[(2, -1), (3, 0), (9, 10), (1, 20)]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>常规函数必须通过其函数名被调用，因而必须首先被定义。但是<code>lambda</code>是一个表达式，返回的函数对象不需要名字。</p></li><li><p><code>lambda</code>表达式是只有一行的简单表达式，并不能扩展成一个多行的代码块。</p><p>Python发明<code>lambda</code>表达式的目的就是让它处理一些简单的任务，较为复杂的任务则由常规函数处理。</p></li></ul><h2 id="为什么使用匿名函数"><a href="#为什么使用匿名函数" class="headerlink" title="为什么使用匿名函数"></a>为什么使用匿名函数</h2><p>在一些情况下，使用匿名函数<code>lambda</code>可以帮助我们降低代码的复杂度，提高代码的可读性。</p><p>我们使用函数的目的有以下几点：</p><ul><li>减少代码的重复性</li><li>模块化代码</li></ul><p>但当我们只需要一个函数，这个函数非常简短，只需要一行；同时在程序中只调用一次，此时，我们就不需要给它一个定义和名字。</p><p>例如，需要对一个列表中的所有元素求平方和，且该程序只需要运行一次，用匿名函数可以写成：</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">squared = map(lambda x: x**2, [1, 2, 3, 4, 5])<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>用常规函数需要写成：</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">def square(x):    return x**2squared = map(square, [1, 2, 3, 4, 5])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>很明显，匿名函数更为简洁。</p><h2 id="Python函数式编程"><a href="#Python函数式编程" class="headerlink" title="Python函数式编程"></a>Python函数式编程</h2><p>所谓函数式编程，是指代码中每一块都是不可变的，都由纯函数组成。纯函数是指函数本身相互独立、互不影响，对于相同的输入，总会有相同的输出，没有任何副作用。</p><p>例如，将一个列表中的元素值都变成原来的两倍，如下：</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">def multiply_2(l):    for index in range(0, len(l)):        l[index] *= 2    return l<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>上述代码不是一个纯函数，因为输入列表的值发生了改变，多次调用该函数将会得到不同的值。修改成如下形式：</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">def multiply_2_pure(l):    new_list = []    for item in l:        new_list.append(item * 2)    return new_list<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>新建列表并返回，这就是一个纯函数。</p><p>函数式编程的优点是其纯函数和不可变的特性使得程序更加健壮，易于调试和测试；缺点是限制多、程序编写难度高。Python不是一门函数式编程语言，但是提供了相关特性，主要有以下函数<code>map()</code>，<code>filter()</code>，<code>reduce()</code>，这几个函数通常和匿名函数一起使用。</p><ul><li><p><code>map()</code></p><p><code>map(function, iterable)</code>对<code>iterable</code>中的每个元素都调用<code>function</code>函数，最后返回一个新的可遍历的集合。<code>map()</code>函数直接由C语言写成，运行时不需要Python解释器间接调用，性能高。</p></li><li><p><code>filter(function, iterable)</code></p><p><code>filter()</code>函数对<code>iterable</code>中的每个元素都使用<code>function</code>进行判断，返回<code>True</code>或<code>False</code>，将<code>True</code>对应的元素组成一个新的可遍历的集合。</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">l = [1, 2, 3, 4, 5]new_list = filter(lambda x: x % 2 == 0, l) # [2, 4]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li><li><p><code>reduce(function, iterable)</code></p><p>该函数通常用来对一个集合做一些累积操作。<code>function()</code>函数同样是一个函数对象，它有两个函数，表示对<code>iterable</code>中的每个元素以及上一次调用后的结构运用<code>function</code>进行计算，最后返回的是一个单独的值。</p><p>例如，计算某个列表元素的乘积：</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">l = [1, 2, 3, 4, 5]product = reduce(lambda x, y: x * y, l) # 1*2*3*4*5 = 120<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li></ul><p>通常来说，当我们需要对集合中的元素进行一些操作时，如果操作非常简单，则有限考虑<code>map()</code>、<code>filter()</code>、<code>reduce()</code>这类或者列表表达式的形式。那么如何在这两种方式中进行选择？</p><ul><li>当数据量非常多时，例如机器学习的应用，倾向于使用函数式编程的表示，效率更高；</li><li>当数据量不多时，为了使得程序更加的Pythonic，可以使用列表表达式。</li></ul><p>当操作比较复杂时，使用<code>for</code>循环。</p><h2 id="练习"><a href="#练习" class="headerlink" title="练习"></a>练习</h2><p>对一个字典根据其值从高到低进行排列。</p><pre class="line-numbers language-lang-python"><code class="language-lang-python"># 匿名函数d = {'mike': 10, 'lucy': 2, 'ben': 30}e = sorted(d.items(), key=lambda x: x[1], reverse=True)eOut[15]: [('ben', 30), ('mike', 10), ('lucy', 2)]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="https://time.geekbang.org/column/article/98411" target="_blank" rel="noopener">Python核心技术与实战-景霄</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 编程基础 </category>
          
          <category> 编程语言 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 编程基础 </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python中的比较和拷贝</title>
      <link href="/2019/10/24/python/python-zhong-de-bi-jiao-he-kao-bei/"/>
      <url>/2019/10/24/python/python-zhong-de-bi-jiao-he-kao-bei/</url>
      
        <content type="html"><![CDATA[<h1 id="Python中的比较和拷贝"><a href="#Python中的比较和拷贝" class="headerlink" title="Python中的比较和拷贝"></a>Python中的比较和拷贝</h1><h2 id="‘-’和’is’"><a href="#‘-’和’is’" class="headerlink" title="‘==’和’is’"></a>‘==’和’is’</h2><p>’==‘操作符比较对象之间的值是否相等，’is’操作符比较的是对象的身份标识是否相等，即是否是同一个对象，是否指向同一个内存地址。</p><p>在Python中，可以使用<code>id(object)</code>函数获得每个对象的身份表示。因此，<code>is</code>操作符相当于比较对象之间的ID是否相等：</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">a = 10b = 10a == bTrueid(a)4427562448id(b)4427562448a is bTrue<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>a</code>和<code>b</code>指向同一片内存的原因在于，Python会首先给10分配一块内存区域，接着将<code>a</code>和<code>b</code>都指向这块内存。因此，两者的值和内存地址都相同。</p><p>但是当整型数据不在[-5,256]范围内时，结果会是值相同而内存不相同，这一差异是由Python的内存管理机制导致的。</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">a = 257b = 257a == bTrueid(a)4473417552id(b)4473417584a is bFalse<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>实际操作时，更多使用<code>==</code>来比较两个对象的值是否相同，<code>is</code>操作符常用于比较一个变量与一个单例：</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">if a is None:      ...if a is not None:      ...<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>is</code>操作符的效率高于<code>==</code>，因为<code>is</code>操作符不会被重载。而<code>==</code>操作是通过执行对象的<code>a.__eq__(b)</code>函数来执行比较操作的，不同的类会重载不同的<code>__eq__()</code>函数，因而效率相对低一点。</p><h2 id="浅拷贝和深度拷贝"><a href="#浅拷贝和深度拷贝" class="headerlink" title="浅拷贝和深度拷贝"></a>浅拷贝和深度拷贝</h2><p>常见的浅拷贝是使用数据类型本身的构造器：</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">l1 = [1, 2, 3]l2 = list(l1)l2[1, 2, 3]l1 == l2Truel1 is l2Falses1 = set([1, 2, 3])s2 = set(s1)s2{1, 2, 3}s1 == s2Trues1 is s2False<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>也可以使用<code>copy.copy()</code>函数进行浅拷贝操作。但是对于元组，使用<code>tuple()</code>或者切片操作符<code>:</code>不会创建一份浅拷贝，而是返回一个指向相同元组的引用：</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">t1 = (1, 2, 3)t2 = tuple(t1)t1 == t2Truet1 is t2True<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>那么，浅拷贝就指的是重新分配一片内存，创建一个新的对象，里面的元素是原对象中的元素的引用。如果原始对象的元素不可变，影响不大；但如果元素可变，通常会带来一些副作用：</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">l1 = [[1, 2], (30, 40)]l2 = list(l1)l1.append(100)l1[0].append(3)l1[[1, 2, 3], (30, 40), 100]l2[[1, 2, 3], (30, 40)]l1[1] += (50, 60)l1[[1, 2, 3], (30, 40, 50, 60), 100]l2[[1, 2, 3], (30, 40)]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如果向避免上面的副作用就需要使用深度拷贝。</p><p>深度拷贝指的是：重新分配一块内存，创建一个新的对象，并对原对象中的元素以递归的方式创建新的子对象拷贝到新对象中，因而，<strong>新对象和原对象没有任何关联</strong>。</p><p>深度拷贝的实现方式如下：</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">import copyl1 = [[1, 2], (30, 40)]l2 = copy.deepcopy(l1)l1.append(100)l1[0].append(3)l1[[1, 2, 3], (30, 40), 100]l2 [[1, 2], (30, 40)]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>但如果原始对象中存在到自身的引用，在使用深度拷贝时很容易出现无限循环。</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">import copyx = [1]x.append(x)x[1, [...]]y = copy.deepcopy(x)y[1, [...]]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>但在执行时并未出现溢出的现象，这时应为深度拷贝函数会在拷贝的同时维持一个列表记录已经被拷贝的对象和其ID，遇到已经拷贝过的对象，会直接从字典中返回。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="https://time.geekbang.org/column/article/100105" target="_blank" rel="noopener">景霄-Python核心技术与实战</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 编程基础 </category>
          
          <category> 编程语言 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 编程基础 </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python的内存管理机制</title>
      <link href="/2019/10/24/python/python-de-nei-cun-guan-li-ji-zhi/"/>
      <url>/2019/10/24/python/python-de-nei-cun-guan-li-ji-zhi/</url>
      
        <content type="html"><![CDATA[<h1 id="Python的内存管理机制"><a href="#Python的内存管理机制" class="headerlink" title="Python的内存管理机制"></a>Python的内存管理机制</h1><h2 id="Python中与内存相关的基本概念"><a href="#Python中与内存相关的基本概念" class="headerlink" title="Python中与内存相关的基本概念"></a>Python中与内存相关的基本概念</h2><h3 id="变量、对象及引用"><a href="#变量、对象及引用" class="headerlink" title="变量、对象及引用"></a>变量、对象及引用</h3><p>在python中有一个基础概念：python中的所有东西都是对象。与C++等编译语言不同（把值赋给变量），python中的变量本身是不具有数据类型的，其数据类型由其所指向的对象的类型决定，如下：</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">a = 1<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>其中<code>a</code>被称为变量，而<code>1</code>则是对象，<code>a</code>的数据类型由<code>1</code>决定，即整型<code>int</code>，当我们将变量<code>a</code>指向另一个数据类型的对象时，<code>a</code>的类型也将随着其所指向的对象类型而发生改变。</p><p>在 Python 中 <code>a = something</code> 应该理解为给 <code>something</code> 贴上了一个标签 <code>a</code>。当再赋值给 <code>a</code> 的时候，就好象把<code>a</code> 这个标签从原来的 <code>something</code>上拿下来，贴到其他对象上，建立新的引用。</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">>> a = [1, 2, 3]>>> b = a>>> a = [4, 5, 6] //赋新的值给 a>>> a[4, 5, 6]>>> b[1, 2, 3]# a 的值改变后，a更换了对象，b 并没有随着 a 变>>> a = [1, 2, 3]>>> b = a>>> a[0], a[1], a[2] = 4, 5, 6 //改变原来 list 中的元素>>> a[4, 5, 6]>>> b[4, 5, 6]# a 的值改变后，b 随着 a 变了<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在python中，对象拥有真正的内存资源与相应的取值，变量只是对象的一个引用。一个变量引用一个对象，而一个对象可以被多个变量引用。正是因为一个对象可以被多个变量引用，所以<strong>只有在某个对象的引用个数为0时，python才会对该对象的内存进行回收</strong>，有点类似于C++中的智能指针的内存回收机制。</p><h3 id="存储机制"><a href="#存储机制" class="headerlink" title="存储机制"></a>存储机制</h3><p>总的来说，python在存储对象时存在<strong>三个存储区域</strong>：</p><ol><li>事先分配的静态内存，这一部分内存的大小以及对应的取值固定，需要某个对象时在相应位置取值即可。</li><li>事先分配的可重复利用内存，这一部分内存的大小固定，但在需要的时候才对这一部分内存进行赋值，这一部分的内存可以重复利用。</li><li>使用<code>malloc</code>和<code>free</code>管理的自由内存，这一部分的内存是动态申请和释放的。</li></ol><p>首先来看整型对象的存储，该类型的存储区域可分为两部分：对小整数<code>[-5, 256]</code>事先分配静态内存、对大整数（其他部分）事先分配可重复利用的内存。比如如下的代码：</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">def main():    x = y = -1    while True:        x += 1        y += 1        if x is y:            print('%d is %d' % (x, y))        else:            print('Attention! %d is not %d' % (x, y))            break    x = y = 0    while True:        x -= 1        y -= 1        if x is y:            print('%d is %d' % (x, y))        else:            print('Attention! %d is not %d' % (x, y))            breakif __name__ == '__main__':    main()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>其运行结果如下图所示：</p><p><img src="/2019/10/24/python/python-de-nei-cun-guan-li-ji-zhi/1568789682133.png" alt=""></p><p>出现这一现象的原因便是Python的静态内存机制，当整数的大小位于[-5,256]范围内时，在任何需要引用这些对象的地方，都不再重新创建新的对象，而是直接引用缓存中的对象。而当整数的大小不在这一范围内时，便会新建新的对象，这时即使值是一样的，也属于不同的对象（对应不同的内存地址）。</p><p>还有另外一种情况，如下代码所示：</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">a = 257def main():    b = 257  # 第6行    c = 257  # 第7行    print(b is c)  # True    print(a is b)  # False    print(a is c)  # Falseif __name__ == "__main__":    main()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>其运行结果如注释所示，看上去<code>a</code>、<code>b</code>和<code>c</code>的值都是一样的，但是<code>is</code>运算的结果却不一样。为什么会出现这样的结果，首先需要理解Python程序中的代码块的概念。</p><blockquote><p>所谓<strong>代码块</strong>是程序的一个最小的基本执行单位，一个模块文件、一个函数体、一个类、交互式命令中的单行代码都叫做一个代码块。</p></blockquote><p>上面的代码由两个代码块构成，<code>a = 257</code>是一个代码块，<code>main</code>函数是另外一个代码块。Python内部为了进一步提高性能，凡是在一个代码块中创建的整数对象，如果值不在<code>small_ints</code>（[-5,256]）缓存范围之内，但在同一个代码块中已经存在一个值与其相同的整数对象了，那么就直接引用该对象，否则创建一个新的对象出来，<strong>这条规则对不在<code>small_ints</code>范围的负数并不适用，对负数值浮点数也不适用，但对非负浮点数和字符串都是适用的</strong>，这一点读者可以自行证明。所以 <code>b is c</code>返回了<code>True</code>，而<code>a</code>和<code>b</code>不在同一个代码块中，虽然值都是257，但却是两个不同的对象，<code>is</code>运算的结果自然是<code>False</code>了。</p><p>而对于<code>string</code>类型，同样也划分为静态内存和可重复利用内存。</p><h2 id="Python的内存管理机制-1"><a href="#Python的内存管理机制-1" class="headerlink" title="Python的内存管理机制"></a>Python的内存管理机制</h2><p>在C++语言中，允许我们直接对内存进行管理，这样做的好处在于我们可以很灵活地对内存进行申请释放，缺点在于内存管理较为复杂、容易出错。在Python中，其本质上也是使用<code>malloc</code>和<code>free</code>等进行内存的管理，但区别在于Python本身完成了对内存的自动管理，有一套完整的内存管理机制，只向程序员提供了少量的接口。</p><p>Python的内存管理机制总体上可以划分为两个部分：</p><h3 id="引用计数机制"><a href="#引用计数机制" class="headerlink" title="引用计数机制"></a>引用计数机制</h3><p>引用计数机制的主要作用为：依据对象的被引用次数决定该对象是否应该被释放。</p><blockquote><p>针对可以重复利用的内存缓冲区和内存，python使用了一种引用计数的方式来控制和判断某快内存是否已经没有再被使用。即每个对象都有一个计数器count，记住了有多少个变量指向这个对象，当这个对象的引用计数器为0时，假如这个对象在缓冲区内，那么它地址空间不会被释放，而是等待下一次被使用，而非缓冲区的该释放就释放</p></blockquote><p>当出现以下情况时，某一对象的引用个数将增加：</p><ul><li><p>对象被创建<code>p = Person()</code>，增加1；</p></li><li><p>对象被引用<code>p1 = p</code>，增加1；</p></li><li>对象被当作参数传入函数<code>func(object)</code>，增加2，原因是函数中有两个属性在引用该对象；</li><li>对象存储到容器对象中<code>l = [p]</code>，增加1</li></ul><p>当出现以下情况时，某一对象的引用个数将减少：</p><ul><li>对象的别名被销毁<code>del p</code>，减少1；</li><li>对象的别名被赋予其他对象，减少1；</li><li>对象离开自己的作用域，如<code>getrefcount(object)</code>方法，每次用完后，其对对象的那个引用就会被销毁，减少1；</li><li>对象从容器对象中删除，或者容器对象被销毁，减少1。</li></ul><h3 id="垃圾回收机制"><a href="#垃圾回收机制" class="headerlink" title="　垃圾回收机制"></a>　垃圾回收机制</h3><p>垃圾回收机制的主要作用为：用于解决引用计数机制无法释放的循环引用问题，同时提供了手动释放内存的接口。</p><p>python提供了<code>del</code>方法来删除某个变量，它的作用是让某个对象引用数减少1。当某个对象引用数变为0时并不是直接将它从内存空间中清除掉，而是采用垃圾回收机制<code>gc</code>模块，当这些引用数为0的变量规模达到一定规模，就自动启动垃圾回收，将那些引用数为0的对象所占的内存空间释放。</p><p><code>gc</code>模块采用了<strong>分代回收</strong>方法，将对象根据存活的时间分为<strong>三代</strong>:</p><ol><li>所有新建的对象都是0代，当0代对象经过一次自动垃圾回收，没有被释放的对象会被归入1代，</li><li>同理1代归入2代。</li><li>每次当0代对象中引用数为0的对象超过700个时，启动一次0代对象扫描垃圾回收;</li><li>经过10次的0代回收，就进行一次0代和1代回收;</li><li>1代回收次数超过10次，就会进行一次0代、1代和2代回收。而这里的几个值是通过查询<code>get_threshold()</code>返回(700,10,10)得到的。此外，<code>gc</code>模块还提供了手动回收的函数，即<code>gc.collect()</code>。</li></ol><p>上述内容参考自<a href="https://chenrudan.github.io/blog/2016/04/23/pythonmemorycontrol.html" target="_blank" rel="noopener">内存管理</a></p><p>而垃圾回收还有一个重要功能是，解决循环引用的问题，通常发生在某个变量<code>a</code>引用了自己或者变量<code>a</code>与<code>b</code>互相引用。考虑引用自己的情况，可以从下面的例子中看到，<code>a</code>所指向的内存对象有3个引用，但是实际上只有两个变量，假如把这两个变量都<code>del</code>掉，对象引用个数还是1，没有变成0，这种情况下，如果只有引用计数的机制，那么这块没有用的内存会一直无法释放掉。</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">>>> a = []>>> b = a>>> getrefcount(b)3>>> a.append(a)>>> getrefcount(b)4>>> del a>>> getrefcount(b)3>>> del b>>> unreachable = gc.collect()>>> unreachable1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Python的<code>gc</code>模块便可以被用来处理这种情况。</p><h2 id="Python中的拷贝"><a href="#Python中的拷贝" class="headerlink" title="Python中的拷贝"></a>Python中的拷贝</h2><p>在Python中，如果直接使用<code>a=b</code>的方式，其实是新增了对象的引用，变量<code>a</code>和<code>b</code>指向同一个对象，因而对两个变量中的任何一个进行修改都会导致原始对象的修改。</p><p>为了使用拷贝，我们需要使用<code>copy</code>模块，在Python中将拷贝分为浅拷贝（<code>copy</code>）和深拷贝（<code>deepcopy</code>），对于一般的对象来说，浅拷贝和深拷贝不存在区别。但对于一些较为复杂的对象，例如嵌套的<code>list</code>将会产生区别。</p><p>当对嵌套<code>list</code>使用浅拷贝时，实际上拷贝的时<code>list</code>里各个对象的引用，将<code>list</code>中各个<strong>对象的引用</strong>存放到了新的内存地址，浅拷贝示意如下：</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">>>> import copy>>> origin = [1, 2, [3, 4]]>>> cop1 = copy.copy(origin)>>> cop2 = copy.deepcopy(origin)>>> cop1 == cop2True>>> cop1 is cop2False # cop2和cop1处于不同的内存地址，是不同的对象>>> origin[2][0] = "hey!" >>> origin[1, 2, ['hey!', 4]]>>> cop1[1, 2, ['hey!', 4]]# 浅拷贝拷贝的是list中的各个对象的引用，改变一个会影响另一个>>> cop2[1, 2, [3, 4]]# 深拷贝拷贝的是list中的各个对象的值，改变一个不会影响另一个<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>copy</code>对于一个<strong>复杂对象的子对象</strong>并不会完全复制，什么是复杂对象的子对象呢？就比如序列里的嵌套序列，字典里的嵌套序列等都是复杂对象的子对象。对于子对象，python会把它当作一个公共镜像存储起来，所有对他的复制都被当成一个<strong>引用</strong>，所以说当其中一个引用将镜像改变了之后另一个引用使用镜像的时候镜像已经被改变了，如下图所示，子对象指向的是同一个公共镜像。</p><p><img src="/2019/10/24/python/python-de-nei-cun-guan-li-ji-zhi/20180330104016583.gif" alt="è¿éåå¾çæè¿°"></p><p>而对于深拷贝<code>deepcopy</code>而言，会将对象中的每一层复制为一个单独的个体，因而复制之后得到的对象和原始对象互不影响，如下图所示，各个子对象指向的是一个独立的个体。</p><p><img src="/2019/10/24/python/python-de-nei-cun-guan-li-ji-zhi/20180330104112461.gif" alt="è¿éåå¾çæè¿°"></p><h2 id="嵌套列表的坑"><a href="#嵌套列表的坑" class="headerlink" title="嵌套列表的坑"></a>嵌套列表的坑</h2><p>以下内容转自<a href="[https://github.com/jackfrued/Python-100-Days/blob/master/%E9%82%A3%E4%BA%9B%E5%B9%B4%E6%88%91%E4%BB%AC%E8%B8%A9%E8%BF%87%E7%9A%84%E9%82%A3%E4%BA%9B%E5%9D%91.md](https://github.com/jackfrued/Python-100-Days/blob/master/那些年我们踩过的那些坑.md">那些年我们踩过的坑</a>)</p><p>Python中有一种内置的数据类型叫列表，它是一种容器，可以用来承载其他的对象（准确的说是其他对象的引用），列表中的对象可以称为列表的元素，很明显我们可以把列表作为列表中的元素，这就是所谓的嵌套列表。嵌套列表可以模拟出现实中的表格、矩阵、2D游戏的地图（如植物大战僵尸的花园）、棋盘（如国际象棋、黑白棋）等。但是在使用嵌套的列表时可能会出现一些问题：</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">names = ['关羽', '张飞', '赵云', '马超', '黄忠']subjs = ['语文', '数学', '英语']scores = [[0] * 3] * 5for row, name in enumerate(names):    print('请输入%s的成绩' % name)    for col, subj in enumerate(subjs):        scores[row][col] = float(input(subj + ': '))        print(scores)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>我们希望录入5个学生3门课程的成绩，于是定义了一个有5个元素的列表，而列表中的每个元素又是一个由3个元素构成的列表，这样一个列表的列表刚好跟一个表格是一致的，相当于有5行3列，接下来我们通过嵌套的for-in循环输入每个学生3门课程的成绩。程序执行完成后我们发现，每个学生3门课程的成绩是一模一样的，而且就是最后录入的那个学生的成绩。</p><p>要想把这个坑填平，我们首先要区分对象和对象的引用这两个概念，而要区分这两个概念，还得先说说内存中的栈和堆。我们经常会听人说起“<strong>堆栈</strong>”这个词，但实际上“堆”和“栈”是两个不同的概念。众所周知，一个程序运行时需要占用一些内存空间来存储数据和代码，那么这些内存从逻辑上又可以做进一步的划分。对底层语言（如C语言）有所了解的程序员大都知道，程序中可以使用的内存从逻辑上可以为五个部分，按照地址从高到低依次是：栈（stack）、堆（heap）、数据段（data segment）、只读数据段（static area）和代码段（code segment）。其中，栈用来存储局部、临时变量，以及函数调用时保存现场和恢复现场需要用到的数据，这部分内存在代码块开始执行时自动分配，代码块执行结束时自动释放，通常由编译器自动管理；堆的大小不固定，可以动态的分配和回收，因此如果程序中有大量的数据需要处理，这些数据通常都放在堆上，如果堆空间没有正确的被释放会引发内存泄露的问题，而像Python、Java等编程语言都使用了垃圾回收机制来实现自动化的内存管理（自动回收不再使用的堆空间）。</p><p>所以下面的代码中，变量<code>a</code>并不是真正的对象，它是对象的引用，相当于记录了对象在堆空间的地址，通过这个地址我们可以访问到对应的对象；同理，变量<code>b</code>是列表容器的引用，它引用了堆空间上的列表容器，而列表容器中并没有保存真正的对象，它保存的也仅仅是对象的引用。</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">a = object()b = ['apple', 'pitaya', 'grape']<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>知道了这一点，我们可以回过头看看刚才的程序，我们对列表进行<code>[[0] * 3] * 5</code>操作时，仅仅是将<code>[0, 0, 0]</code>这个列表的地址进行了复制，并没有创建新的列表对象，所以容器中虽然有5个元素，但是这5个元素引用了同一个列表对象，这一点可以通过<code>id</code>函数检查<code>scores[0]</code>和<code>scores[1]</code>的地址得到证实。</p><pre class="line-numbers language-lang-shell"><code class="language-lang-shell">scores[0]: 212a5f1f8c8, scores[1]: 212a5f1f8c8<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-lang-python"><code class="language-lang-python">scores = [[0] * 3] * 5<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这句代码所创建的内存的分布如下图所示：</p><p><img src="/2019/10/24/python/python-de-nei-cun-guan-li-ji-zhi/1568792629558.png" alt=""></p><p>所以正确的代码应该按照如下的方式进行修改。</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">names = ['关羽', '张飞', '赵云', '马超', '黄忠']subjs = ['语文', '数学', '英语']scores = [[]] * 5for row, name in enumerate(names):    print('请输入%s的成绩' % name)    scores[row] = [0] * 3    for col, subj in enumerate(subjs):        scores[row][col] = float(input(subj + ': '))        print(scores)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>内存分布方式如下：</p><p><img src="/2019/10/24/python/python-de-nei-cun-guan-li-ji-zhi/1568792969372.png" alt="1568792969372"></p><p>在上述代码中，最外层列表的每一个元素所引用的列表都是在运行时重新分配的。</p><p>或者：</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">names = ['关羽', '张飞', '赵云', '马超', '黄忠']subjs = ['语文', '数学', '英语']scores = [[0] * 3 for _ in range(5)]for row, name in enumerate(names):    print('请输入%s的成绩' % name)    scores[row] = [0] * 3    for col, subj in enumerate(subjs):        scores[row][col] = float(input(subj + ': '))        print(scores)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这一做法其实和上一个做法相同，都是在运行时分配对象内存。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="https://blog.csdn.net/u010712012/article/details/79754132" target="_blank" rel="noopener">python中copy()和deepcopy()详解</a></li><li><a href="https://chenrudan.github.io/blog/2016/04/23/pythonmemorycontrol.html" target="_blank" rel="noopener">Python内存管理</a></li><li><a href="[https://github.com/jackfrued/Python-100-Days/blob/master/%E9%82%A3%E4%BA%9B%E5%B9%B4%E6%88%91%E4%BB%AC%E8%B8%A9%E8%BF%87%E7%9A%84%E9%82%A3%E4%BA%9B%E5%9D%91.md](https://github.com/jackfrued/Python-100-Days/blob/master/那些年我们踩过的那些坑.md">那些年我们踩过的坑</a>)</li></ul>]]></content>
      
      
      <categories>
          
          <category> 编程基础 </category>
          
          <category> 编程语言 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 编程基础 </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python中的函数</title>
      <link href="/2019/10/19/python/python-zhong-de-han-shu/"/>
      <url>/2019/10/19/python/python-zhong-de-han-shu/</url>
      
        <content type="html"><![CDATA[<h1 id="Python中的函数"><a href="#Python中的函数" class="headerlink" title="Python中的函数"></a>Python中的函数</h1><p><img src="/2019/10/19/python/python-zhong-de-han-shu/58154038eb26ff83d72f993821002b0f.jpg" alt=""></p><p>该博客主要记录Python中函数的一些高级用法，例如函数变量作用域、闭包、固定函数的部分参数等。该博客的大部分内容来自《Python Cookbook》。</p><h2 id="函数变量作用域"><a href="#函数变量作用域" class="headerlink" title="函数变量作用域"></a>函数变量作用域</h2><p>Python函数中变量的作用域和其它语言类似。如果变量是在函数内部定义的，就称为局部变量，只在函数内部有效。一旦函数执行完毕，局部变量就会被回收，无法访问。</p><p>而全局变量是定义在整个文件层次上的，如果局部变量和全局或者外部变量同名，局部变量会覆盖全局或者外部变量。但这里要注意的一点是我们不能直接在函数中改变全局变量的值，如下述代码：</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">MIN_VALUE = 1MAX_VALUE = 10def validation_check(value):    ...    MIN_VALUE += 1    ...validation_check(5)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>会引发以下错误：</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">UnboundLocalError: local variable 'MIN_VALUE' referenced before assignment<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>因为，Python的解释器会默认函数内部的变量为局部变量，但是局部变量尚未被声明，因而无法执行相关操作。所有，如果我们一定要在函数内部改变全局变量的值，必须加上<code>global</code>声明：</p><pre class="line-numbers language-lang-python"><code class="language-lang-python"># 变量作用域MIN_VALUE = 1def func():    global MIN_VALUE     MIN_VALUE = 3    print("Inner value: %d" % MIN_VALUE)func()print('Outer value: %d' % MIN_VALUE)# 结果Inner value: 3Outer value: 3<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如果我们在函数中重新声明一个同名的局部变量，那么在函数内部局部变量会覆盖全局变量，无论对内部局部变量进行何种操作都不会影响到外部的全局变量：</p><pre class="line-numbers language-lang-python"><code class="language-lang-python"># %%# 变量作用域MIN_VALUE = 1def func():    MIN_VALUE = 3    print("Inner value: %d" % MIN_VALUE)func()print('Outer value: %d' % MIN_VALUE)# 结果Inner value: 3Outer value: 1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>类似，对于嵌套函数来说，内部函数是无法改变外部函数定义的变量的，如果要修改就需要加上<code>nonlocal</code>关键字：</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">def outer():    x = "local"    def inner():        nonlocal x # nonlocal 关键字表示这里的 x 就是外部函数 outer 定义的变量 x        x = 'nonlocal'        print("inner:", x)    inner()    print("outer:", x)outer()# 输出inner: nonlocalouter: nonlocal<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如果没有<code>nonlocal</code>关键字，内部的变量会覆盖外部变量：</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">def outer():    x = "local"    def inner():        x = 'nonlocal' # 这里的 x 是 inner 这个函数的局部变量        print("inner:", x)    inner()    print("outer:", x)outer()# 输出inner: nonlocalouter: local<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>总的来说，如果我们想要在函数作用域里面修改函数外部的变量的值，就必须使用相应的关键字进行提前声明。</p><h2 id="闭包"><a href="#闭包" class="headerlink" title="闭包"></a>闭包</h2><p>该部分参考<a href="https://foofish.net/python-closure.html" target="_blank" rel="noopener">Python之禅-一步一步教你认识Python闭包</a>。</p><p>闭包的作用：使得局部变量在函数外被访问成为可能。闭包返回内部的嵌套函数。</p><blockquote><p>在计算机科学中，闭包（Closure）是词法闭包（Lexical Closure）的简称，是引用了自由变量的函数。这个被引用的自由变量将和这个函数一同存在，即使已经离开了创造它的环境也不例外。所以，有另一种说法认为闭包是由函数和与其相关的引用环境组合而成的实体。</p></blockquote><p>以下述代码为例：</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">def print_msg():    # print_msg 是外围函数    msg = "zen of python"    def printer():        # printer 是嵌套函数        print(msg)    return printeranother = print_msg()# 输出 zen of pythonanother()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这里的<code>another</code>就是一个闭包，闭包本质上是一个函数，由两部分组成：<code>printer</code>函数和变量<code>msg</code>。闭包的作用是使得变量始终被保存在内存中。</p><blockquote><p>闭包，顾名思义，就是一个封闭的包裹，里面包裹着自由变量，就像在类里面定义的属性值一样，自由变量的可见范围随同包裹，哪里可以访问到这个包裹，哪里就可以访问到这个自由变量。</p></blockquote><p>除此之外，如果一个函数被反复调用，且在这个函数的开始会调用一些类型检查、参数初始化的语句时，就可以使用闭包来实现。</p><h2 id="使用函数替代只有单个方法的类"><a href="#使用函数替代只有单个方法的类" class="headerlink" title="使用函数替代只有单个方法的类"></a>使用函数替代只有单个方法的类</h2><p>有时，我们需要在执行函数的过程中保存其中的一些状态变量。一种最简单的方法是定义一个类，使用类的属性保存变量，但这种做法未免过于冗余。为了简单起见，我们可以使用闭包技术将其转换为一个函数。</p><pre class="line-numbers language-lang-python"><code class="language-lang-python"># 使用类保存状态from urllib.request import urlopenclass UrlTemplate:    def __init__(self, template):        self.template = template    def open(self, **kwargs):        return urlopen(self.template.format_map(kwargs))yahoo = UrlTemplate('http://finance.yahoo.com/d/quotes.csv?s={names}&f={fields}')for line in yahoo.open(names='IBM,AAPL,FB', fields='sllclv'):    print(line.decode('utf-8'))# 使用闭包def urltemplate(template):    def opener(**kwargs):        return urlopen(template.format_map(kwargs))    return openeryahoo = urltemplate('http://finance.yahoo.com/d/quotes.csv?s={names}&f={fields}')for line in yahoo(names='IBM,AAPL,FB', fields='sllclv'):    print(line.decode('utf-8'))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>相比于使用只有单个方法的类，使用闭包会更加简洁优雅。闭包的核心就是它可以记住定义闭包时的环境。无论何时，当在编写代码时遇到需要附加额外的状态给函数时，请考虑闭包。</p><h2 id="在回调函数中携带额外的状态"><a href="#在回调函数中携带额外的状态" class="headerlink" title="在回调函数中携带额外的状态"></a>在回调函数中携带额外的状态</h2><p>在实际项目中，我们会编写许多需要回调函数的代码，有时我们需要在回调函数中保存额外的状态。与上一小节类似，我们可以考虑使用类来实现这一功能。</p><pre class="line-numbers language-lang-python"><code class="language-lang-python"># 使用类保存额外的状态class ResultHandler:    def __init__(self):        self.sequence = 0    def handler(self, result):        self.sequence += 1        print('[{}] Got: {}'.format(self.sequence, result))def apply_async(func, args, *, callback):    result = func(*args)    # 调用回调函数    callback(result)def add(x, y):    return x + yr = ResultHandler()apply_async(add, (2, 3), callback=r.handler)apply_async(add, ('hello', 'world'), callback=r.handler)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>运行结果如下：</p><pre class="line-numbers language-lang-shell"><code class="language-lang-shell">[1] Got: 5[2] Got: helloworld<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>同样，我们也可以使用闭包来捕获状态：</p><pre class="line-numbers language-lang-python"><code class="language-lang-python"># 使用闭包def make_handler():    sequence = 0    def handler(result):        # nonlocal声明用于表明变量sequence是在回调函数中修改的        nonlocal sequence        sequence += 1        print('[{}] Got: {}'.format(sequence, result))    return handlerhandler = make_handler()apply_async(add, (2, 3), callback=handler)apply_async(add, ('hello', 'world'), callback=handler)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>除此之外，还可以使用<strong>协程</strong>来携带状态：</p><pre class="line-numbers language-lang-python"><code class="language-lang-python"># 使用协程的方式在回调函数中携带状态def apply_async(func, args, *, callback):    result = func(*args)    # 调用回调函数    callback(result)def add(x, y):    return x + ydef make_handler():    sequence = 0    while(True):        result = yield        sequence += 1        print('[{}] Got: {}'.format(sequence, result))handler = make_handler()next(handler)apply_async(add, (2, 3), callback=handler.send)apply_async(add, ('hello', 'world'), callback=handler.send)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>最后，也可以使用额外的参数在回调函数中携带状态：</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">from functools import partialdef apply_async(func, args, *, callback):    result = func(*args)    # 调用回调函数    callback(result)def add(x, y):    return x + yclass SequenceNo:    def __init__(self):        self.sequence = 0def handler(result, seq):    seq.sequence += 1    print('[{}] Got: {}'.format(seq.sequence, result))seq = SequenceNo()apply_async(add, (2, 3), callback=partial(handler, seq=seq))apply_async(add, ('hello', 'world'), callback=partial(handler, seq=seq))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在上述代码中，因为要传入额外的参数来保存状态，因而回调函数会多出一个参数。同时，在调用回调函数时，只能传入一个参数，因而需要使用<code>partial</code>函数来解决这一问题。</p><h2 id="访问定义在闭包内的变量"><a href="#访问定义在闭包内的变量" class="headerlink" title="访问定义在闭包内的变量"></a>访问定义在闭包内的变量</h2><p>希望通过函数来扩展闭包，使得在闭包内层定义的变量可以被访问或修改。一般来说，在闭包内层定义的变量对于外界来说是完全隔离的，但是可以通过编写存取函数，并将它们作为函数属性附加到闭包上来提供对内层变量的访问机制。</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">def sample():    n = 0    # Closure function    def func():        print('n=', n)    # Accessor methods for n    def get_n():        return n    def set_n(value):        nonlocal n        n = value    # Attach as function attributes    func.get_n = get_n    func.set_n = set_n    return func<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>nolocal</code>关键字使得我们可以编写函数来修改内部变量的值；函数属性允许我们用一种简单的方式将方法绑定到闭包函数上。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li>Python-Cookbook</li></ul>]]></content>
      
      
      <categories>
          
          <category> 编程基础 </category>
          
          <category> 编程语言 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 编程基础 </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python的模块化编程</title>
      <link href="/2019/10/19/python/python-mo-kuai-hua-bian-cheng/"/>
      <url>/2019/10/19/python/python-mo-kuai-hua-bian-cheng/</url>
      
        <content type="html"><![CDATA[<h1 id="Python模块化编程"><a href="#Python模块化编程" class="headerlink" title="Python模块化编程"></a>Python模块化编程</h1><h2 id="包与模块的导入"><a href="#包与模块的导入" class="headerlink" title="包与模块的导入"></a>包与模块的导入</h2><h3 id="包对应的from语句和import语句"><a href="#包对应的from语句和import语句" class="headerlink" title="包对应的from语句和import语句"></a>包对应的from语句和import语句</h3><p>import语句和包一起使用时，有些不方便，因为你必须经常在程序中重新输入路径。因此，让包使用from语句，来避免每次读取时都得重新输入路径，并且当目录树结构发生改变时，只需要在程序中更新一次路径即可。</p><p>实际中需要包导入的场合，就是解决当多个同名程序文件安装在同一个机器上时，所引发的模糊性。假设目录结构如下：</p><pre class="line-numbers language-lang-shell"><code class="language-lang-shell">system1\    utilities.py    main.py    other.py<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>与<code>system1</code>位于同一父目录下存在另一目录：</p><pre class="line-numbers language-lang-shell"><code class="language-lang-shell">system2\    utilities.py    main.py    other.py<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Python总是先搜索主目录，也就是包含顶层文件的目录，例如，在<code>system1/main.py</code>中使用导入语句<code>import utilities</code>，导入会先搜索<code>system1</code>，只有在跨目录进行导入时才需要模块搜索路径的设置。</p><p>但是在第三个目录下导入另两个目录中的同名文件时就会发生错误，例如在第三个目录的程序文件中使用<code>import utilities</code>，便会产生模糊性，解释器会先搜索位于搜索路径左侧的<code>utilities.py</code>，这样做很容易出错，当然，我们可以使用<code>sys.path</code>对路径进行修改，但很容易出错。</p><p><strong>使用包便可以解决模块查找的模糊性</strong>，不要在单独的目录内把文件安装成单纯的文件列表，而是将它们打包，在共同的根目录下，以子目录的方式进行组织，如下所示：</p><pre class="line-numbers language-lang-shell"><code class="language-lang-shell">root\    system1\        __init__.py        utilities.py        main.py        other.py    system2\        __init__.py        utilities.py        main.py        other.py    system3\        __init__py        myfile.py<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在<code>myfile.py</code>中可以使用import语句进行导入：</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">import system1.utilitiesimpott system2.utilitiessystem1.utilities.function('spam')system2.utilities.function('eggs')<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>注意</strong>：当读取两个或两个以上路径内的同名属性时，必须使用 <code>import</code>，不能使用<code>from</code>。</p><h3 id="包相对导入"><a href="#包相对导入" class="headerlink" title="包相对导入"></a>包相对导入</h3><p>上述导入方式都是针对从包的外部导入包文件而言的，在包自身的内部，包文件的导入可以使用和外部导入相同的路径语法。但是，也存在特殊的包内搜索规则来简化导入语句，也就是说，<strong>包内的导入可能相对于包，而不是列出包导入路径</strong>。</p><p>注意，包的相对导入机制与版本有关。Python2.6首先在导入上隐式地搜索包目录，而Python3.0需要显示地使用相对导入语法，这种变化使得相同的包的导入更为明显，从而增强代码的可读性。</p><h4 id="Python3-0中的变化"><a href="#Python3-0中的变化" class="headerlink" title="Python3.0中的变化"></a>Python3.0中的变化</h4><p>引入了两个变化：</p><ul><li>修改了模块导入搜索路径语义，默认跳过包自己的目录。导入只是检查搜索路径的其他组件，叫做“<strong>绝对导入</strong>”。</li><li></li><li>扩展了<code>from</code>语句，允许显式地要求导入只搜索包的目录，叫做“<strong>相对导入</strong>”.</li></ul><p>在python3.0和python2.6中，from语句可以使用前面的点号<code>.</code>来指定，导入位于同一包的模块，即相对导入，而不是位于模块导入路径上某处的模块，即绝对导入。</p><ul><li>点号表示导入应该相对于外围的包-这样的导入将只在包的内部搜索，并且不会搜索位于导入搜索路径(sys.path)上某处的同名模块。即包模块覆盖了外部的模块。</li><li>在python2.6中，包的代码中的常规导入默认为先相对再绝对。而在Python3.0中在一个包中导入默认是绝对的。</li></ul><p>使用两个点表示在文件所在的包的父目录的相对导入，如：</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">from .. import spam<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>表示从与spam所在包的父目录开始进行相对导入，假设目录结构如下。</p><pre><code>A\|_ _ __init__.py|_ _ B\|    |_ _ myfile.py|    |_ _ D\|         |_ _ X|_ _ E\     |_ _X</code></pre><blockquote><p><strong>注意：A目录下有<code>__init__.py</code>文件，也就是说A是一个包，如果没有<code>__init__.py</code></strong> ，则会出现以下错误：</p></blockquote><pre class="line-numbers language-lang-shell"><code class="language-lang-shell">ImportError: attempted relative import with no known parent package<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>该错误说明，解释器在从当前文件向上查找包时，超出了包的范围。</p><p>在该目录结构下，<code>myfile.py</code>有如下导入方式：</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">from . import D # 导入A.B.Dfrom .. import E # 导入 A.Efrom .D import X # 导入A.B.D.Xfrom ..E import X # 导入A.E.X<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="使用相对导入要注意以下几点"><a href="#使用相对导入要注意以下几点" class="headerlink" title="使用相对导入要注意以下几点"></a>使用相对导入要注意以下几点</h3><ul><li>相对导入只适用于包内导入。</li><li>相对导入只适用于from语句。</li></ul><h3 id="可选导入"><a href="#可选导入" class="headerlink" title="可选导入"></a>可选导入</h3><p>如果你希望优先使用某个模块或包，但是同时也想在没有这个模块或包的情况下有备选，你就可以使用可选导入这种方式。这样做可以导入支持某个软件的多种版本或者实现性能提升。以<a href="http://pythonhosted.org/github2/_modules/github2/request.html" target="_blank" rel="noopener">github2包</a>中的代码为例：</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">try:    # For Python 3    from http.client import responsesexcept ImportError:  # For Python 2.5-2.7    try:        from httplib import responses  # NOQA    except ImportError:  # For Python 2.4        from BaseHTTPServer import BaseHTTPRequestHandler as _BHRH        responses = dict([(k, v[0]) for k, v in _BHRH.responses.items()])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>lxml</code>包也有使用可选导入方式：</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">try:    from urlparse import urljoin    from urllib2 import urlopenexcept ImportError:    # Python 3    from urllib.parse import urljoin    from urllib.request import urlopen<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>正如以上示例所示，<strong>可选导入的使用很常见，是一个值得掌握的技巧</strong>。</p><h3 id="局部导入"><a href="#局部导入" class="headerlink" title="局部导入"></a>局部导入</h3><p>当你在局部作用域中导入模块时，你执行的就是局部导入。如果你在Python脚本文件的顶部导入一个模块，那么你就是在将该模块导入至全局作用域，这意味着之后的任何函数或方法都可能访问该模块。例如：</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">import sys  # global scopedef square_root(a):    # This import is into the square_root functions local scope    import math    return math.sqrt(a)def my_pow(base_num, power):    return math.pow(base_num, power)if __name__ == '__main__':    print(square_root(49))    print(my_pow(2, 3))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这里，我们将<code>sys</code>模块导入至全局作用域，但我们并没有使用这个模块。然后，在<code>square_root</code>函数中，我们将<code>math</code>模块导入至该函数的局部作用域，这意味着<code>math</code>模块只能在<code>square_root</code>函数内部使用。如果我们试图在<code>my_pow</code>函数中使用<code>math</code>，会引发<code>NameError</code>。</p><p>使用局部作用域的好处之一，是你使用的模块可能需要很长时间才能导入，如果是这样的话，将其放在某个不经常调用的函数中或许更加合理，而不是直接在全局作用域中导入。</p><p>但是，<strong>根据约定，所有的导入语句都应该位于模块的顶部</strong>。</p><h3 id="导入注意事项"><a href="#导入注意事项" class="headerlink" title="导入注意事项"></a>导入注意事项</h3><p>在导入模块方面，有几个程序员常犯的错误。这里我们介绍两个。</p><ul><li>循环导入（circular imports）</li><li>覆盖导入（Shadowed imports，暂时翻译为覆盖导入）</li></ul><p>先来看看循环导入。</p><h3 id="循环导入"><a href="#循环导入" class="headerlink" title="循环导入"></a>循环导入</h3><p>如果你创建两个模块，二者相互导入对方，那么就会出现循环导入。例如：</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">a.pyimport bdef a_test():    print("in a_test")    b.b_test()a_test()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>然后在同个文件夹中创建另一个模块，将其命名为<code>b.py</code>。</p><pre class="line-numbers language-lang-Python"><code class="language-lang-Python">import adef b_test():    print('In test_b"')    a.a_test()b_test()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如果你运行任意一个模块，都会引发<code>AttributeError</code>。这是因为这两个模块都在试图导入对方。简单来说，模块<code>a</code>想要导入模块<code>b</code>，但是因为模块<code>b</code>也在试图导入模块<code>a</code>（这时正在执行），模块<code>a</code>将无法完成模块<code>b</code>的导入。一般来说，<strong>修改方法是重构代码，避免发生这种情况</strong>。</p><h4 id="覆盖导入"><a href="#覆盖导入" class="headerlink" title="覆盖导入"></a>覆盖导入</h4><p>当你创建的模块与标准库中的模块同名时，如果你导入这个模块，就会出现覆盖导入。举个例子，创建一个名叫<code>math.py</code>的文件，在其中写入如下代码：</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">import mathdef square_root(number):    return math.sqrt(number)square_root(72)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>试着运行这个文件，你会得到以下回溯信息（traceback）：</p><pre class="line-numbers language-lang-shell"><code class="language-lang-shell">Traceback (most recent call last):  File "math.py", line 1, in <module>    import math  File "/Users/michael/Desktop/math.py", line 6, in <module>    square_root(72)  File "/Users/michael/Desktop/math.py", line 4, in square_root    return math.sqrt(number)AttributeError: module 'math' has no attribute 'sqrt'<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>你运行这个文件的时候，Python解释器首先在当前运行脚本所处的的文件夹中查找名叫<code>math</code>的模块。在这个例子中，解释器找到了我们正在执行的模块，试图导入它。但是我们的模块中并没有叫<code>sqrt</code>的函数或属性，所以就抛出了<code>AttributeError</code>。</p><h2 id="项目模块化"><a href="#项目模块化" class="headerlink" title="项目模块化"></a>项目模块化</h2><p>在Linux系统中，每一个文件都有一个绝对路径，以<code>\</code>开头，来表示从根目录到叶子结点的路径，这种方法叫做绝对路径。另外，对于任意两个文件，都存在从一个文件到另一个文件的路径，如：<code>../../Downloads/example.json</code>，该路径称为相对路径。</p><p>在大型工程中应该尽可能使用绝对位置，而非相对位置，对于一个独立的项目，所有的模块的追寻方式都最好从项目的根目录开始，称为相对的绝对路径。</p><p>例如，有一个项目的结构如下：</p><pre class="line-numbers language-lang-shell"><code class="language-lang-shell">.├── proto│   ├── mat.py├── utils│   └── mat_mul.py└── src    └── main.py<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>各个文件中的代码如下：</p><pre class="line-numbers language-lang-python"><code class="language-lang-python"># proto/mat.pyclass Matrix(object):    def __init__(self, data):        self.data = data        self.n = len(data)        self.m = len(data[0])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-lang-python"><code class="language-lang-python"># proto/mat.pyclass Matrix(object):    def __init__(self, data):        self.data = data        self.n = len(data)        self.m = len(data[0])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-lang-python"><code class="language-lang-python"># utils/mat_mul.pyfrom proto.mat import Matrixdef mat_mul(matrix_1: Matrix, matrix_2: Matrix):    assert matrix_1.m == matrix_2.n    n, m, s = matrix_1.n, matrix_1.m, matrix_2.m    result = [[0 for _ in range(n)] for _ in range(s)]    for i in range(n):        for j in range(s):            for k in range(m):                result[i][k] += matrix_1.data[i][j] * matrix_2.data[j][k]    return Matrix(result)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-lang-python"><code class="language-lang-python"># src/main.pyfrom proto.mat import Matrixfrom utils.mat_mul import mat_mula = Matrix([[1, 2], [3, 4]])b = Matrix([[5, 6], [7, 8]])print(mat_mul(a, b).data)########## 输出 ##########[[19, 22], [43, 50]]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>观察上述代码，在<code>utils/mat_mul.py</code>文件中，导入<code>Matrix</code>的方式是从工程的目录开始导入<code>from proto.mat import Matrix</code>，而不是使用<code>..</code>从上一级目录导入。</p><p>在<code>Pycharm</code>中，上述代码可以被成功运行，但是如果在命令行中，无论是进入<code>src</code>文件夹输入<code>python main.py</code>还是退回上一级目录，输入<code>python src/main.py</code>，都会出现找不到包<code>proto</code>的错误。</p><p>实际上，正如上文中所示，Python解释器在导入模块时，会在一个特定的列表中查找模块，如下：</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">import sys  print(sys.path)########## 输出 ##########['', '/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '/usr/local/lib/python3.6/dist-packages', '/usr/lib/python3/dist-packages']<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>对于Pycharm来说，当它运行程序时，会首先将上述列表的第一项设置为项目的根目录。因而，无论如何运行<code>main.py</code>，导入模块时都会首先从项目的根目录中寻找对应的包和模块。</p><p>为了在命令函中也能达到无论如何运行<code>main.py</code>也能正确找到包和模块的目的，有以下两种方法：</p><ul><li><p>直接对上述列表的第一个位置进行修改。但这样就在代码中写入了绝对路径，不推荐。</p></li><li><p>修改<code>PYTHONHOME</code>。Python存在一个虚拟运行环境，提倡每一个项目最好都有一个对立的运行环境来保持包和模块的纯洁性。</p><p>可以直接在Virtual Environment中的activate文件中加入：</p><pre class="line-numbers language-lang-shell"><code class="language-lang-shell">export PYTHONPATH="/home/ubuntu/workspace/your_projects"<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li></ul><h2 id="if-name-‘main‘"><a href="#if-name-‘main‘" class="headerlink" title="if name == ‘main‘"></a>if <strong>name</strong> == ‘<strong>main</strong>‘</h2><p>C++、Java等语言需要显式提供入口函数<code>main()</code>，但Python不用。那么，<code>if __name__ == __main__</code>的作用是什么？</p><p>有项目结构如下：</p><pre class="line-numbers language-lang-shell"><code class="language-lang-shell">.├── utils.py├── utils_with_main.py├── main.py└── main_2.py<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-lang-python"><code class="language-lang-python"># utils.pydef get_sum(a, b):    return a + bprint('testing')print('{} + {} = {}'.format(1, 2, get_sum(1, 2)))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-lang-python"><code class="language-lang-python"># utils_with_main.pydef get_sum(a, b):    return a + bif __name__ == '__main__':    print('testing')    print('{} + {} = {}'.format(1, 2, get_sum(1, 2)))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-lang-python"><code class="language-lang-python"># main.pyfrom utils import get_sumprint('get_sum: ', get_sum(1, 2))########## 输出 ##########testing1 + 2 = 3get_sum: 3<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-lang-python"><code class="language-lang-python"># main_2.pyfrom utils_with_main import get_sumprint('get_sum: ', get_sum(1, 2))########## 输出 ##########get_sum_2: 3<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>import</code>在导入模块时会自动将文件中的暴露代码执行一遍，对于模块的测试代码，如果我们不想在导入模块的时候执行这些代码，就要将这些代码放在<code>if __name__ == __main__</code>之下。</p>]]></content>
      
      
      <categories>
          
          <category> 编程基础 </category>
          
          <category> 编程语言 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 编程基础 </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用链表实现LRU缓存淘汰算法</title>
      <link href="/2019/10/01/shu-ju-jie-gou-yu-suan-fa/shu-ju-jie-gou/shi-yong-lian-biao-shi-xian-lru-huan-cun-tao-tai-suan-fa/"/>
      <url>/2019/10/01/shu-ju-jie-gou-yu-suan-fa/shu-ju-jie-gou/shi-yong-lian-biao-shi-xian-lru-huan-cun-tao-tai-suan-fa/</url>
      
        <content type="html"><![CDATA[<h1 id="使用链表实现LRU缓存淘汰算法"><a href="#使用链表实现LRU缓存淘汰算法" class="headerlink" title="使用链表实现LRU缓存淘汰算法"></a>使用链表实现LRU缓存淘汰算法</h1><blockquote><p>本文为<a href="https://time.geekbang.org/column/article/40036" target="_blank" rel="noopener">数据结构与算法之美-王争</a>的学习笔记，如需查看完整内容，请参考链接。</p></blockquote><p>所谓缓存，是一种提高数据读取性能的技术，在硬件设计、软件开发中有着非常广泛的应用，如CPU缓存、数据库缓存和浏览器缓存等。</p><p>当缓存被用满时，就需要对数据进行清理。这时常用的清理策略有以下三种：先进先出策略FIFO（First In, First Out）、最少使用策略LFU（Least Frequently Used）、最近最少使用策略LRU（Least Recently Used）。</p><p>那么如何使用链表来实现最近最少使用策略呢？</p><h2 id="什么是链表"><a href="#什么是链表" class="headerlink" title="什么是链表"></a>什么是链表</h2><p>链表和数组一样，是最基础的链表结构。两者的逻辑结构都是一种线性表，但两者在存储结构上存在很大的差别。我们已知在对数组进行存储时需要开辟一连串的连续内存，并向这一串内存中放入相同类型的数据。如果我们需要申请的连续的内存空间大于内存中最大的连续空间的大小，这时即时内存中总的剩余空间足够多，也会导致申请失败。如下图左侧所示（示意图来自<a href="https://time.geekbang.org/column/article/41013" target="_blank" rel="noopener">数据结构与算法之美</a>）。</p><p><img src="/2019/10/01/shu-ju-jie-gou-yu-suan-fa/shu-ju-jie-gou/shi-yong-lian-biao-shi-xian-lru-huan-cun-tao-tai-suan-fa/d5d5bee4be28326ba3c28373808a62cd.jpg" alt=""></p><p>但如果使用的是链表便可以解决这一问题。与数组不同，链表使用的是<strong>内存中零散分布的一系列内存空间</strong>，这些内存空间之间使用“<strong>指针</strong>”连接，如上图右侧所示。</p><p>常用的链表有单链表、双向链表和循环链表三种。</p><h2 id="单链表"><a href="#单链表" class="headerlink" title="单链表"></a>单链表</h2><p>在上面的描述中，我们了解到链表之间是通过指针进行连接的。那么在存储链表的过程中就需要对指针信息进行存储。在数组中，每一个位置存储的数据元素本身，而在链表中将每一个内存块称为<strong>结点</strong>。结点中除了要存储数据本身之外，还要存储链表的下一个结点的地址。将存储下个结点地址的指针称作<strong>后继指针</strong>（Next），将只有后继指针的链表称作单链表，如下图所示。</p><p><img src="/2019/10/01/shu-ju-jie-gou-yu-suan-fa/shu-ju-jie-gou/shi-yong-lian-biao-shi-xian-lru-huan-cun-tao-tai-suan-fa/b93e7ade9bb927baad1348d9a806ddeb.jpg" alt=""></p><p>与数组一样，链表同样存在查找、插入和删除操作。在数组中，由于存储空间连续，依据查找的元素的下表和偏移地址计算公式可以很方便地计算出要查找的元素的位置，算法的时间复杂度为$O(1)$；但由于元素是连续存储的，插入和删除任何一个元素都需要对后续的所有元素进行移动，时间复杂度为$O(n)$。</p><p>针对这些问题，我们可以探究一下链表的查找、插入和删除操作。首先来看插入和删除操作，对于链表中的任何一个元素，在对其进行插入和删除操作时，我们并不需要移动其后的所有元素，因为我们不需要保证链表的存储空间为连续。任何时候进行插入和删除操作都只需要考虑相邻结点的操作，因而时间复杂度为$O(n)$，如下图所示。</p><p><img src="/2019/10/01/shu-ju-jie-gou-yu-suan-fa/shu-ju-jie-gou/shi-yong-lian-biao-shi-xian-lru-huan-cun-tao-tai-suan-fa/452e943788bdeea462d364389bd08a17.jpg" alt=""></p><p>随机存储的特性降低了链表在插入和删除操作上的时间复杂度，但同时也给随机查找造成了一定的麻烦。在链表中，为了查找某一个位置的元素，只能从第一个位置开始向后遍历，直到找到对应的元素，时间复杂度为$O(n)$。</p><h2 id="循环链表"><a href="#循环链表" class="headerlink" title="循环链表"></a>循环链表</h2><p>循环链表是一种特殊的单链表，与单链表的区别在于尾结点。单链表的尾结点指向空地址，而循环链表的尾结点指向链表的头结点，呈现出一种首位相接的结构，如下图所示。</p><p><img src="/2019/10/01/shu-ju-jie-gou-yu-suan-fa/shu-ju-jie-gou/shi-yong-lian-biao-shi-xian-lru-huan-cun-tao-tai-suan-fa/86cb7dc331ea958b0a108b911f38d155.jpg" alt=""></p><p>循环链表的特点是从链尾到链头的访问非常方便，当要处理的数据具有环形结构特点时，就适合采用循环链表。</p><h2 id="双向链表"><a href="#双向链表" class="headerlink" title="双向链表"></a>双向链表</h2><p>在单链表中只有一个后继指针（next）指向后继结点，而在双向链表中，除了后继指针外还存在一个前驱指针指向（prev）指向前驱结点。</p><p><img src="/2019/10/01/shu-ju-jie-gou-yu-suan-fa/shu-ju-jie-gou/shi-yong-lian-biao-shi-xian-lru-huan-cun-tao-tai-suan-fa/cbc8ab20276e2f9312030c313a9ef70b.jpg" alt=""></p><p>在存储空间方面，因为双向链表的每一个结点都需要额外存储一个前驱指针，所以相较于单链表，双向链表会占据更过的内存空间。但正是由于有个双向指针，双向链表在解决双向遍历问题时具有明显的优势。</p><p>那么相较于单链表，双向链表更适合解决那些问题呢？</p><blockquote><p>双向链表支持$O(1)$时间复杂度内找到前驱结点，因而在某些情况下，双向链表的插入和删除操作比单链表更为高效。</p></blockquote><ul><li><p>删除操作</p><p>删除操作有两种情况：1）删除结点中等于某个给定值的结点；2）删除给定指针指向的结点。</p><p>对于第一种情况，单链表和双向链表所需的时间复杂度相同，都需要从第一个结点查找对应的结点，然后删除该结点。操作主要几种在查找对应元素上，时间复杂度为$O(n)$；对于第二种情况，我们需要找到该指针所指结点的前驱结点，单链表同样需要从第一个结点开始向后遍历。而对于双向链表来说，只需要使用前驱指针即可，时间复杂度为$O(1)$。</p></li><li><p>插入操作</p><p>与删除操作相同，当我们需要在指定结点的位置前插入一个结点时，双向链表的时间复杂度为$O(1)$，而单链表的时间复杂度为$O(n)$。</p></li></ul><p>这实际上是一种<strong>利用空间换取时间的思想</strong>。对于执行较慢的程序，可以消耗更多的内存来进行优化，而对于消耗过多内存的程序，可以通过消耗更多的时间进行优化。</p><p>将双向链表和循环链表进行结合便可以得到双向循环链表，如下图所示：</p><p><img src="/2019/10/01/shu-ju-jie-gou-yu-suan-fa/shu-ju-jie-gou/shi-yong-lian-biao-shi-xian-lru-huan-cun-tao-tai-suan-fa/d1665043b283ecdf79b157cfc9e5ed91.jpg" alt=""></p><p><strong>链表和数组的性能对比如图所示</strong>：</p><p><img src="/2019/10/01/shu-ju-jie-gou-yu-suan-fa/shu-ju-jie-gou/shi-yong-lian-biao-shi-xian-lru-huan-cun-tao-tai-suan-fa/4f63e92598ec2551069a0eef69db7168.jpg" alt=""></p><h2 id="LRU缓存淘汰算法"><a href="#LRU缓存淘汰算法" class="headerlink" title="LRU缓存淘汰算法"></a>LRU缓存淘汰算法</h2><p>LRU算法的全称是最近最少使用策略，意思就是以当前时间为基准，越少被使用的元素将越有可能被删除。可以使用有序单链表来实现，将越少被使用的元素放在链表的尾部，越多被使用的元素放在链表的头部，当缓存不足时直接从尾部删除元素即可，具体步骤如下。</p><ol><li>如果当前数据已经在链表中，遍历得到该数据对应的结点，将其从原始位置删除并移至链表的头部。</li><li>如果当前数据不在链表中：<ul><li>缓存未满，将该数据插入链表的头部。</li><li>缓存已满，删除链表尾部的元素，再将数据插入链表的头部。</li></ul></li></ol><p>该算法的时间复杂度未$O(n)$，因为无论何种情况下都要在单链表中进行查找操作，相比之下，插入和删除操作只消耗很少的时间。</p><h2 id="如何编写链表代码"><a href="#如何编写链表代码" class="headerlink" title="如何编写链表代码"></a>如何编写链表代码</h2><h3 id="使用哨兵简化实现难度"><a href="#使用哨兵简化实现难度" class="headerlink" title="使用哨兵简化实现难度"></a>使用哨兵简化实现难度</h3><p>以单链表的插入为例，如下图所示：</p><p><img src="/2019/10/01/shu-ju-jie-gou-yu-suan-fa/shu-ju-jie-gou/shi-yong-lian-biao-shi-xian-lru-huan-cun-tao-tai-suan-fa/05a4a3b57502968930d517c934347c6e.jpg" alt=""></p><p>如果要在结点p后面插入一个新的结点，只需要如下两行代码即可：</p><pre class="line-numbers language-lang-c"><code class="language-lang-c">new_node->next = p->next;p->next = new_node;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>但如果要向一个空链表插入第一个结点时，就无法使用这一代码，因为此时链表的表头指向为空。因而应该使用如下的逻辑：</p><pre class="line-numbers language-lang-c"><code class="language-lang-c">if (head == null) {  head = new_node;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>同理对于单链表中的一般结点的删除操作，只需要一行代码即可：</p><pre class="line-numbers language-lang-c"><code class="language-lang-c">p->next = p->next->next;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>但是，如果删除的结点为单链表的最后一个，就需要使用如下代码：</p><pre class="line-numbers language-lang-c"><code class="language-lang-c">if (head->next == null) {   head = null;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>也就是说，我们需要在插入和删除单链表的结点时，分别对第一个和最后一个结点进行特殊处理。为了解决代码编写时的麻烦，我们可以引入哨兵元素，所谓哨兵即为了防止操作越界。在单链表中，我们可以声明一个哨兵结点，单链表的head指针会一直指向该哨兵结点，将这种链表称为<strong>带头链表</strong>，如下图所示。</p><p><img src="/2019/10/01/shu-ju-jie-gou-yu-suan-fa/shu-ju-jie-gou/shi-yong-lian-biao-shi-xian-lru-huan-cun-tao-tai-suan-fa/7d22d9428bdbba96bfe388fe1e3368c7.jpg" alt=""></p><p>通过加入哨兵结点，便可以将链表的插入和删除操作统一起来。</p><h3 id="重点留意边界条件的处理"><a href="#重点留意边界条件的处理" class="headerlink" title="重点留意边界条件的处理"></a>重点留意边界条件的处理</h3><p>在进行软件开发中，需要特别留意代码运行时的一些边界条件是否满足。代码不仅要在一般情况下能够正常运行，还需要能够对一些异常情况进行处理。编写链表代码时常用的边界条件有以下几点：</p><ul><li>链表为空时是否工作正常。</li><li>链表中只有一个元素时是否工作正常。</li><li>链表中有两个元素时是否工作正常。</li><li>代码在处理头结点和尾结点时是否工作正常。</li></ul><h3 id="善于使用举例法和画图法"><a href="#善于使用举例法和画图法" class="headerlink" title="善于使用举例法和画图法"></a>善于使用举例法和画图法</h3><p>有些情况下，只依靠抽象的思考是无法理清代码逻辑的，这时候就需要使用举例法和画图法。比如上述所说的插入操作的三种不同情况：1）链表为空时插入；2）在表头插入；3）在两个元素之间插入。可以画图如下：</p><p><img src="/2019/10/01/shu-ju-jie-gou-yu-suan-fa/shu-ju-jie-gou/shi-yong-lian-biao-shi-xian-lru-huan-cun-tao-tai-suan-fa/4a701dd79b59427be654261805b349f8.jpg" alt=""></p><h3 id="多写多实践"><a href="#多写多实践" class="headerlink" title="多写多实践"></a>多写多实践</h3><p>无论如何，代码只有多写才能发现问题。正所谓孰能生巧。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="https://time.geekbang.org/column/article/40036" target="_blank" rel="noopener">数据结构与算法之美-王争</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 数据结构 </category>
          
          <category> 编程基础 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 编程基础 </tag>
            
            <tag> 数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>最好、最坏、平均和均摊时间复杂度</title>
      <link href="/2019/09/27/shu-ju-jie-gou-yu-suan-fa/suan-fa/zui-hao-zui-pi-ping-jun-he-jun-tan-shi-jian-fu-za-du/"/>
      <url>/2019/09/27/shu-ju-jie-gou-yu-suan-fa/suan-fa/zui-hao-zui-pi-ping-jun-he-jun-tan-shi-jian-fu-za-du/</url>
      
        <content type="html"><![CDATA[<h1 id="最好、最坏、平均和均摊时间复杂度"><a href="#最好、最坏、平均和均摊时间复杂度" class="headerlink" title="最好、最坏、平均和均摊时间复杂度"></a>最好、最坏、平均和均摊时间复杂度</h1><p>本文为<a href="https://time.geekbang.org/column/article/40036" target="_blank" rel="noopener">数据结构与算法之美-王争</a>的学习笔记，如需查看完整内容，请参考链接。</p><h2 id="不同情况下具有不同的时间复杂度"><a href="#不同情况下具有不同的时间复杂度" class="headerlink" title="不同情况下具有不同的时间复杂度"></a>不同情况下具有不同的时间复杂度</h2><p>考虑如下代码：</p><pre class="line-numbers language-lang-c"><code class="language-lang-c">// n 表示数组 array 的长度int find(int[] array, int n, int x) {  int i = 0;  int pos = -1;  for (; i < n; ++i) {    if (array[i] == x) {       pos = i;       break;    }  }  return pos;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>上述代码的功能是在一个数组中查找指定的元素。对于这一段程序有以下几种情况：</p><ul><li>所查找的元素位于数组的首位，那么<code>for</code>循环中的程序只需运行一次，该算法的时间复杂度为$O(1)$。</li><li>所查找的元素位于数组的末位或者不存在于数组中，那么<code>for</code>循环需要执行n次，该算法的时间复杂度为$O(n)$。</li><li>所查找的元素既不位于首位也不位于末位，属于一般的情况。</li></ul><p>对于这一类的程序，我们无法简单地判定代码地时间复杂度，为了解决这一问题，需要引入<strong>最好情况时间复杂度</strong>、<strong>最坏情况时间复杂度</strong>和<strong>平均情况时间复杂度</strong>的概念。</p><p>所谓最好情况时间复杂度，即在最理想的情况下，这段代码的时间复杂度；而相应的最坏情况时间复杂度就是最坏的情况下这段代码的时间复杂度。这两种情况的发生概率都不大，因而我们<strong>重点关注平均情况时间复杂度</strong>。</p><h2 id="平均情况时间复杂度"><a href="#平均情况时间复杂度" class="headerlink" title="平均情况时间复杂度"></a>平均情况时间复杂度</h2><p>对于刚才的程序，假设元素出现在数组中的任何一个位置（0~n-1）和不在数组中这n中情况的概率相同，那么查找次数的期望为：</p><p><img src="/2019/09/27/shu-ju-jie-gou-yu-suan-fa/suan-fa/zui-hao-zui-pi-ping-jun-he-jun-tan-shi-jian-fu-za-du/d889a358b8eccc5bbb90fc16e327a22f.jpg" alt=""></p><p>忽略系数、低阶、常量，得到的平均时间复杂度为$O(n)$。</p><p>在上述分析过程中，我们使用了加权平均值，也叫期望值，所以平均情况时间复杂度也可称为<strong>加权平均时间复杂度</strong>。实际上，上述n中情况发生的概率不一定相同，但最终得到的时间复杂度是正确的。</p><h2 id="均摊时间复杂度"><a href="#均摊时间复杂度" class="headerlink" title="均摊时间复杂度"></a>均摊时间复杂度</h2><p>实际上，在一般的算法时间度分析时，我们不需要区分最好、最坏、平均三种复杂度。平均复杂度只在某些特殊情况下才会用到，而均摊时间复杂度应用的场景更为特殊。</p><p>以下述代码为例：</p><pre class="line-numbers language-lang-c"><code class="language-lang-c"> // array 表示一个长度为 n 的数组 // 代码中的 array.length 就等于 n int[] array = new int[n]; int count = 0; void insert(int val) {    if (count == array.length) {       int sum = 0;       for (int i = 0; i < array.length; ++i) {          sum = sum + array[i];       }       array[0] = sum;       count = 1;    }    array[count] = val;    ++count; }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这段代码实现的功能为向数组中插入元素，当数组满时，对数组中的元素进行遍历求和，将求和结果放到数组的第一个位置，并将要插入的元素放到数组的第二个位置。</p><p>在最好的情况下，数组中还有空位，程序只需运行一次，因而时间复杂度为$O(1)$；最坏的情况下，数组已满，则需要执行<code>for</code>循环，时间复杂度为$O(n)$。</p><p>数组中还有空位的情况共有n种，每一种的时间复杂度都为$O(1)$，除此之外，当数组已满时，时间复杂度为$O(n)$。在插入一个元素时，这$n+1$种情况具有同等的概率，加权平均后得：</p><p><img src="/2019/09/27/shu-ju-jie-gou-yu-suan-fa/suan-fa/zui-hao-zui-pi-ping-jun-he-jun-tan-shi-jian-fu-za-du/6df62366a60336d9de3bc34f488d8bed.jpg" alt=""></p><p>因此该算法的平均时间复杂度为$O(1)$。</p><p>实际上，上述分析过程偏复杂，<code>insert()</code>函数和<code>find()</code>函数存在很大的不同：</p><ul><li><code>find()</code>函数在极端情况下时间复杂度为$O(1)$，而<code>insert()</code>函数在大多数情况下时间复杂度都是$O(1)$。</li><li><code>insert()</code>函数的$O(1)$和$O(n)$时间复杂度存在一定的次序，一个$O(n)$时间复杂度后紧跟n-1个$O(1)$时间复杂度。</li></ul><p>因此，我们不需要像平均时间复杂度分析那样，找出每一种情况的发生概率，再求加权平均。为此，引入一种称为<strong>摊还分析法</strong>的分析方法。</p><p>摊还分析法的大体思路如下：在上述插入程序中，一个$O(n)$时间复杂度后紧跟n-1个$O(1)$时间复杂度，因而可以直接将$O(n)$时间复杂度平摊到后续的n-1个耗时少的操作上，这样一组连续的操作的均摊时间复杂度就是$O(1)$。</p><p>均摊分析法适用于以下场景：在对一个数据结构进行一系列操作时，大部分情况下时间复杂度都很低，只有个别情况下时间复杂度比较高，并且，这些操作之间通常存在前后连贯的操作关系。因而，可以将这一系列的操作放在一起进行分析，看是否可以将耗时高的操作的耗时均摊到耗时低的操作上。</p><p>一般能应用均摊时间复杂度的场合，均摊时间复杂度就等于最好情况时间复杂度。</p><h2 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h2><p>一段算法如下：</p><pre class="line-numbers language-lang-c"><code class="language-lang-c">// 全局变量，大小为 10 的数组 array，长度 len，下标 i。int array[] = new int[10]; int len = 10;int i = 0;// 往数组中添加一个元素void add(int element) {   if (i >= len) { // 数组空间不够了     // 重新申请一个 2 倍大小的数组空间     int new_array[] = new int[len*2];     // 把原来 array 数组中的数据依次 copy 到 new_array     for (int j = 0; j < len; ++j) {       new_array[j] = array[j];     }     // new_array 复制给 array，array 现在大小就是 2 倍 len 了     array = new_array;     len = 2 * len;   }   // 将 element 放到下标为 i 的位置，下标 i 加一   array[i] = element;   ++i;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在这段往数组中添加元素的代码中</p><ul><li><p>最好的情况是数组空间充足，那么时间复杂度为$O(1)$；</p></li><li><p>最坏的情况是，数组已满，那么需要对数组进行拷贝，此时数组的大小会增加一倍，假设某次添加前数组的大小为n（因为数组是变长的，所以只能假设），那么时间复杂度为$O(n)$；</p></li><li><p>平均：添加元素之前数组未满，此种情况有n（剩余n个空位）种，时间复杂度都是$O(1)$；数组已满，时间复杂度为$O(n)$，在添加元素之前，这n+1种情况的概率是相同的，因而平均时间复杂度为$O(1)$。</p><script type="math/tex; mode=display">\frac{1}{n+1}O(1)+\frac{1}{n+1}O(1)+...+\frac{1}{n+1}O(1)+\frac{1}{n+1}O(n)=\frac{n}{n+1}O(1)+\frac{1}{n+1}O(n)=O(1)</script></li><li><p>对于均摊时间复杂度，每数组复制之后都会接着n次耗时少的插入，因而均摊时间复杂度为$O(1)$。</p></li></ul><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="https://time.geekbang.org/column/article/40447" target="_blank" rel="noopener">数据结构与算法之美</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
          <category> 编程基础 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 编程基础 </tag>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>神经网络中的优化方法</title>
      <link href="/2019/09/18/shen-du-xue-xi/ji-chu-zhi-shi/shen-jing-wang-luo-de-you-hua/"/>
      <url>/2019/09/18/shen-du-xue-xi/ji-chu-zhi-shi/shen-jing-wang-luo-de-you-hua/</url>
      
        <content type="html"><![CDATA[<h1 id="神经网络的优化"><a href="#神经网络的优化" class="headerlink" title="神经网络的优化"></a>神经网络的优化</h1><p>我们在使用神经网络时会面临一些难点，这些难点主要可分为以下两大类：</p><ol><li>优化问题：神经网络模型是一个非凸函数，再加上在深度网络中的梯度消失问题，很难进行优化；另外，深层神经网络模型一般参数比较多，训练数据也比较大，会导致训练的效率比较低 。</li><li>泛化问题：神经网络具有很强的拟合能力，因而很容易在训练集上产生过拟合。在训练神经网络时，需要采取一定的正则化方法来改进网络的泛化能力。</li></ol><h2 id="网络优化"><a href="#网络优化" class="headerlink" title="网络优化"></a>网络优化</h2><p>在对神经网络进行优化时存在一些难点，主要有以下几点：</p><ul><li><p><strong>网络结构多样</strong></p><p>神经网络具有非常多样的结构，我们无法找到一种通用的优化方法来解决所有网络上的参数优化问题。</p></li><li><p><strong>高维变量非凸优化</strong></p><p>在低维优化问题中，要解决的问题主要是如何逃离局部最优值。而在高维空间中，所面临的是另一种问题，即如何逃离<strong>鞍点</strong>（Saddle Point）。鞍点处的的梯度为0，但在一些维度上是最高点、在另一些维度上是最低点，如图所示：</p><p><img src="/2019/09/18/shen-du-xue-xi/ji-chu-zhi-shi/shen-jing-wang-luo-de-you-hua/1568453885312.png" alt="鞍点示意"></p><p>在高维空间中，大部分梯度为0的点都是鞍点。基于梯度下降的优化方法在鞍点附近会处于停滞状态，很难从这些鞍点逃离。</p></li><li><p><strong>平坦的底部</strong></p><p>神经网络的参数非常多，且参数之间存在一定的冗余性，因而每一个参数对于最终的损失的影响都非常小，损失函数在局部最优点附近表现为一个平坦的区域，称为<strong>平坦最小值</strong>。</p></li></ul><p><img src="/2019/09/18/shen-du-xue-xi/ji-chu-zhi-shi/shen-jing-wang-luo-de-you-hua/1568454107662.png" alt="神经网络中的平坦底部"></p><p>目前，神经网络所使用的参数优化方法主要是基于梯度下降来寻找一组可以最小化结构风险的参数。可以将梯度下降法分为：</p><ul><li>随机梯度下降（每次只使用一个样本进行梯度计算）</li><li>批量梯度下降（每次使用所有的样本进行梯度计算）</li><li>小批量梯度下降（每次使用小批量的样本进行梯度计算）</li></ul><h2 id="小批量梯度下降（mini-batch）"><a href="#小批量梯度下降（mini-batch）" class="headerlink" title="小批量梯度下降（mini-batch）"></a>小批量梯度下降（mini-batch）</h2><p>影响小批量梯度下降算法的因素主要有三个：<strong>学习率</strong>、<strong>小批量的大小</strong>以及<strong>参数更新方向</strong>。</p><ul><li><p><strong>批量大小的选择</strong></p><p>批量大小一般不会影响随机梯度的期望，但对随机梯度的方差有较大影响。批量大小越大，随机梯度的方差越小，引入的噪声也越小，训练也越稳定，因此可以设置较大的学习率。反之，当批量大小越小时，需要设置较小的学习率，否则模型会不收敛。</p><p>学习率通常要随着批量大小的增加而相应的增大，一个常用的方法是<strong>线性缩放规则</strong>，即学习率和批量大小以同等的倍数增大。要注意的是，线性缩放规则在批量大小较小时适用，当批量大小非常大时，线性缩放会使得训练不稳定。</p></li><li><p><strong>学习率调整</strong></p><p>学习率的调整非常重要，过大导致训练不收敛，过小导致训练收敛缓慢。常用的学习率调整方法包括学习率衰减、学习率预热、周期学习率和自适应学习率调整方法等。</p><p>常见的<strong>学习率衰减方法</strong>有：</p><ol><li><p><strong>分段常数衰减</strong>（Piecewise Constant Decay）：每经过$T_1,T_2,…T_m$次训练迭代，分别将学习率衰减为原来的$\beta_1, \beta_2,…,\beta_m$倍，也称为步衰减（Step Decay）。</p></li><li><p><strong>逆时衰减</strong>（Inverse Time Decay）：</p><script type="math/tex; mode=display">\alpha_{t}=\alpha_{0} \frac{1}{1+\beta \times t}</script></li><li><p><strong>指数衰减</strong>（Exponential Decay）：</p><script type="math/tex; mode=display">\alpha_{t}=\alpha_{0} \beta^{t},\ \ \ \beta<1</script></li><li><p><strong>自然指数衰减</strong>（Natural Exponential Decay）：</p><script type="math/tex; mode=display">\alpha_{t}=\alpha_{0} \beta^{t}</script></li><li><p><strong>余弦衰减</strong>（Cosine Decay）：</p><script type="math/tex; mode=display">\alpha_{t}=\alpha_{0} \exp (-\beta \times t)</script></li></ol><p>不同的学习率衰减方法的示意图如下所示：</p></li></ul><p><img src="/2019/09/18/shen-du-xue-xi/ji-chu-zhi-shi/shen-jing-wang-luo-de-you-hua/1568456615851.png" alt="学习率衰减示意图"></p><p>​    除了使用学习率衰减方法之外，在训练的开始阶段常用的学习率调整方法还有<strong>学习率预热</strong>：</p><p>​    使用学习率预热的原因在于，在一开始时由于网络的参数是随机初始化的，因而梯度也比较大，这时候如果同    时采用较大的初始学习率会导致训练不稳定。因而我们可以在开始的几轮迭代中使用较小的学习率进行预热，    当梯度下降到一定梯度时再恢复初始学习率。</p><p>​    在学习率调整方法中，一种常用的方法还有周期性学习率调整：为了使得梯度下降方法能够逃离局部最小点，    一种经验性的方式是在训练过程中周期性地增大学习率。增加学习率短期内会损害网络的收敛稳定性，但从长    期来看有助于找到更好的局部最优解。主要有两种周期性学习率调整方法：循环学习率、带热重启的随机梯度    下降。所谓循环学习率即让学习率在一个区间内周期性地增大和缩小，每个周期的学习率的上界和下界可以随    着循环周期数的增大而减小：</p><p><img src="/2019/09/18/shen-du-xue-xi/ji-chu-zhi-shi/shen-jing-wang-luo-de-you-hua/1568535431591.png" alt="三角循环学习率"></p><p>​    所谓带热重启的随机梯度下降指的是：学习率每隔一定周期后重新初始化为某个预设值，然后逐渐衰减，每次    重启后模型参数不是从头开始优化，而是从重启前的参数基础上继续优化：</p><p><img src="/2019/09/18/shen-du-xue-xi/ji-chu-zhi-shi/shen-jing-wang-luo-de-you-hua/1568535554582.png" alt="带热重启的随机梯度下降"></p><p>除了上述的学习率调整方法之外，还有一些自适应的学习率调整方法。</p><h3 id="自适应学习率调整"><a href="#自适应学习率调整" class="headerlink" title="自适应学习率调整"></a>自适应学习率调整</h3><p>在自适应学习率调整中，调整对象为各个参数各自的学习率。</p><h4 id="AdaGrad算法"><a href="#AdaGrad算法" class="headerlink" title="AdaGrad算法"></a>AdaGrad算法</h4><p>在标准的梯度下降算法中，每个参数在每次迭代时都使用相同的学习率。但实际上，对于每个参数来说，在每一迭代中是具有不同的梯度的，因而统一采用相同的学习率并不合适。自适应学习率调整方法便是被用来解决这一问题的。</p><p>AdaGrad（Adaptive Gradient）算法[Duchi et al.，2011]借鉴$l_2$正则化思想，<strong>在每次迭代时自适应地调整每个参数的学习率</strong>：</p><ol><li><p>在第$t$次迭代时，首先计算每一个参数各自的梯度平方的累积和：</p><script type="math/tex; mode=display">G_{t}=\sum_{\tau=1}^{t} g_{\tau} \odot g_{\tau}</script></li><li><p>接着，依据各个参数各自的梯度平方累计和的大小计算当前迭代所使用的梯度：</p><script type="math/tex; mode=display">\Delta \theta_t=-\frac{\alpha}{\sqrt{G_t+\epsilon}}\odot g_t</script></li></ol><p>在AdaGrad算法中，如果某个参数的偏导数累计比较大，其学习率相对较小；相反，如果其偏导数较小，其学习率相对较大。但整体上，各个参数的学习率随着迭代次数的增加而逐渐减小。</p><p>该算法的缺点是，在经过一定次数的迭代后，如果仍旧没有找到最优点，由于此时的学习率非常小，很难再继续找到最优点。</p><h4 id="RMSprop算法"><a href="#RMSprop算法" class="headerlink" title="RMSprop算法"></a>RMSprop算法</h4><p>该算法由Geoff Hinton提出，可以在有些情况下避免AdaGrad算法中学习率不断单调下降以至于过早衰减的缺点。该算法中首先计算每次迭代梯度$g_t$平方的指数衰减移动平均：</p><p><img src="/2019/09/18/shen-du-xue-xi/ji-chu-zhi-shi/shen-jing-wang-luo-de-you-hua/1568687020682.png" alt=""></p><p>其中$\beta$为衰减率，一般取值为0.9。</p><p>参数的更新差值为：</p><p><img src="/2019/09/18/shen-du-xue-xi/ji-chu-zhi-shi/shen-jing-wang-luo-de-you-hua/1568687091725.png" alt=""></p><p>该算法与AdaGrad的区别在于，$G_t$的计算方式由平方累计和变为了指数衰减移动平均。</p><h4 id="AdaDelta算法"><a href="#AdaDelta算法" class="headerlink" title="AdaDelta算法"></a>AdaDelta算法</h4><p>该算法也属于AdaGrad算法的一个改进，该算法除了使用梯度的指数衰减移动平均来调整学习率之外，还引入了每次参数更新的差值$\Delta \theta$的指数衰减移动平均。</p><p>在第$t$次迭代时，每次参数更新差$\Delta \theta_\tau$，$1\leq \tau \geq t-1$的平方的指数衰减权移动平均为：</p><script type="math/tex; mode=display">\Delta X_{t-1}^2=\beta_1\Delta X_{t-2}^2+(1-\beta_1)\Delta \theta_{t-1} \odot \Delta \theta_{t-1}</script><p>其中$\beta_1$为衰减率。在此基础上，参数的更新差值为：</p><script type="math/tex; mode=display">\Delta \theta_t=-\frac{\sqrt{\Delta X_{t-1}^2}+\epsilon}{\sqrt{G_t}+\epsilon}g_t</script><p>AdaDelta算法将RMSprop算法中的初始学习率改为动态计算，在一定程度上抑制了学习率的波动。</p><h3 id="更新方向的优化"><a href="#更新方向的优化" class="headerlink" title="更新方向的优化"></a>更新方向的优化</h3><p>除了对学习率进行优化之外，我们还可以对参数的更新方向即梯度进行优化。为了缓解在样本数量较少时所导致的梯度震荡问题，可以使用最近一段时间的平均梯度来替代当前时刻的梯度，并提高优化速度，即<strong>动量法</strong>。</p><h4 id="动量法"><a href="#动量法" class="headerlink" title="动量法"></a>动量法</h4><p>所谓动量，指的是物理中一个物体在其运动方向上保持运动的趋势，是物体的质量和速度的乘积。所谓动量法（Momentum Method）是用之前积累动量来替代真正的梯度，每次迭代的梯度可以看作加速度。</p><p>在第t次迭代时，计算<strong>负梯度</strong>的“加权移动平均”作为当前参数的更新方向：</p><script type="math/tex; mode=display">\Delta\theta_t=\rho\Delta\theta_{t-1}-\alpha g_t=-\alpha \sum_\tau^t\rho^{t-\tau}g_{\tau}</script><p>这样，每个参数的实际更新差值取决于最近一段时间内梯度的加权平均值。当某个参数在最近一段时间内的梯度方向不一致时，其真实的参数更新幅度变小；相反，当在最近一段时间内的梯度方向都一致时，其真实的参数更新幅度变大，起到加速作用。一般而言，在迭代初期，梯度方向都比较一致，动量法会起到加速作用，可以更快地到达最优点。在迭代后期，梯度方向会不一致，在收敛值附近震荡，动量法会起到减速作用，增加稳定性。</p><h4 id="Nesterov加速梯度"><a href="#Nesterov加速梯度" class="headerlink" title="Nesterov加速梯度"></a>Nesterov加速梯度</h4><p>Nesterov加速梯度法是对动量法的一种改进，在动量法中，实际的参数更新方向$\Delta\theta_t$可以被拆分为两步，第一步是先根据$\Delta\theta_{t-1}$更新一次得到参数$\hat \theta$，再使用$g_t$进行更新：</p><p><img src="/2019/09/18/shen-du-xue-xi/ji-chu-zhi-shi/shen-jing-wang-luo-de-you-hua/1568773120967.png" alt=""></p><p>在第二步更新中，梯度$g_t$为$\theta_{t-1}$上的梯度，按照梯度下降法来说，应该是$\hat \theta$上的梯度。依照这种思路，合并后的更新方向为：</p><p><img src="/2019/09/18/shen-du-xue-xi/ji-chu-zhi-shi/shen-jing-wang-luo-de-you-hua/1568773274360.png" alt=""></p><p>Nesterov加速梯度与动量法在参数更新方向上的比较：</p><p><img src="/2019/09/18/shen-du-xue-xi/ji-chu-zhi-shi/shen-jing-wang-luo-de-you-hua/1568773378763.png" alt=""></p><h4 id="Adam算法"><a href="#Adam算法" class="headerlink" title="Adam算法"></a>Adam算法</h4><p>自适应动量估计（Adaptive Moment Estimation, Adam）算法可以看作动量法和RMSprop学习率更新算法的结合，在<strong>使用动量作为参数更新方向</strong>的同时，<strong>对学习率进行自适应调整</strong>。</p><p>Adam算法一方面计算梯度平方的指数加权平均，另一方面计算梯度的指数加权平均：</p><p><img src="/2019/09/18/shen-du-xue-xi/ji-chu-zhi-shi/shen-jing-wang-luo-de-you-hua/1568773826547.png" alt=""></p><p><img src="/2019/09/18/shen-du-xue-xi/ji-chu-zhi-shi/shen-jing-wang-luo-de-you-hua/1568773835231.png" alt=""></p><p>其中$\beta_1,\beta_2$为两个指数加权平均的衰减率，通常取值为$\beta_1=0.9,\beta_2=0.99$。</p><p>梯度的指数加权平均$M_t$可以被看作梯度的均值（一阶矩），梯度的平方的指数加权平均可以被看作梯度的未减去均值的方差（二阶矩）。</p><p>假设$M_0=0,G_0=0$，那么在迭代初期两者的值会比真实的均值和方差要小。特别是当两个衰减率接近于1时，偏差会很大，因而需要对偏差进行修正：</p><p><img src="/2019/09/18/shen-du-xue-xi/ji-chu-zhi-shi/shen-jing-wang-luo-de-you-hua/1568774196413.png" alt=""></p><p>最终，Adam算法的参数更新值为：</p><p><img src="/2019/09/18/shen-du-xue-xi/ji-chu-zhi-shi/shen-jing-wang-luo-de-you-hua/1568774234393.png" alt=""></p><p>其中，学习率通常设置为0.001，也可以进行衰减。</p><p>既然，Adam算法是RMSprop算法和动量法的结合，那么自然也可以将RMSprop算法和Nesterov加速度算法进行结合，即Nadam算法。</p><h3 id="梯度截断"><a href="#梯度截断" class="headerlink" title="梯度截断"></a>梯度截断</h3><p>在深度神经网络的训练过程中，除了梯度消失之外，梯度爆炸是影响学习效率的主要因素。在梯度下降算法中，如果梯度突然增大，将导致模型远离最优点。因而，当梯度大于一定值时，需要对梯度进行截断，即梯度阶段（gradient clipping）。</p><p>梯度截断一般有以下两种方法：</p><ul><li><p>按值截断</p><p>将参数的梯度限制在一个区间内，按照区间的端点进行截断。</p></li><li><p>按模截断</p><p>将参数的梯度的模值限制在一个给定的阈值下，当参数的梯度的模值小于该阈值时，梯度保持不变，大于该阈值时，令：</p><p><img src="/2019/09/18/shen-du-xue-xi/ji-chu-zhi-shi/shen-jing-wang-luo-de-you-hua/1568774686577.png" alt=""></p></li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>总的来说，可以将优化算法划分为两类：一类是调整学习率；另一类是调整参数优化方向。总结为公式如下：</p><p><img src="/2019/09/18/shen-du-xue-xi/ji-chu-zhi-shi/shen-jing-wang-luo-de-you-hua/1568775024667.png" alt=""></p><p>其中，$g_t$为第$t$步的梯度，$\alpha_t$为第$t$步的学习率，可以衰减也可以不变。依据参数优化方向和学习率调整方法的不同，可以将优化方法划分为下表所示：</p><p><img src="/2019/09/18/shen-du-xue-xi/ji-chu-zhi-shi/shen-jing-wang-luo-de-you-hua/1568775165104.png" alt="神经网络常用优化方法"></p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="https://github.com/nndl/nndl.github.io" target="_blank" rel="noopener">邱锡鹏-《神经网络与深度学习》</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
          <category> 基础知识 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 基础知识 </tag>
            
            <tag> 常见知识 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>神经网络中的归一化操作</title>
      <link href="/2019/09/14/shen-du-xue-xi/ji-chu-zhi-shi/shen-jing-wang-luo-zhong-de-gui-yi-hua/"/>
      <url>/2019/09/14/shen-du-xue-xi/ji-chu-zhi-shi/shen-jing-wang-luo-zhong-de-gui-yi-hua/</url>
      
        <content type="html"><![CDATA[<h1 id="神经网络中的归一化操作"><a href="#神经网络中的归一化操作" class="headerlink" title="神经网络中的归一化操作"></a>神经网络中的归一化操作</h1><h2 id="内部协变量偏移（Internal-Covariate-Shift）"><a href="#内部协变量偏移（Internal-Covariate-Shift）" class="headerlink" title="内部协变量偏移（Internal Covariate Shift）"></a>内部协变量偏移（Internal Covariate Shift）</h2><p>在介绍归一化操作之前，我们需要了解什么是内部协变量偏移。首先，协变量偏移是数据分布不一致性的一种表现。已知贝叶斯公式：</p><script type="math/tex; mode=display">p(\mathbf{x}, y)=p(\mathbf{x} | y) p(y)=p(y | \mathbf{x}) p(\mathbf{x})</script><p>所谓协变量偏移指的是：源领域和目标领域的输入边际分布不同$p_{S}(\mathbf{x}) \neq p_{T}(\mathbf{x})$，但两者的后验分布相同$p_{S}(y | \mathbf{x})=p_{T}(y | \mathbf{x})$，即学习任务相同。</p><p>而在深度神经网络中，中间某一层的输入是其之前的神经层的输出。因此，其之前的神经层的参数变化会导致其输入的分布发生较大的差异。在使用随机梯 度下降来训练网络时，每次参数更新都会导致网络中间每一层的输入的分布发 生改变。越深的层，其输入的分布会改变得越明显。就像一栋高楼，低楼层发生一个较小的偏移，都会导致高楼层较大的偏移。</p><p>从机器学习的角度来看，如果某一层网络的输入的分布发生了变化，那么其参数就需要重新学习，我们将这种现象称为内部协变量偏移。归一化便是一种被用来解决内部协变量偏移的方法。归一化方法的引入可以使得每一个神经层的输入的分布在训练过程中保持一致。</p><h2 id="梯度弥散问题"><a href="#梯度弥散问题" class="headerlink" title="梯度弥散问题"></a>梯度弥散问题</h2><p>所谓梯度弥散，指的是，梯度在反向传播过程中由于网络太深或者网络激活值位于激活函数的饱和区而消失，深层的梯度无法顺利传播到神经网络的浅层，进而导致神经网络无法正常训练。</p><p><img src="/2019/09/14/shen-du-xue-xi/ji-chu-zhi-shi/shen-jing-wang-luo-zhong-de-gui-yi-hua/1568275983687.png" alt="sigmoid及其梯度示意"></p><p>如上图常用的sigmoid激活函数，虚线为导数。可以看出，当函数输入位于饱和区时，梯度将保持为0。那么如何解决这一现象呢？一种做法是在网络的结构上做文章，例如ResNet中引入了跨层连接，梯度可以通过跨层连接传入底层网络层；另一种做法就是将激活函数的输入限制在非饱和区。</p><p><img src="/2019/09/14/shen-du-xue-xi/ji-chu-zhi-shi/shen-jing-wang-luo-zhong-de-gui-yi-hua/1568276150912.png" alt="归一化对激活函数的影响"></p><p>通过使用归一化操作便可以达到这一目的。对网络层的输入进行归一化后，输入的数值便被限制在较小的区间进而保证了输入不会进入激活函数的饱和区。</p><p>以下为几种常用的逐层归一化方法，所谓逐层归一化指的是可以被应用在深度神经网络的任何一个中间层。<strong>在实际应用中，并不需要对所有的网络层进行归一化</strong>。</p><h2 id="批量归一化（Batch-Normalization-BN）"><a href="#批量归一化（Batch-Normalization-BN）" class="headerlink" title="批量归一化（Batch Normalization, BN）"></a>批量归一化（Batch Normalization, BN）</h2><p>批量归一化方法由$[Ioffe \ and\ Szegedy, 2015]$提出，是一种有效的逐层归一化方法。对于一个深层神经网络，令第$l$层的净输入为$z^{(l)}$，神经元的输出为$a^{l}$，即：</p><script type="math/tex; mode=display">\mathbf{a}^{(l)}=f\left(\mathbf{z}^{(l)}\right)=f\left(W \mathbf{a}^{(l-1)}+\mathbf{b}\right)</script><p>其中$f()$是激活函数，$W$和$b$为可学习参数。</p><p>为了解决内部协变量偏移问题，就要使得网络层的净输入$z{(l)}$的分布一致。在实际应用中，归一化操作常应用在仿射变换之后，激活函数之前，这么做的原因在于输入的分布性质不如净输入稳定。</p><p>逐层归一化需要在中间层进行，因而需要有较高的效率，不适合使用复杂度较高的归一化方法，一般使用标准归一化方法，将净输入$z{(l)}$的<strong>每一个维度</strong>都归一化到标准正态分布。</p><script type="math/tex; mode=display">\hat{\mathbf{z}}^{(l)}=\frac{\mathbf{z}^{(l)}-\mathbb{E}\left[\mathbf{z}^{(l)}\right]}{\sqrt{\operatorname{var}\left(\mathbf{z}^{(l)}\right)+\epsilon}}</script><p>其中的均值$\mathbb{E}\left[\mathbf{z}^{(l)}\right]$和方差$var(z^{(l)})$是在当前网络参数下，$z^{(l)}$的每一维在整个训练集上的期望和方差。但实际上，我们是无法计算整个数据集上的统计量的，<strong>只能使用当前小批量数据集的均值和方差进行估计</strong>。给定包含$K$个样本的小批量样本集合，计算第$l$层神经元的净输入$z^{(1,l)},…,z^{(K,l)}$的均值和方差：</p><script type="math/tex; mode=display">\begin{aligned} \mu_{\mathcal{B}} &=\frac{1}{K} \sum_{k=1}^{K} \mathbf{z}^{(k, l)} \end{aligned}</script><script type="math/tex; mode=display">\sigma_{\mathcal{B}}^{2} =\frac{1}{K} \sum_{k=1}^{K}\left(\mathbf{z}^{(k, l)}-\mu_{\mathcal{B}}\right) \odot\left(\mathbf{z}^{(k, l)}-\mu_{\mathcal{B}}\right)</script><p>但是，直接将网络层的净输入归一化到$[-1,1]$区间会使得激活函数的取值区间限制在线性变换区间内，减弱了神经网络的非线性性质。因此，为了使得归一化不对网络的表示能力造成负面影响，可以通过一个附加的缩放和平移变换改变取值区间。</p><script type="math/tex; mode=display">\begin{aligned} \hat{\mathbf{z}}^{(l)} &=\frac{\mathbf{z}^{(l)}-\mu_{\mathcal{B}}}{\sqrt{\sigma_{\mathcal{B}}^{2}+\epsilon}} \odot \gamma+\beta \\ & \triangleq \mathrm{BN}_{\gamma, \beta}\left(\mathbf{z}^{(l)}\right) \end{aligned}</script><p>其中$\gamma$和$\beta$分别表示缩放因子和平移因子。在实际应用中，这两个参数常被设置为可学习参数。</p><p>我们可以将批量归一化层看作一个特殊的神经层，加载每一层非线性激活函数之前：</p><script type="math/tex; mode=display">\mathbf{a}^{(l)}=f \left(\mathrm{BN}_{\gamma, \beta}\left(\mathbf{z}^{(l)}\right)\right)</script><script type="math/tex; mode=display">\mathbf{z^{(l)}}=f\left(\mathrm{BN}_{\gamma, \beta} \left(W \mathbf{a}^{(l-1)}\right)\right)</script><p>这里有一个很重要的性质:</p><blockquote><p>因为批量归一化层本身有平移变化参数，因而仿射变化可以不加偏置参数。</p></blockquote><h3 id="实际计算细节"><a href="#实际计算细节" class="headerlink" title="实际计算细节"></a>实际计算细节</h3><p>各种归一化方法的区别在于，按照特征图的哪一个维度计算均值和方差。</p><h4 id="批量归一化（Batch-Normalization-BN）-1"><a href="#批量归一化（Batch-Normalization-BN）-1" class="headerlink" title="批量归一化（Batch Normalization, BN）"></a>批量归一化（Batch Normalization, BN）</h4><p>在卷积神经网络中，设一个层的特征图的大小为$x\in R^{N\times C \times H \times W}$，包含$N$个样本，每个样本有$C$个通道、高为$H$、宽为$W$。现在，我们要对该特征图求均值和方差，<strong>计算方式为按照通道$C$分别计算各个通道的均值和方差</strong>，计算完成后对于该层特征图，将得到$C$个均值和$C$个方差。</p><script type="math/tex; mode=display">\begin{array}{c}{\mu_{c}(x)=\frac{1}{N H W} \sum_{n=1}^{N} \sum_{h=1}^{H} \sum_{w=1}^{W} x_{n c h w}}\end{array}</script><script type="math/tex; mode=display">{\sigma_{c}(x)=\sqrt{\frac{1}{N H W} \sum_{n=1}^{N} \sum_{h=1}^{H} \sum_{w=1}^{W}\left(x_{n c h w}-\mu_{c}(x)\right)^{2}+\epsilon}}</script><p>表示如下图所示：</p><p><img src="/2019/09/14/shen-du-xue-xi/ji-chu-zhi-shi/shen-jing-wang-luo-zhong-de-gui-yi-hua/v2-cc921c4c597e89a862785a842b0c4293_1200x500.jpg" alt="批量归一化示意图"></p><p>正如上图中的Batch Norm所示，<strong>通道之间独立计算</strong>是批量归一化的核心。</p><h4 id="层归一化（Layer-Normalization-LN）"><a href="#层归一化（Layer-Normalization-LN）" class="headerlink" title="层归一化（Layer Normalization, LN）"></a>层归一化（Layer Normalization, LN）</h4><p>正如上一小节所述，每一个通道的均值和方差需要使用mini-batch中的所有样本的对应通道的值计算得到，当batch-size较小时，各个通道的均值和方差的偏差将比较大。且当训练样本的大小不同（例如RNN模型）时，无法进行合理计算。为了解决这一问题，提出了层归一化方法。</p><p>所谓层归一化，即<strong>按照样本数$N$分别计算各个样本的均值和方差</strong>，计算完成后，对于该层特征图将得到$N$个均值和$N$个方差。</p><script type="math/tex; mode=display">\begin{array}{c}{\mu_{n}(x)=\frac{1}{C H W} \sum_{c=1}^{C} \sum_{h=1}^{H} \sum_{w=1}^{W} x_{n c h w}}\end{array}</script><script type="math/tex; mode=display"> {\sigma_{n}(x)=\sqrt{\frac{1}{C H W} \sum_{c=1}^{C} \sum_{h=1}^{H} \sum_{w=1}^{W}\left(x_{n c h w}-\mu_{n}(x)\right)^{2}+\epsilon}}</script><p>同样参考之前的示意图，<strong>样本之间独立计算</strong>是层归一化的核心。</p><h4 id="实例归一化（Instance-Normalization-IN）"><a href="#实例归一化（Instance-Normalization-IN）" class="headerlink" title="实例归一化（Instance Normalization, IN）"></a>实例归一化（Instance Normalization, IN）</h4><p>所谓实例归一化，即按照单个样本的单个通道进行计算，计算对象为单层特征图的$N \times W$个值，最终将分别得到$N\times C$个均值和方差。</p><script type="math/tex; mode=display">\begin{array}{c}{\mu_{n c}(x)=\frac{1}{H W} \sum_{h=1}^{H} \sum_{w=1}^{W} x_{n c h w}}\end{array}</script><script type="math/tex; mode=display">{\sigma_{n c}(x)=\sqrt{\frac{1}{H W} \sum_{h=1}^{H} \sum_{w=1}^{W}\left(x_{n c h w}-\mu_{n c}(x)\right)^{2}+\epsilon}}</script><p>同样参考之前的示意图，<strong>所有样本的各个通道之间独立计算</strong>是实例归一化的核心。</p><h4 id="分组归一化（Group-Normalization-GN）"><a href="#分组归一化（Group-Normalization-GN）" class="headerlink" title="分组归一化（Group Normalization, GN）"></a>分组归一化（Group Normalization, GN）</h4><p>分组归一化适用于需要大量显存的任务，对于一些任务，我们无法设置较大的batch size，因而无法使用批量归一化。为了缓和这一问题，提出了分组归一化，这里的分组对象是单个样本的通道。</p><p>在计算均值和方差时，将每一个样本的特征图的通道划分为$G$组，每组将有$C/G$个通道，将各个通道组内的元素求均值和方差，作为通道组内各个通道的均值和方差，最终将得到$N\times G$个均值和方差。</p><script type="math/tex; mode=display">\begin{array}{c}{\mu_{n g}(x)=\frac{1}{(C/G)H W} \sum_{C=gC/G}^{(g+1)C/G} \sum_{h=1}^{H}\sum_{w=1}^{W} x_{n c h w}}\end{array}</script><script type="math/tex; mode=display">{\sigma_{n g}(x)=\sqrt{\frac{1}{(C/G)H W} \sum_{c=gC/G}^{(g+1)C/G} \sum_{h=1}{H}\sum_{w=1}^{W}\left(x_{n c h w}-\mu_{n g}(x)\right)^{2}+\epsilon}}</script><p>可以将分组归一化看作层归一化和实例归一化的中间状态，分组为1时就是层归一化，分组为通道数$C$时就是实例归一化。</p><p>分组归一化的核心就是，<strong>单个样本的不同通道组之间</strong>独立计算。</p><p>总的来说，使用不同的计算对象便可以得到不同的归一化方式。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="https://zhuanlan.zhihu.com/p/69659844" target="_blank" rel="noopener">如何区分并记住常见的几种 Normalization 算法</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
          <category> 基础知识 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 基础知识 </tag>
            
            <tag> 常见知识 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>模型剪枝-基于损失变化的泰勒展开近似的卷积核重要性度量准则</title>
      <link href="/2019/09/12/lun-wen-yue-du/pruning-convolutional-neural-networks-for-resource-efficient-inference/"/>
      <url>/2019/09/12/lun-wen-yue-du/pruning-convolutional-neural-networks-for-resource-efficient-inference/</url>
      
        <content type="html"><![CDATA[<h1 id="Pruning-Convolutional-Neural-Networks-For-Resource-Efficient-Inference"><a href="#Pruning-Convolutional-Neural-Networks-For-Resource-Efficient-Inference" class="headerlink" title="Pruning Convolutional Neural Networks For Resource Efficient Inference"></a>Pruning Convolutional Neural Networks For Resource Efficient Inference</h1><blockquote><p>作者：Pavlo Molchanov, Stephen Tyree, Tero Karras, Timo Aila, Jan Kautz</p><p>机构：Nvidia</p></blockquote><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>在该方法中，使用迭代步骤进行剪枝：在基于准则的贪婪剪枝和使用反向传播进行微调两个步骤之间进行切换。作者提出了一种新的权重重要性度量准则-该准则<strong>基于对网络参数进行剪枝所导致的损失函数变化的泰勒展开式</strong>提出。作者将注意力集中在迁移学习上，将大的预训练网络调整到特定的任务。所提出的度量准则优于其他准则。</p><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><p>在本文中提出的剪枝算法包含以下几步：</p><ol><li>对网络进行微调，直到网络在特定任务上收敛。</li><li>在剪枝和微调两步之间进行迭代。</li><li>在准确率和剪枝指标之间取得平衡后停止剪枝（FLOPS或者内存利用率）。</li></ol><p>如下图所示：</p><p><img src="/2019/09/12/lun-wen-yue-du/pruning-convolutional-neural-networks-for-resource-efficient-inference/1568081011761.png" alt="剪枝流程"></p><p>剪枝流程很简单，但其成功应用依赖于使用正确的剪枝准则。在本节，我们将介绍一些有效的剪枝准则和相关技术。</p><p>考虑给定的训练样本$\mathcal{D}=\{\mathcal{X}=\left.\left\{\mathbf{x}_{0}, \mathbf{x}_{1}, \ldots, \mathbf{x}_{N}\right\}, \mathcal{Y}=\left\{y_{0}, y_{1}, \ldots, y_{N}\right\}\right\}$，其中$x$和$y$分别表示输入样本和目标变量。网络参数$\mathcal{W}=\left\{\left(\mathbf{w}_{1}^{1}, b_{1}^{1}\right),\left(\mathbf{w}_{1}^{2}, b_{1}^{2}\right), \ldots\left(\mathbf{w}_{L}^{C_{\ell}}, b_{L}^{C_{\ell}}\right)\right\}$被用于最小化损失值$\mathcal{C}(\mathcal{D} | \mathcal{W})$，常用的损失函数为负对数似然函数（$L(y)=-\log (y)$）。损失函数的选取与剪枝无关，只与网络所处理的任务有关。在迁移学习中，我们使用一个在类似但有区别的任务上训练的模型参数进行迁移。</p><p>在进行剪枝时，我们使用网络参数的子集来维持网络原有的准确率，即使得$\mathcal{C}\left(\mathcal{D} | \mathcal{W}^{\prime}\right) \approx \mathcal{C}(\mathcal{D} | \mathcal{W})$，为了达到这一目的，我们需要求解一个组合有优化问题：</p><script type="math/tex; mode=display">\min _{W^{\prime}}\left|\mathcal{C}\left(\mathcal{D} | \mathcal{W}^{\prime}\right)-\mathcal{C}(\mathcal{D} | \mathcal{W})\right| \text { s.t. } \quad\left\|\mathcal{W}^{\prime}\right\|_{0} \leq B</script><p>上式中使用$L_0$范数来限制网络权重中非零参数的个数。对于上述问题，当$\mathcal{W}^{\prime}=\mathcal{W}$时，函数取得全局最小值，但由于约束条件的限制，一般无法取得这个值。</p><p>在参数空间中，查找足够好的参数子集使得损失函数的值尽可能地接近原始网络的损失值的问题属于组合优化问题。对于给定的数据，我们需要进行$2^{|\mathcal{W}|}$次评估来查找最优值。但是由于网络参数的个数过多，导致搜索空间太大，无法计算。在本文中，我们调查了一些贪婪方法。</p><p>给定参数集合，我们迭代地识别并移除最不重要的参数。在每次迭代中，保证参数数目满足约束条件的要求。</p><p>因为我们的目标集中在从卷积层中剪除特征图，因此将特征图的集合表示为：$\mathbf{z}_{\ell} \in \mathbb{R}^{H_{\ell} \times W_{\ell} \times C_{\ell}}$，其中$H_{\ell} \times W_{\ell}$表示特征图的大小，$C_{\ell}$表示独立特征图的个数（通道数）。特征图可以是网络的输入或者某一层卷积层的输出。$z_l$中$l \in[1,2,…,L]$。单个卷积图表示为$z_l^{(k)}$，其中$k\in[1,2,…,C_l]$。卷积层执行卷积核和输入特征图之间的卷积运算。</p><script type="math/tex; mode=display">\mathbf{z}_{\ell}^{(k)}=\mathbf{g}_{\ell}^{(k)} \mathcal{R}\left(\mathbf{z}_{\ell-1} * \mathbf{w}_{\ell}^{(k)}+b_{\ell}^{(k)}\right)</script><p>其中$\mathbf{g}_{\ell}$为开关函数，决定一个特定的特征图是否在前向传播过程中被剪除或保留。</p><h3 id="Oracle-Pruning"><a href="#Oracle-Pruning" class="headerlink" title="Oracle Pruning"></a>Oracle Pruning</h3><p>是否能最小化剪枝模型和全模型之间的准确率的差别取决于所使用的识别“最不重要”参数的准则。最优准则是对每一个参数进行经验评估，将其表示为oracle准则，<strong>通过依次移除权重中的非零参数并记录损失的差别得到</strong>。</p><p>我们对比了两种使用oracle重要性评估的方式：</p><ol><li><p><em>oracle-loss</em>：将重要性表示为损失函数变化值的符号：</p><script type="math/tex; mode=display">\mathcal{C}\left(\mathcal{D} | \mathcal{W}^{\prime}\right)-\mathcal{C}(\mathcal{D} | \mathcal{W})</script></li><li><p>oracle-abs：将重要性表示为损失函数变化值的绝对值：</p><script type="math/tex; mode=display">\left|\mathcal{C}\left(\mathcal{D} | \mathcal{W}^{\prime}\right)-\mathcal{C}(\mathcal{D} | \mathcal{W})\right|</script></li></ol><p>两种评判方式都组织对可能导致损失增大的权重进行剪枝，不同之处在于：oracle-loss鼓励剪除那些被剪除后损失函数的值会减低的参数；而oracle-abs会惩罚那些可能会导致损失值发生变化的任何值，而不是变化的方向。</p><p>尽管oracle是贪婪搜索流程的最优选择，但是这一方法是非常耗时的。对于一个训练集，需要进行$\left|W^{\prime}\right|_{0}$次评估（对参数中的所有非零参数依次进行评估）。参数重要性的评估对于剪枝算法的准确率和效率都很重要，因而我们提出和评估了集中不同的准则。</p><h3 id="剪枝准则"><a href="#剪枝准则" class="headerlink" title="剪枝准则"></a>剪枝准则</h3><p>在本文中，我们对以下几种方法进行了评估，并提出了基于<strong>泰勒展开式</strong>的评估准则。</p><p><strong>最小权重</strong>：依据权重的幅度移除卷积核可能是最简单的评价准则之一。在使用权重的范数进行剪枝的算法中，评估准则为：$\Theta_{M W} : \mathbb{R}^{C_{\ell-1} \times p \times p} \rightarrow \mathbb{R}$，其中$\Theta_{M W}(\mathbf{w})=\frac{1}{|\mathbf{w}|} \sum_{i} w_{i}^{2}$，$|\mathbf{w}|$为将权重向量化之后的维度。这一准则的出发点是具有较小二范数的权重的重要性低于具有较大二范数的权重。可以通过在训练过程中添加$l_1$、$l_2$正则项得到。</p><p><strong>激活值</strong>：ReLU激活函数流行的原因之一是其会使得激活值变得稀疏，使得卷积层可以被当作一个特征检测器。因此我们可以假设：如果一个输入特征图的值很小的话，那么其对应的特征检测器将不是很重要。我们可以使用单个特征图的平均激活值进行度量：$\Theta_{MA}:\mathbb{R}^{H_{l} \times W_{\ell} \times \mathcal{C}_{\ell}} \rightarrow \mathbb{R}$，其中 $\Theta_{M A}(\mathbf{a})=\frac{1}{|\mathbf{a}|} \sum_{i} a_{i}$。或者使用激活值的标准差：$\Theta_{M A_{-} s t d}(\mathbf{a})=\sqrt{\frac{1}{|\mathbf{a}|} \sum_{i}\left(a_{i}-\mu_{\mathbf{a}}\right)^{2}}$。</p><p><strong>混合信息</strong>：混合信息用来度量在一个变量中包含的另一个变量的信息量。可以使用混合信息来度量在某一激活值中所包含的目标的信息量，使用该信息量作为重要性的度量。因为混合信息定义在连续值上，因而可以使用信息增益进行替代。</p><p><strong>泰勒展开</strong>：我们将剪枝问题视作最优化问题，尝试找到在非零参数个数受限的情况下使得$\left|\Delta \dot{C}\left(h_{i}\right)\right|=\left|\mathcal{C}\left(\mathcal{D} | \mathcal{W}^{\prime}\right)-\mathcal{C}(\mathcal{D} | \mathcal{W})\right|$最小化的参数子集$\mathcal{W}^{\prime}$。基于泰勒展开的方法，我们直接对由移除某个参数所导致的损失函数的变化值进行近似。设$h_i$表示参数$i$产生的输出。在特征图中，$h=\left\{z_{0}^{(1)}, z_{0}^{(2)}, \ldots, z_{L}^{\left(C_{\ell}\right)}\right\}$。为了表示方便，认为参数和参数对应的输出对损失函数的值所造成的影响是相同的：$\mathcal{C}\left(\mathcal{D} | h_{i}\right)=\mathcal{C}\left(\mathcal{D} |(\mathbf{w}, b)_{i}\right)$。假设参数之间互相独立：</p><script type="math/tex; mode=display">\left|\Delta \mathcal{C}\left(h_{i}\right)\right|=\left|\mathcal{C}\left(\mathcal{D}, h_{i}=0\right)-\mathcal{C}\left(\mathcal{D}, h_{i}\right)\right|（1）</script><p>其中，$\mathcal{C}\left(\mathcal{D}, h_{i}=0\right)$表示将输出$h_i$剪除后损失函数的值，$\mathcal{C}\left(\mathcal{D}, h_{i}\right)$表示未剪除该输出时的损失函数的值。尽管参数之间并非相互独立，我们仍旧在每次参数更新时进行了独立性假设。</p><p>为了对损失函数的变化$\Delta \mathcal{C}\left(h_{i}\right)$的一阶泰勒展开对其进行近似。对于函数$f(x)$，其在$x=a$点的泰勒展开可以表示为：</p><script type="math/tex; mode=display">f(x)=\sum_{p=0}^{P} \frac{f^{(p)}(a)}{p !}(x-a)^{p}+R_{p}(x)</script><p>其中$f^{(p)}(a)$为函数的$p$阶导数在$a$点的值，$R_p(x)$为$p$阶余项。将$C(D,h_i=0)$表示为函数在$h_i=0$点附近的一阶泰勒展开式。</p><script type="math/tex; mode=display">\mathcal{C}\left(\mathcal{D}, h_{i}=0\right)=\mathcal{C}\left(\mathcal{D}, h_{i}\right)-\frac{\delta \mathcal{C}}{\delta h_{i}} h_{i}+R_{1}\left(h_{i}=0\right)  （2）</script><p>使用二阶拉格朗日余项：</p><script type="math/tex; mode=display">R_{1}\left(h_{i}=0\right)=\frac{\delta^{2} \mathcal{C}}{\delta\left(h_{i}^{2}=\xi\right)} \frac{h_{i}^{2}}{2}</script><p>这里，我们直接忽略掉余项，一方面因为计算余项需要大量的计算资源（求二阶导数）；另一方面因为$ReLU$激活函数的原因，余项中的二阶项会比较小。</p><p>接着，将$(2)$式代入$(1)$式并忽略余项，可以得到$\Theta_{T E}:$$<br>\mathbb{R}^{H_{l} \times W_{l} \times \tilde{C}_{l}} \rightarrow \mathbb{R}^{+}<br>$：</p><script type="math/tex; mode=display">\Theta_{T E}\left(h_{i}\right)=\left|\Delta \mathcal{C}\left(h_{i}\right)\right|=\left|\mathcal{C}\left(\mathcal{D}, h_{i}\right)-\frac{\delta \mathcal{C}}{\delta h_{i}} h_{i}-\mathcal{C}\left(\mathcal{D}, h_{i}\right)\right|=\left|\frac{\delta \mathcal{C}}{\delta h_{i}} h_{i}\right|</script><p>上式即可表示移除某一参数后对损失函数所造成的影响。在这一准则下，那些有较为平坦的梯度的特征图所对应的参数将被剪除。其中的梯度在反向传播过程中很容易计算得到。对于某个特征图,可以将上式转换为如下形式：</p><script type="math/tex; mode=display">\Theta_{T E}\left(z_{l}^{(k)}\right)=\left|\frac{1}{M} \sum_{m} \frac{\delta C}{\delta z_{l, m}^{(k)}} z_{l, m}^{(k)}\right|</script><p>其中，$M$是向量化特征图的长度。对于一个minibatch的样本，分别针对每个样本计算上述值，再将各个样本的值进行平均。</p><h2 id="相关博客"><a href="#相关博客" class="headerlink" title="相关博客"></a>相关博客</h2><p>在VGG网络中，大部分的参数来自于全连接层，但全连接层的计算量只占所有浮点运算数的1%。对全连接层进行剪枝，会大幅度降低网络的参数量，但计算量并不会变化太多。而对卷积核进行剪枝不仅会降低参数量，也会大幅度降低运算量。</p><p>当对卷积核进行剪枝时，有一种操作是剪除每一个核中的一些权重，或者移除单个卷积核中的特定维度。这样，会得到稀疏的卷积核，但并不会起到加速计算的作用。因而，更多的工作集中在结构化剪枝 （移除整个卷积核）。</p><p>一些论文显示，通过对一个大的网络进行训练和剪枝，特别是迁移学习，会得到比直接从零开始训练一个小的网络更好的结果。</p><h4 id="论文-Pruning-Filters-For-Efficient-Convnets"><a href="#论文-Pruning-Filters-For-Efficient-Convnets" class="headerlink" title="论文-Pruning Filters For Efficient Convnets"></a>论文-Pruning Filters For Efficient Convnets</h4><p>在本文中，移除整个卷积核。移除第k个卷积核将导致其产生的特征图中的第k个通道消失，进而导致下一层的所有卷积核的第k个通道消失，如下图所示：</p><p><img src="/2019/09/12/lun-wen-yue-du/pruning-convolutional-neural-networks-for-resource-efficient-inference/prune_example.png" alt="Pruning a convolutional filter entire filter"></p><p>当下一层为全连接层时，假设被移除的通道的特征图大小为$M\times N$，那么全连接层中将有$M \times N$个神经元被移除。</p><p>在本文中，使用权重的$L1$范数对其进行分级。</p><h4 id="使用泰勒准则来对猫狗分类器进行剪枝"><a href="#使用泰勒准则来对猫狗分类器进行剪枝" class="headerlink" title="使用泰勒准则来对猫狗分类器进行剪枝"></a>使用泰勒准则来对猫狗分类器进行剪枝</h4><h5 id="第一步-训练一个大的网络"><a href="#第一步-训练一个大的网络" class="headerlink" title="第一步-训练一个大的网络"></a>第一步-训练一个大的网络</h5><p>使用VGG16，移除全连接层，替换为三层新的全连接层。在训练过程中，冻结卷积层，只对新的全连接层进行训练。在Pytorch中，新的层如下：</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">self.classifier = nn.Sequential(        nn.Dropout(),        nn.Linear(25088, 4096),        nn.ReLU(inplace=True),        nn.Dropout(),        nn.Linear(4096, 4096),        nn.ReLU(inplace=True),        nn.Linear(4096, 2))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>使用数据增强训练20个epoches后，在测试集上得到98.7%的准确率。</p><h5 id="第二步-对卷积核进行分级"><a href="#第二步-对卷积核进行分级" class="headerlink" title="第二步-对卷积核进行分级"></a>第二步-对卷积核进行分级</h5><p>为了计算泰勒准则，我们需要在数据集上（如果数据集太大，可以使用一部分数据集）进行前向传播和反向传播（需要计算梯度）。</p><p>接着，我们需要同时得到军基层的梯度和激活值。在Pytorch中，我们可以在梯度计算中注册一个hook，所以在调用时便会完成相关计算：</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">for layer, (name, module) in enumerate(self.model.features._modules.items()):    x = module(x)    if isinstance(module, torch.nn.modules.conv.Conv2d):        x.register_hook(self.compute_rank)        self.activations.append(x)        self.activation_to_layer[activation_index] = layer        activation_index += 1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这样，我们就使用<code>self.activations</code>保存了各层的激活值，当完成梯度的计算时，<code>compute_rank</code>函数便会被调用。</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">def compute_rank(self, grad):    activation_index = len(self.activations) - self.grad_index - 1    activation = self.activations[activation_index]    values = \        torch.sum((activation * grad), dim = 0).\            sum(dim=2).sum(dim=3)[0, :, 0, 0].data    # Normalize the rank by the filter dimensions    values = \        values / (activation.size(0) * activation.size(2) * activation.size(3))    if activation_index not in self.filter_ranks:        self.filter_ranks[activation_index] = \            torch.FloatTensor(activation.size(1)).zero_().cuda()    self.filter_ranks[activation_index] += values    self.grad_index += 1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这一函数对batch中的激活值和其梯度进行点乘，接着对于每一个激活值，在除了输出维度（特征图通道数）之外的所有维度进行求和。</p><p>例如，batch的大小为32，某一激活值的大小为256、空间大小为$112\times 112$，那么该激活值和其梯度的大小为$32\times 256 \times 112 \times 112$，那么其输出为大小为256的向量，向量的每一个元素表示该层中的256个卷积核各自的等级。</p><p>得到各个卷积核的等级之后，使用最小堆来得到$N$个等级最低的卷积核。和原始文章中在每一轮迭代中使用$N=1$不同，为了计算快速，我们使用$N=512$。这意味着，在每次剪枝迭代中，会移除$12%$的卷积核。</p><p>大多数被剪除的卷积核都来自于较深的层，在第一次迭代后被剪除的卷积核的分布：</p><p><img src="/2019/09/12/lun-wen-yue-du/pruning-convolutional-neural-networks-for-resource-efficient-inference/1568261252580.png" alt="剪枝卷积核分布示意"></p><h5 id="第三步-微调并重复"><a href="#第三步-微调并重复" class="headerlink" title="第三步-微调并重复"></a>第三步-微调并重复</h5><p>在这一步，解冻所有的层，并重新训练10个epochs。接着返回第一步并重复。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="https://jacobgil.github.io/deeplearning/pruning-deep-learning" target="_blank" rel="noopener">https://jacobgil.github.io/deeplearning/pruning-deep-learning</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
          <category> 模型压缩 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 模型压缩 </tag>
            
            <tag> 模型剪枝 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据结构-基本概念</title>
      <link href="/2019/09/05/shu-ju-jie-gou-yu-suan-fa/shu-ju-jie-gou/shu-ju-jie-gou-ji-chu-gai-nian-zhun-bei/"/>
      <url>/2019/09/05/shu-ju-jie-gou-yu-suan-fa/shu-ju-jie-gou/shu-ju-jie-gou-ji-chu-gai-nian-zhun-bei/</url>
      
        <content type="html"><![CDATA[<h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><p>在研究数据结构之前，我们有必要搞清楚什么是数据结构。</p><p>首先，什么是<strong>数据</strong>？</p><blockquote><p>数据是描述客观事物的符号，是计算机中可以操作的对象，是能被计算机识别，并输入给计算机处理的符号集合。</p></blockquote><p>而<strong>数据元素</strong>指的是组成数据的、有一定意义的基本单位，在计算机中通常作为整体处理，例如：人、猫等。一个数据元素可以由若干个<strong>数据项</strong>组成，例如：人由眼睛、鼻子等组成，数据项是数据不可分割的最小单位。</p><p>对于数据元素中性质相同的集合，我们将其称为数据对象。在实际应用中，处理的数据元素通产具有相同的性质，在不产生混淆的情况下，将数据对象称为数据。</p><p>那么，什么是数据结构呢？</p><blockquote><p>数据结构：是相互之间存在一种或多种特定关系的数据元素的集合。</p></blockquote><h2 id="逻辑结构与物理结构"><a href="#逻辑结构与物理结构" class="headerlink" title="逻辑结构与物理结构"></a>逻辑结构与物理结构</h2><p>上文中说到，数据元素之间存在一种或多种特定的关系，依据关系类型的不同可以将数据结构分为逻辑结构和物理结构。</p><h3 id="逻辑结构"><a href="#逻辑结构" class="headerlink" title="逻辑结构"></a>逻辑结构</h3><p>逻辑结构是指数据对象中数据元素之间的相互关系，逻辑结构可以分为以下四种：</p><ul><li><p><strong>集合结构</strong></p><p>集合结构中的数据除了同属于一个集合外，它们之间没有其它关系。各个数据之间是<strong>相互平等</strong>的。</p></li><li><p><strong>线性结构</strong></p><p>线性结构中的数据是<strong>一对一</strong>的关系。</p></li><li><p><strong>树形结构</strong></p><p>树形结构中的数据之间存在一种<strong>一对多</strong>的层次关系。</p></li><li><p><strong>图形结构</strong></p><p>图形结构的数据元素是<strong>多对多</strong>的关系。</p></li></ul><p>逻辑结构是针对具体问题的，是为了解决某个问题，在对问题理解的基础上，选择一个合适的数据结构表示数据元素之间的逻辑关系。</p><h3 id="物理结构"><a href="#物理结构" class="headerlink" title="物理结构"></a>物理结构</h3><p>物理结构是指数据的逻辑结构在计算机中的存储形式。物理结构研究的就是如何将数据元素存储到计算机中，存储器主要是针对内存而言的。</p><p>数据的存储结构应该正确反映数据元素之间的逻辑关系，如何存储数据元素之间的逻辑关系，是实现物理结构的重点和难点。</p><p>数据元素的存储形式有两种：顺序存储和链式存储。</p><ul><li><p>顺序存储结构</p><p>把数据元素存放在地址连续的存储单元里，其数据间的逻辑关系和物理关系一致。</p></li><li><p>链式存储结构</p><p>把数据元素存放在任意的存储单元里，这组存储单元可以是连续的，也可以是不连续的。</p></li></ul><p>总的来说，逻辑结构是面向问题的，物理结构解决如何将数据元素之间的逻辑关系存储在计算机中。</p><h2 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h2><p>为了学好数据结构，就必须学习算法，只有同时掌握了数据结构和算法才能写出完整的程序。</p><p>何为算法？</p><blockquote><p>算法是解决特定问题求解步骤的描述，在计算机中表现为指令的有限序列，并且每条指令表示一个或多个操作。</p></blockquote><h3 id="算法的特性"><a href="#算法的特性" class="headerlink" title="算法的特性"></a>算法的特性</h3><ul><li><p>输入、输出</p><p>算法具有零个或多个输入，至少有一个或多个输出。</p></li><li><p>有穷性</p><p>指算法在执行有限的步骤后，自动结束而不会陷入死循环，并且每一个步骤在可接受的时间内完成。</p></li><li><p>确定性</p><p>算法的每一步骤都具有确定的含义，不会出现二义性。</p></li><li><p>可行性</p><p>算法的每一步都必须可行，每一步都能够通过执行有限次数完成。</p></li></ul><h3 id="算法效率度量方式"><a href="#算法效率度量方式" class="headerlink" title="算法效率度量方式"></a>算法效率度量方式</h3><p>在进行算法设计时，我们需要对算法的效率进行度量（大部分情况下指运行时间），那么如何对算法的运行时间进行度量呢？</p><p>一般存在两种度量方式，<strong>事后度量和事前度量</strong>，所谓事后度量，指的是设计测试程序和数据对程序的性能进行实地测试，但一个算法的运行效率和所使用的测试样例、硬件环境等有很大的关系，事后度量一般不准确。因而我们一般采用事前度量的方式。</p><p>一个用高级程序语言设计的程序在计算机上运行时所消耗的时间取决于下列因素：</p><ul><li>算法采用的策略、方法。</li><li>编译产生的代码质量。</li><li>问题的输入规模。</li><li>机器执行指令的速度。</li></ul><p>抛开与计算机硬件（第四条）、软件（第二条）相关的因素，<strong>一个程序运行的时间取决于算法的好坏和问题的输入规模</strong>。</p><p>而测定一个程序的运行时间的最可靠的方法就是<strong>计算对运行时间有消耗的基本操作的执行次数</strong>，运行时间与这个计数成正比，如下述程序所示：</p><pre class="line-numbers language-lang-c++"><code class="language-lang-c++">int i, j, x = 0, sum = 0, n = 100; /* 执行一次 */for (i = 1; i <= n; i++){    for (j = 1; j <= n; j++)    {        x++;        sum = sum + x; /* 执行nxn次 */    }}printf("%d", sum); /* 执行一次 */<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在上述程序中，其最核心的基本操作便是两个<code>for</code>循环中的语句，该语句总计执行了<code>nxn</code>次。</p><p>在对算法效率进行分析的时候，我们不关心算法的实现语言是什么、实现平台是什么，只关注算法本身。不计循环索引的递增、循环终止条件、变量声明和打印等操作，<strong>在分析程序的运行时间时，最重要的是把程序看作是独立于程序设计语言的算法或一系列步骤</strong>。</p><p>我们要做的是把基本操作的数量与输入规模关联起来，即<strong>基本操作的数量必须表示成输入规模的函数</strong>。</p><h3 id="函数的渐近增长"><a href="#函数的渐近增长" class="headerlink" title="函数的渐近增长"></a>函数的渐近增长</h3><p>给出定义如下：</p><blockquote><p>给定两个函数$f(n)$和$g(n)$，如果存在一个整数$N$，使得对于所有的$n&gt;N$，$f(n)$总是比$g(n)$大，那么我们就说$f(n)$的增长渐近快于$g(n)$。</p></blockquote><h4 id="忽略加法常数"><a href="#忽略加法常数" class="headerlink" title="忽略加法常数"></a>忽略加法常数</h4><p>存在这样一种现象，随着输入规模的逐渐增大，算法计算效率中的<strong>加法常数所造成的影响将变得可以忽略不计</strong>。例如在对比$2n+3$和$3n+1$时，两者中的常数便可以被忽略。</p><h4 id="忽略与最高次项相乘的常数"><a href="#忽略与最高次项相乘的常数" class="headerlink" title="忽略与最高次项相乘的常数"></a>忽略与最高次项相乘的常数</h4><p>假如两个算法的计算效率分别是$4n+8$和$2n^2+1$，我们可以忽略掉其中的最高次项的常数系数，只保留$n$和$n^2$。</p><h4 id="忽略低次项"><a href="#忽略低次项" class="headerlink" title="忽略低次项"></a>忽略低次项</h4><p>在比较两个算法的计算效率时，我们可以忽略掉除最高次项的其它项，例如，$2n^2+3n+1$和$2n^3+3n+1$等价于比较$n^2$和$n^3$。</p><p>综合上述所言，我们可以得出这样一个结论：<strong>在判断一个算法的效率时，函数中的常数和其他次要项常常可以忽略，而更应该关注主项（最高阶项）的阶数</strong>。</p><p>判断一个算法的优劣，我们无法只通过少量数据进行准确的判断。通过上述分析可以看出，如果我们可以对比这几个算法的关键执行次数函数的渐近增长性，基本就可以分析出：<strong>某个算法，随着$n$的增大，它会越来越优于另一个算法，或者越来越差于另一个算法</strong>。</p><p>这就是事前估计方法的理论依据，通过算法时间复杂度来估算算法时间效率。</p><h2 id="算法时间复杂度"><a href="#算法时间复杂度" class="headerlink" title="算法时间复杂度"></a>算法时间复杂度</h2><h3 id="算法的时间复杂度的定义"><a href="#算法的时间复杂度的定义" class="headerlink" title="算法的时间复杂度的定义"></a><strong>算法的时间复杂度的定义</strong></h3><p>算法的时间复杂度，也就是算法的时间度量，记作：$T(n)=O(f(n))$，它表示随问题规模$n$的增大，算法执行时间的增长率和$f(n)$的增长率相同，称作算法的渐近时间复杂度，简称为时间复杂度。其中，$f(n)$是问题规模的某个函数。</p><p>上述使用大写的$O$表示算法的时间复杂度的记法，称作大$O$记法。</p><h3 id="计算算法的大-O-阶"><a href="#计算算法的大-O-阶" class="headerlink" title="计算算法的大$O$阶"></a>计算算法的大$O$阶</h3><p>计算方法大体如下：</p><ul><li><p>用常数1取代运行时间中的所有加法常数。</p></li><li><p>在修改后的运行次数函数中，只保留最高阶项，也就是只关注循环执行次数最多的一段代码。</p><p>在分析一个算法、一段代码的时间复杂度时，只关注循环执行次数最多的那一段代码就行了。</p></li><li><p>如果最高阶项存在且不是1，则去除于这个项相乘的常数。</p></li><li><p>嵌套代码的时间复杂度等于嵌套内外代码复杂度的乘积。</p><pre class="line-numbers language-lang-c++"><code class="language-lang-c++">int cal(int n) {   int ret = 0;    int i = 1;   for (; i < n; ++i) {     ret = ret + f(i);   }  }  int f(int n) {  int sum = 0;  int i = 1;  for (; i < n; ++i) {    sum = sum + i;  }   return sum; }<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>上述代码的时间复杂度等于<code>cal(int n)</code>函数中<code>for</code>循环的时间复杂度$O(n)$乘以函数<code>f(int n)</code>的时间复杂度$O(n)$，即该段代码的时间复杂度为$O(n^2)$。</p></li></ul><h4 id="常数阶"><a href="#常数阶" class="headerlink" title="常数阶"></a>常数阶</h4><p>存在这样一类算法，它们的计算复杂度与问题的输入无关，无论问题的规模为多少，这些算法的执行时间都是恒定的，我们称此类算法为具有$O(1)$的时间复杂度，又叫常数阶。<strong>一般情况下，只要算法中不存在循环语句、递归语句，即使有成千上万行的代码，其时间复杂度也是$O(1)$</strong>。</p><h4 id="线性阶"><a href="#线性阶" class="headerlink" title="线性阶"></a>线性阶</h4><p>我们要分析算法的复杂度，关键就是要分析循环结构的执行情况。</p><pre class="line-numbers language-lang-c++"><code class="language-lang-c++">int  i;for (i = 0; i < n; i++){    /* 时间复杂度为O(1)的程序步骤序列 */}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>上述程序的循环分支中的语句执行了$n$次，因此其时间复杂度为$O(n)$。</p><h4 id="对数阶"><a href="#对数阶" class="headerlink" title="对数阶"></a>对数阶</h4><p>如下述代码：</p><pre class="line-numbers language-lang-c++"><code class="language-lang-c++">int count = 1;while (count < n){    count = count * 2;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>我们需要计算出上述代码中的<code>while</code>循环中的语句的执行次数，<code>count</code>每次乘2，满足$count*2^x=n$，即$x=log_2n$时循环结束，所以这个循环的时间复杂度为$log_2n$。</p><p>实际上，不论以2为底还是以3为底，都将所有对数阶的时间复杂度记为$O(logn)$。同时，如果一段代码的时间复杂度为$O(logn)$，将这段代码重复执行$n$次，时间复杂度就是$O(nlogn)$。</p><h4 id="平方阶"><a href="#平方阶" class="headerlink" title="平方阶"></a>平方阶</h4><p>当循环内部嵌套循环时，总的算法的时间复杂度为循环体的复杂度乘以该循环运行的次数。</p><pre class="line-numbers language-lang-c++"><code class="language-lang-c++">ing i, j;for (i = 0; i < m; i++){    for (j = 0; j < n; j++)    {        /* 时间复杂度为O(1)的程序步骤 */    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>上述算法的时间复杂度为$O(n^2)$。</p><h3 id="O-m-n-、O-m-n"><a href="#O-m-n-、O-m-n" class="headerlink" title="$O(m+n)、O(m*n)$"></a>$O(m+n)、O(m*n)$</h3><p>这一类时间复杂度与前面几种复杂度不同，该类时间复杂度由<strong>两个数据的规模</strong>决定。如下述代码所示：</p><pre class="line-numbers language-lang-c"><code class="language-lang-c">int cal(int m, int n) {  int sum_1 = 0;  int i = 1;  for (; i < m; ++i) {    sum_1 = sum_1 + i;  }  int sum_2 = 0;  int j = 1;  for (; j < n; ++j) {    sum_2 = sum_2 + j;  }  return sum_1 + sum_2;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在上述代码中，$m$和$n$是两个数据规模，我们无法事先估计两者的量级大小，所以在计算时间复杂度时就无法利用加法规则省略掉其中的一个。但是此时乘法规则仍旧适用。</p><h2 id="常见的时间复杂度"><a href="#常见的时间复杂度" class="headerlink" title="常见的时间复杂度"></a>常见的时间复杂度</h2><p>常见的时间复杂度如下表所示：</p><div class="table-container"><table><thead><tr><th>执行次数函数</th><th>阶</th><th>非正式用语</th></tr></thead><tbody><tr><td>$12$</td><td>$O(1)$</td><td>常数阶</td></tr><tr><td>$2n+3$</td><td>$O(n)$</td><td>线性阶</td></tr><tr><td>$3n^2+2n+1$</td><td>$O(n^2)$</td><td>平方阶</td></tr><tr><td>$5log_2n+20$</td><td>$O(logn)$</td><td>对数阶</td></tr><tr><td>$2n+3nlog_2n+19$</td><td>$O(nlogn)$</td><td>$nlogn$阶</td></tr><tr><td>$6n^3+2n^2+3n+4$</td><td>$O(n^3)$</td><td>立方阶</td></tr><tr><td>$2^n$</td><td>$O(2^n)$</td><td>指数阶</td></tr></tbody></table></div><p>上述时间复杂度所耗费的时间从小到大以此为：</p><script type="math/tex; mode=display">O(1)<O(N)<O(n^2)<O(logn)<O(nlogn)<O(n^3)<O(2^n)</script><blockquote><p>在算法复杂度的分析中，一般提到的运行时间都是最坏情况下的运行时间。</p></blockquote><p><img src="/2019/09/05/shu-ju-jie-gou-yu-suan-fa/shu-ju-jie-gou/shu-ju-jie-gou-ji-chu-gai-nian-zhun-bei/497a3f120b7debee07dc0d03984faf04.jpg" alt=""></p><h2 id="算法的空间复杂度"><a href="#算法的空间复杂度" class="headerlink" title="算法的空间复杂度"></a>算法的空间复杂度</h2><p>在进行算法设计时，我们完全可以使用空间换时间。算法的空间复杂度通过计算算法所需的存储空间实现，算法空间复杂度的计算公式记作：$S(n)=O(f(n))$，其中，$n$为问题的规模，$f(n)$为语句关于$n$所占存储空间的函数。同样，空间复杂度的全称为渐近空间复杂度。</p><p>通常情况下，我们使用“时间复杂度”指程序运行时间的需求，使用“空间复杂度”指空间需求。当不使用限定词时，“复杂度”通常都是指时间复杂度。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li>《大话数据结构》</li><li><a href="https://time.geekbang.org/column/article/40036" target="_blank" rel="noopener">数据结构与算法之美-王争</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 数据结构 </category>
          
          <category> 编程基础 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 编程基础 </tag>
            
            <tag> 数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>C++基础-变量和基本类型</title>
      <link href="/2019/09/03/c/bian-liang-he-ji-ben-lei-xing/"/>
      <url>/2019/09/03/c/bian-liang-he-ji-ben-lei-xing/</url>
      
        <content type="html"><![CDATA[<h2 id="变量和基本类型"><a href="#变量和基本类型" class="headerlink" title="变量和基本类型"></a>变量和基本类型</h2><h3 id="1-复合类型"><a href="#1-复合类型" class="headerlink" title="1 复合类型"></a>1 复合类型</h3><blockquote><p>一条声明语句由一个<strong>基本数据类型</strong>（base type）和紧随其后的一个<strong>声明符</strong>（declarator）列表组成。</p></blockquote><p>基本数据类型：int、double等；声明符：变量名、引用&amp;、指针*（引用和指针又称为类型修饰符，为声明符的一部分）等。</p><h3 id="2-引用"><a href="#2-引用" class="headerlink" title="2 引用"></a>2 引用</h3><ol><li><p>引用并非对象，只是为已经存在的对象所起的另外一个名字。</p></li><li><p><strong>因为引用本身不是对象，所以不能定义引用的引用。</strong></p></li><li><p>引用必须在定义的时候初始化。</p></li></ol><h3 id="3-指针"><a href="#3-指针" class="headerlink" title="3 指针"></a>3 指针</h3><ol><li><p>指针是一个对象，因而允许定义指针的指针。</p></li><li><p>指针无须在定义时赋初值，但如果指针没有被初始化，将拥有一个不确定的初始值。</p></li></ol><blockquote><p>  建议初始化所有指针，并且在可能的情况下，在定义了对象之后再定义指向它的指针。</p></blockquote><ol><li>空指针不指向任何对象，使用字面值nullptr初始化指针。</li></ol><p><strong>void指针</strong> 该类型的指针所指向的地址中存放的对象的类型并不确定。</p><h3 id="4-const限定符"><a href="#4-const限定符" class="headerlink" title="4 const限定符"></a>4 const限定符</h3><p>const对象的值一旦创建后其值就不能再改变，所以const对象必须进行初始化。</p><p>在<strong>默认状态下，const对象仅在文件内有效</strong>，当多个文件中出现了同名的const对象时，其实等同于在不同文件中分别定义了独立的变量。当我们希望在不同文件之间使用同一const对象时（只在一个文件中定义const，而在多个文件中声明并使用它），则需要添加<code>extern</code>关键字，如。</p><pre class="line-numbers language-lang-c++"><code class="language-lang-c++">// file_1.cc定义并初始化一个常量，该常量可被其他文件访问extern const int bufSize = fcn();// file_1.h头文件extern const int bufSize;// 与file_1.cc中定义的bufSize是同一个。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>定义对const的引用后，不允许使用引用去改变它所绑定的对象。</p><h4 id="4-1-指针和const"><a href="#4-1-指针和const" class="headerlink" title="4.1 指针和const"></a>4.1 指针和const</h4><h5 id="指向常量的指针"><a href="#指向常量的指针" class="headerlink" title="指向常量的指针"></a>指向常量的指针</h5><p>指向常量的指针不能用于改变其所指对象的值，只能使用指向常量的指针存放常量对象的地址。</p><pre class="line-numbers language-lang-c++"><code class="language-lang-c++">const double pi = 3.14;const double *cptr = &pi;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>在初始化指向常量的指针时，既可以使用字面值进行初始化，也可以使用常量、非常量进行初始化。</p><blockquote><p>和常量引用一样，指向常量的指针没有规定其所指向的对象必须是一个常量，只是限定不能使用指针（通过<strong>解引用符</strong>（操作符*））更改对象的值。</p></blockquote><h5 id="常量指针（const-pointer）"><a href="#常量指针（const-pointer）" class="headerlink" title="常量指针（const pointer）"></a>常量指针（const pointer）</h5><p>指针本身是常量，const修饰符修饰的是指针本身。意味着，初始化之后指针所存储的地址值不能被改变。</p><pre class="line-numbers language-lang-c++"><code class="language-lang-c++">int errNumb = 0;int j;int *const curErr = &errNumb;// 从右往左进行解读，const说明curErr是常量，*说明是常量指针，int说明指向的对象是整形。curErr = &j;// 错误，改变了常量指针所存储的地址值。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="4-2-顶层const（top-level-const）"><a href="#4-2-顶层const（top-level-const）" class="headerlink" title="4.2 顶层const（top-level const）"></a>4.2 顶层const（top-level const）</h4><p>指针本身是常量，或者说对象本身是不可变的。</p><pre class="line-numbers language-lang-c++"><code class="language-lang-c++">int i = 0;int *const p1 = &i;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h4 id="4-3-底层const（low-level-const）"><a href="#4-3-底层const（low-level-const）" class="headerlink" title="4.3 底层const（low-level const）"></a>4.3 底层const（low-level const）</h4><p>指针所指向的对象是常量。</p><pre class="line-numbers language-lang-c++"><code class="language-lang-c++">const int ci = 42;const int *p2 = &ci;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h4 id="4-4-区分顶层const和底层const的作用"><a href="#4-4-区分顶层const和底层const的作用" class="headerlink" title="4.4 区分顶层const和底层const的作用"></a>4.4 区分顶层const和底层const的作用</h4><ol><li>赋值操作存在限制,不能将底层const赋值给非底层const。</li></ol><pre class="line-numbers language-lang-c++"><code class="language-lang-c++">int num_c = 3;const int *p_c = &num_c;  //p_c为底层const的指针int *p_d = p_c;  //错误，不能将底层const指针赋值给非底层const指针const int *p_d = p_c; //正确，可以将底层const指针复制给底层const指针<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol><li>使用命名的强制类型转换函数const_cast时，需要能够分辨底层const和顶层const，因为const_cast只能改变运算对象的底层const。</li></ol><pre class="line-numbers language-lang-c++"><code class="language-lang-c++">int num_e = 4;const int *p_e = &num_e;*p_e = 5;  //错误，不能改变底层const指针指向的内容int *p_f = const_cast<int *>(p_e);  //正确，const_cast可以改变运算对象的底层const(这里需要确保num_e不是const)。*p_f = 5;  //正确，非底层const指针可以改变指向的内容cout << num_e;  //输出5<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="5-auto类型说明符"><a href="#5-auto类型说明符" class="headerlink" title="5 auto类型说明符"></a>5 auto类型说明符</h3><p>在编程时，需要把表达式的值赋给变量，则需要知道表达式的值的类型。使用<code>auto</code>可以让编译器分析表达式所属的类型。</p><p>- <code>auto</code>定义的变量必须有初始值。</p><p>- 同一语句中的所有变量的<strong>初始基本数据类型</strong>必须相同。</p><h4 id="5-1-引用与auto"><a href="#5-1-引用与auto" class="headerlink" title="5.1 引用与auto"></a>5.1 引用与auto</h4><p>使用引用的对象的类型作为auto的类型。</p><h4 id="5-2-const与auto"><a href="#5-2-const与auto" class="headerlink" title="5.2 const与auto"></a>5.2 const与auto</h4><p>auto会忽略掉顶层const，而保留底层const。</p><h3 id="6-decltype类型指示符"><a href="#6-decltype类型指示符" class="headerlink" title="6 decltype类型指示符"></a>6 decltype类型指示符</h3><p>希望从表达式的类型推断出要定义的变量的类型，但是不想使用该表达式的值初始化变量，这时就无法使用<code>auto</code>，需要使用<code>decltype</code>。</p><h4 id="6-1-decltype与const"><a href="#6-1-decltype与const" class="headerlink" title="6.1 decltype与const"></a>6.1 decltype与const</h4><p>如果decltype是一个变量，则decltype会返回该变量的类型，而不会忽略任何const。</p><h3 id="7-编写自己的头文件"><a href="#7-编写自己的头文件" class="headerlink" title="7 编写自己的头文件"></a>7 编写自己的头文件</h3><ol><li><p>为了确保各个文件中类的定义一致，类通常被定义在头文件中，而且类所在头文件的名字应与类的名字一样。</p></li><li><p>头文件通常包含那些只能被定义一次的实体，如<code>const constexpr</code>。</p></li></ol><blockquote><p>注意：头文件一旦改变，相关的源文件必须重新编译以获取更新过的声明。</p></blockquote><h4 id="7-1-如何防止头文件的重复包含？"><a href="#7-1-如何防止头文件的重复包含？" class="headerlink" title="7.1 如何防止头文件的重复包含？"></a>7.1 如何防止头文件的重复包含？</h4><p><strong>使用预处理技术</strong></p><blockquote><p><strong>预处理器是在编译之前执行的一段程序，可以部分地改变我们写的程序。</strong></p></blockquote><p><strong>头文件保护符</strong></p><p>头文件保护符属于预处理技术的一种，其状态依赖于预处理变量，预处理变量有两种状态：已定义、未定义。</p><p><code>#define</code> 指令把一个名字设为预处理变量</p><p><code>#ifdef</code> 当且仅当变量已定义时为真</p><p><code>#ifndef</code> 当且仅当变量未定义时为真</p><p>注意：当检查状态为真时，执行后续操作直到<code>#endif</code>指令为止。</p><p>使用头文件保护符防止重复包含头文件的例子：</p><pre class="line-numbers language-lang-c++"><code class="language-lang-c++">#ifndef SALES_DATA_H#define SALES_DATA_H#include <string.h>struct Sales_data{    std::string bookNo;    unsigned units_sold = 0;    double revenue = 0.0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在其他文件第一次包含<code>Sales_data.h</code>时，程序检查<code>#ifndef SALES_DATA_H</code>为真，则执行后续语句，通过<code>#define SALES_DATA_H</code>定义预处理变量<code>SALES_DATA_H</code>，并将<code>Sales_data.h</code>的内容拷贝至当前程序中。那么当其他文件第二次包含<code>Sales_data.h</code>，程序检查<code>#ifndef SALES_DATA_H</code>为假，则不会执行后续语句，也就不会重复拷贝<code>Sales_data.h</code>头文件。</p><blockquote><p>一般将预处理变量的名称全部大写，并且应该习惯性地加上头文件保护符.</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 编程基础 </category>
          
          <category> 编程语言 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 编程基础 </tag>
            
            <tag> C++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>C++基础-模板和泛型编程</title>
      <link href="/2019/09/03/c/mo-ban-he-fan-xing-bian-cheng/"/>
      <url>/2019/09/03/c/mo-ban-he-fan-xing-bian-cheng/</url>
      
        <content type="html"><![CDATA[<h2 id="模板和泛型编程"><a href="#模板和泛型编程" class="headerlink" title="模板和泛型编程"></a>模板和泛型编程</h2><p>模板是c++泛型编程的基础。</p><h3 id="定义模板"><a href="#定义模板" class="headerlink" title="定义模板"></a>定义模板</h3><h4 id="函数模板"><a href="#函数模板" class="headerlink" title="函数模板"></a>函数模板</h4><pre class="line-numbers language-lang-c++"><code class="language-lang-c++">template <typename T>int compare(const T &v1, const T &v2){    if (v1 < v2) return -1;    if (v1 > v2) return 1;    return 0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>模板定义以关键字template开始，后跟一个<strong>模板参数列表</strong>，模板参数列表不能为空。</p><p>模板参数表示在类或函数定义中用到的类型或值。当使用模板时，我们（显式或者隐式地）指定模板参数，将其绑定到模板参数上。</p><p>当我们调用一个函数模板时，编译器通常用函数实参来为我们推断模板实参。即，编译器使用实参的类型来确定绑定到模板实参T的类型。</p><p>编译器用推断出的模板参数来实例化出一个特定版本的函数，该特定版本的函数称为模板的<strong>实例</strong>。</p><h4 id="模板类型参数"><a href="#模板类型参数" class="headerlink" title="模板类型参数"></a>模板类型参数</h4><p>在模板参数列表中用于定义类型的参数称为模板类型参数。</p><p>可以将类型参数看做类型说明符，就像内置类型或类类型说明符一样使用。类型参数可以用来指定返回类型或函数的参数类型，以及在函数体内用于变量声明或类型转换。</p><p>类型参数前必须使用关键字class或typename，在模板参数列表中，这两个关键字的含义相同，可以互换使用。</p><h4 id="非类型模板参数"><a href="#非类型模板参数" class="headerlink" title="非类型模板参数"></a>非类型模板参数</h4><p>一个非类型模板参数表示一个值而非一个类型。通过一个特定的类型名而非关键字class或typename来制定非类型参数。</p><p>当一个模板被实例化时，非类型参数被一个用户提供的或编译器推断出的值所替代。这些值必须是常量表达式，从而允许编译器在编译时实例化模板。</p><p>一个非类型参数可以是一个整型，或者是一个指向对象或函数类型的指针或（左值）引用。</p><p>绑定到非类型整型参数的实参必须是一个常量表达式。绑定到指针或引用非类型参数的实参必须具有静态的生存期。</p><p>在模板定义内，模板非类型参数是一个常量值。在需要常量表达式的地方可以使用非类型参数。</p><h4 id="模板编译"><a href="#模板编译" class="headerlink" title="模板编译"></a>模板编译</h4><p>当编译器遇到一个模板定义时，它并不生成代码，只有当我们实例化出模板的一个特定版本时，编译器才会生成代码。</p><p>通常，当我们调用一个函数时，编译器只需要掌握函数的声明。类似的，当我们使用一个类类型的对象时，类定义必须是可用的，但成员函数的定义不必已经出现。因此，我们将类定义和函数声明放在头文件中，而将普通函数和类的成员函数的定义放在源文件中。</p><p><strong>模板不同</strong>，为了生成一个实例化版本，编译器需要掌握函数模板或类模板成员函数的定义，因此，与非模板代码不同，<strong>模板的头文件通常包括声明也包括定义</strong>。</p><h4 id="大多数编译错误在实例化期间报告"><a href="#大多数编译错误在实例化期间报告" class="headerlink" title="大多数编译错误在实例化期间报告"></a>大多数编译错误在实例化期间报告</h4><p>编译器会在三个截断报告错误：</p><ol><li>编译模板本身时。</li><li>编译器遇到模板使用时，该阶段检查模板实参数目是否正确、参数类型是否匹配，可检查的错误很少。</li><li>模板实例化时，只有这个阶段才能发现类型相关的错误。</li></ol><blockquote><p>保证传递给模板的实参支持模板所要求的操作，以及这些操作在模板中能够正确工作，是调用者的责任。</p></blockquote><h3 id="类模板"><a href="#类模板" class="headerlink" title="类模板"></a>类模板</h3><p>类模板作为类的蓝图，与函数模板不同，编译器无法为类模板推断模板参数类型，在使用类模板时，我们必须在类模板名后的尖括号内提供额外信息。</p><h4 id="类模板的定义"><a href="#类模板的定义" class="headerlink" title="类模板的定义"></a>类模板的定义</h4><pre class="line-numbers language-lang-c++"><code class="language-lang-c++">template <typename T> class Blob{public:    typedef T value_type;    typedef typename std::vector<T>::size_type size_type;    // 构造函数    Blob();    Blob(std::initializer_list<T> i1);    // Blob中的元素数目    size_type size() const { return data->size(); }    bool empty() const { return data->empty; }    // 添加和删除元素    void push_back(const T &t) { data->push_back(t); }    // 移动版本    void push_back(T &&t) { data->push_back(std::move(t)); }    void pop_back();    // 元素访问    T &back();    T &operator[] (size_type i);private:    std::shared_ptr<std::vector<T>> data;    // 若data[i]无效，则抛出msg    void check(size_type i, const std::string &msg) const;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在定义中有下面一句代码：</p><pre class="line-numbers language-lang-c++"><code class="language-lang-c++">typedef typename std::vector<T>::size_type size_type;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>其中，<code>typename</code>的作用是，在实例化模板之前，编译器不清楚<code>std::vector&lt;T&gt;</code>的具体类型，使用<code>typename</code>告诉编译器后者是一个类型。</p><p>在上述类模板的构造函数中，使用了如下的格式：</p><pre class="line-numbers language-lang-c++"><code class="language-lang-c++">Blob(std::initializer_list<T> i1);<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在上述语句中使用了标准库中的<code>initializer_list</code>类模板，该类可以使得我们使用下述语句对类进行初始化：</p><pre class="line-numbers language-lang-c++"><code class="language-lang-c++">Blob<int> ia2 = {0,1,2,3,4};<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="实例化类模板"><a href="#实例化类模板" class="headerlink" title="实例化类模板"></a>实例化类模板</h4><p>当编译器从Blob模板实例化出一个类时，它会重写Blob模板，将模板参数T的每个实例替换为给定的模板实参。</p><p>一个类模板的每个实例都形成一个独立的类。</p><h4 id="在模板作用域中引用模板类型"><a href="#在模板作用域中引用模板类型" class="headerlink" title="在模板作用域中引用模板类型"></a>在模板作用域中引用模板类型</h4><p>类模板的名字不是一个类型名，类模板用来实例化类型，而一个实例化的类型总是包含模板参数的。</p><p>一个类模板中的代码如果使用了另外一个模板，通常不将一个实际类型（或值）的名字用作其模板实参。通常将模板自己的参数当做被使用模板的实参。</p><p>无论何时使用模板都必须提供模板实参，提供给类模板中的模板的模板实参就是使用它的类模板的模板参数。</p><h4 id="类模板的成员函数"><a href="#类模板的成员函数" class="headerlink" title="类模板的成员函数"></a>类模板的成员函数</h4><p>类模板的成员函数具有和类模板相同的模板参数，因而，定义在类模板之外的成员函数就必须以关键字template开始，后接类模板参数列表。</p><p>在类外定义一个成员时，必须说明成员属于哪个类。而且，从一个模板生成的类的名字中必须包含其模板实参。当我们定义一个成员函数时，模板实参与模板形参相同。</p><pre class="line-numbers language-lang-c++"><code class="language-lang-c++">template <typename T>ret-type Blob<T>::member-name(parm-list);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>例如，上述类模板的check成员。</p><pre class="line-numbers language-lang-c++"><code class="language-lang-c++">template <typename T>void Blob<T>::check(size_type i, const std::string &msg) const{    if (i >= data->size())        throw std::out_of_range(msg);}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="类模板的构造函数"><a href="#类模板的构造函数" class="headerlink" title="类模板的构造函数"></a>类模板的构造函数</h4><p>与其他的在外部的类模板的普通成员函数一样，构造函数的定义要以模板参数开始。</p><pre class="line-numbers language-lang-c++"><code class="language-lang-c++">template <typename T>Blob<T>::Blob():data(std::make_shared<std::vector<T>>()) {}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h4 id="类模板成员函数的实例化"><a href="#类模板成员函数的实例化" class="headerlink" title="类模板成员函数的实例化"></a>类模板成员函数的实例化</h4><p>一个类模板的成员函数只有当程序用到它时才进行实例化。如果一个成员函数没有被使用，则它不会被实例化，这一特性使得即使某种类型不能完全符合模板操作的要求。</p><h4 id="在类代码内简化模板类名的使用"><a href="#在类代码内简化模板类名的使用" class="headerlink" title="　在类代码内简化模板类名的使用"></a>　在类代码内简化模板类名的使用</h4><p>在类模板自己的作用域内，可以直接使用模板名而不提供模板实参。当我们处于一个类模板的作用域中时，编译器处理模板自身引用时就好像我们已经提供了模板参数匹配的实参一样。</p><h4 id="在类模板外使用类模板名"><a href="#在类模板外使用类模板名" class="headerlink" title="在类模板外使用类模板名"></a>在类模板外使用类模板名</h4><p>当我们在类模板为定义其成员时，必须记住，我们并不在类的作用域内，只有遇到类名才表示进入类的作用域。</p><pre class="line-numbers language-lang-c++"><code class="language-lang-c++">template <typename T>BlobPtr<T> BlobPtr<T>::operator++(int){    BlobPtr ret = *this; // 保存当前状态    ++*this; // 推进一个元素；前置++检车递增是否合法    return ret; // 返回保存的状态}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>返回类型位于类的作用域之外，因此必须指定模板类型参数。在函数体内，已经进入了类的作用域，因而在定义ret时无需重复模板实参。</p><h4 id="类模板和友元"><a href="#类模板和友元" class="headerlink" title="类模板和友元"></a>类模板和友元</h4><ul><li>如果一个类模板包含一个<strong>非模板友元</strong>，则友元被授权可以访问所有模板实例。</li><li>如果<strong>友元自身是模板</strong>，类可以授权给所有友元模板实例，也可以只授权给特定实例。</li></ul><h5 id="一对一友好关系"><a href="#一对一友好关系" class="headerlink" title="一对一友好关系"></a>一对一友好关系</h5><p>类模板与另一个模板（类模板或函数模板）友好关系的常见形式是建立对应实例及其友元间的友好关系。</p><p>例如，Blob类将BlobPtr类和一个模板版本的Blob相等运算符定义为友元的情况。</p><blockquote><p>为了引用（类或函数）模板的一个特定实例，我们必须首先声明模板自身。一个模板的声明包括模板参数列表。</p></blockquote><pre class="line-numbers language-lang-c++"><code class="language-lang-c++">// 前置声明在Blob中声明友元所需template <typename T> class BlobPtr;template <typename T> calss Blob; // 运算符==中的参数需要template <typename T>    bool operator==(const Blob<T>&, const Blob<T>&);template <typename T> class Blob{    // 每个Blob实例将访问权限授予用相同类型实例化的BlobPtr和相等运算符    friend class BlobPtr<T>;    friend bool operator==<T>            (const Blob<T>&, const Blob<T>&);}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在上述代码中，<strong>友元的声明用Blob的模板形参作为它们自己的模板实参</strong>。因此，友好关系<strong>被限定</strong>在用相同类型实例化的Blob与BlobPtr相等运算符之间。</p><h5 id="通用和特定的模板友好关系"><a href="#通用和特定的模板友好关系" class="headerlink" title="通用和特定的模板友好关系"></a>通用和特定的模板友好关系</h5><p>一个类可以将另一个模板的每个实例都声明为自己的友元，也可以限定特定的实例为友元。</p><pre class="line-numbers language-lang-c++"><code class="language-lang-c++">template <typename T> class Pal;class C{    friend class Pal<C>;// 用类C实例化的Pal是C的一个友元    template <typename T> friend class Pal2; // 模板类Pal2的所有实例都是C的友元，这种情况无需前置声明};template <typename T> class C2{    // C2的每个实例将相同实例化的Pal声明为友元，需要前置声明    friend class Pal<T>;    template <typename X> friend class Pal2;// 模板类Pal2的所有实例都是C的友元     // Pal3是非模板类，它是C2所有实例的友元    friend class Pal3;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>为了让所有实例成为友元，友元声明中必须使用与类模板本身不同的模板参数</p></blockquote><h5 id="模板类型别名"><a href="#模板类型别名" class="headerlink" title="模板类型别名"></a>模板类型别名</h5><pre class="line-numbers language-lang-c++"><code class="language-lang-c++">typedef Blob<string> StrBlob;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h5 id="类模板的static成员"><a href="#类模板的static成员" class="headerlink" title="类模板的static成员"></a>类模板的static成员</h5><p>类模板可以声明static成员.。</p><pre class="line-numbers language-lang-c++"><code class="language-lang-c++">template <typename T> class Foo{public:    static std::size_t count() { return ctr; }private:    static std::size_t ctr;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>类模板的不同实例有其各自的static成员实例。所有<code>Foo&lt;X&gt;</code>类型的对象共享相同的<code>ctr</code>对象和<code>count</code>函数。</p><p>模板类的每个static数据成员都有且仅有一个定义，但是，类模板的每个实例都有一个独有的static对象，因而，将类模板的static数据成员也定义为模板:</p><pre class="line-numbers language-lang-c++"><code class="language-lang-c++">template <typename T>size_t Foo<T>::ctr = 0;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 编程基础 </category>
          
          <category> 编程语言 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 编程基础 </tag>
            
            <tag> C++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>C++基础-面向对象程序设计</title>
      <link href="/2019/09/03/c/mian-xiang-dui-xiang-cheng-xu-she-ji/"/>
      <url>/2019/09/03/c/mian-xiang-dui-xiang-cheng-xu-she-ji/</url>
      
        <content type="html"><![CDATA[<h2 id="面向对象程序设计"><a href="#面向对象程序设计" class="headerlink" title="面向对象程序设计"></a>面向对象程序设计</h2><p>[TOC]</p><h3 id="面向对象程序设计的核心思想"><a href="#面向对象程序设计的核心思想" class="headerlink" title="面向对象程序设计的核心思想"></a>面向对象程序设计的核心思想</h3><ol><li>数据抽象</li><li>继承</li><li>动态绑定</li></ol><p>使用数据抽象将类的接口和实现分离。</p><h3 id="继承"><a href="#继承" class="headerlink" title="继承"></a>继承</h3><p>通过继承联系在一起的类构成一种层次关系。层次关系的根部有一个<strong>基类</strong>，其他类则直接或间接地从基类继承而来，这些继承而来的类成为<strong>派生类</strong>。</p><p>基类负责定义在层次关系中所有类共同拥有的成员，而每个派生类定义各自特有的成员。</p><p>基类将类型相关的函数与派生类不做任何改变直接继承的函数区分对待。对于某些函数，基类希望它的派生类各自定义适合自身的版本，此时基类就将这些函数声明为<strong>。</strong></p><h3 id="动态绑定"><a href="#动态绑定" class="headerlink" title="动态绑定"></a>动态绑定</h3><p>有时我们希望使用同一段代码同时处理具有继承关系的类的对象，这时就需要用到<strong>动态绑定</strong>。例如如下一段代码：</p><pre class="line-numbers language-lang-c++"><code class="language-lang-c++">double print_total(Ostream &os, const Quote &item, size_t n){    // 根据传入的形参item的具体类型决定调用Quote::net_price或者Bulk_quote::net_price    double ret = item.net_price(n);    os << "ISBN: " << item.isbn() << "# sold: " <<n < "total due: " << ret << endl;    return ret;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在上述代码中，需要注意的地方是，<strong>传入的形参item的类型是基类Quote的引用，且调用的函数为虚函数</strong>。只有这样，才会在运行时进行动态绑定，如果形参的类型为类的具体对象或者调用的函数不是虚函数，就不会发生动态绑定，这时，所调用的函数是确定的。</p><blockquote><p>在C++语言中，当我们<strong>使用基类的引用（或指针）调用一个虚函数</strong>时将发生动态绑定。</p></blockquote><h3 id="定义基类"><a href="#定义基类" class="headerlink" title="定义基类"></a>定义基类</h3><p>定义基类如下：</p><pre class="line-numbers language-lang-c++"><code class="language-lang-c++">class Quote {public:    Quote() = default; // 默认构造函数    Quote(const std::string &book, double sales_price):bookNo(book), price(sales_price){}    std::string isbn() const { return bookNo; }    // 返回给定数量的书籍的销售总额    // 派生类负责改写并使用不同的折扣计算算法    virtual double net_price(std::size_t n) const    {        return n * price;    }    virtual ~Quote() = default; // 对析构函数进行动态绑定private:    std::string bookNo;protected:    double price = 0.0;};<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>基类通常都应该定义一个虚析构函数，即使该函数不执行任何实际操作</p></blockquote><h3 id="成员函数与继承"><a href="#成员函数与继承" class="headerlink" title="成员函数与继承"></a>成员函数与继承</h3><p>派生类可以继承其基类的成员，但对于虚函数这种与类型相关的操作，派生类必须定义自己的操作以覆盖基类的旧定义。</p><p>基类将其两种成员函数进行区分：</p><ol><li>基类希望其派生类进行覆盖的函数，需要将该类函数定义为虚函数，当使用指针或引用调用虚函数时，将进行动态绑定。任何构造函数之外的非静态函数（static）都可以被定义为虚函数。关键字virtual只能出现在类内部的声明语句之前，而不能用于类外部的函数定义。虚函数在派生类中隐式地也是虚函数。</li><li>成员函数没被声明为虚函数时，则其解析过程发生在编译而非运行时。这类普通的成员函数不存在动态绑定问题，行为是固定的。</li></ol><h3 id="访问控制和继承"><a href="#访问控制和继承" class="headerlink" title="访问控制和继承"></a>访问控制和继承</h3><p>派生类有权访问基类的公有成员，而不能访问私有成员。除了公有成员和私有成员之外，基类还有一种受保护成员，这一类成员只允许基类的派生类访问，而不允许其他用户访问。</p><h3 id="定义派生类"><a href="#定义派生类" class="headerlink" title="定义派生类"></a>定义派生类</h3><p>派生类必须将其继承而来的成员函数中需要覆盖的那些函数重新声明。</p><pre class="line-numbers language-lang-c++"><code class="language-lang-c++">class Bulk_quote : Quote {public:    Bulk_quote() = default;    Bulk_quote(const std::string &, double, std::size_t, double);    // 对基类中的函数进行覆盖        double net_price(std::size_t) const override;private:    std::size_t min_qty = 0;    double discount = 0.0;};<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在上述代码中，对基类的虚函数进行了覆盖，但有时不需要对虚函数进行覆盖，这时，派生类会直接继承其在基类中的版本。</p><p>在派生类中，可以使用override关键字显示的表示它使用某个成员函数覆盖了它继承的虚函数。</p><h4 id="派生类对象及派生类向基类的类型转换"><a href="#派生类对象及派生类向基类的类型转换" class="headerlink" title="派生类对象及派生类向基类的类型转换"></a>派生类对象及派生类向基类的类型转换</h4><p>可以将一个派生类的对象划分为两个部分：</p><ol><li>一个含有派生类自己定义的（非静态）成员的子对象。</li><li>派生类从基类继承而来的子对象。</li></ol><p>因为派生类中含有基类所对应的子对象，所以可以将基类的<strong>指针</strong>或者<strong>引用</strong>绑定到<strong>派生类对象中的基类部分</strong>。这种转换称为派生类到基类的类型转换。</p><p>这一转换过程是由编译器隐式进行的，意味着我们可以将派生类对象或者派生类对象的引用（指针）用在需要基类引用（指针）的部分。</p><blockquote><p>特别注意，只能是指针或引用。</p></blockquote><p>可以将基类的指针或引用绑定到派生类对象上有一层极为重要的含义：当使用基类的指针（或引用）时，实际上我们并不清楚该引用（或指针）所绑定的对象的真实类型，可能是基类的对象，也可能是派生类的对象。</p><blockquote><p>智能指针也支持派生类向基类的类型转换，即可以将一个派生类对象的指针存储在一个基类的智能指针中。</p></blockquote><h4 id="静态类型与动态类型"><a href="#静态类型与动态类型" class="headerlink" title="静态类型与动态类型"></a>静态类型与动态类型</h4><p>在使用存在<strong>继承关系</strong>的类型时，必须将一个变量或其他表达式的静态类型和动态类型区分开来。</p><ol><li><strong>静态类型</strong>：在<strong><em>编译时</em></strong>是已知的，它是变量声明时的类型或表达式生成的类型。</li><li><strong>动态类型</strong>：变量或表达式所表示的内存中实际存储的对象的类型，在<strong><em>运行时</em></strong>才可知。</li></ol><blockquote><p>如果表达式既不是引用也不是指针，则它的动态类型和静态类型永远一致。</p></blockquote><h4 id="类型转换注意点"><a href="#类型转换注意点" class="headerlink" title="类型转换注意点"></a>类型转换注意点</h4><ol><li><p>不存在从基类向派生类的隐式类型转换。因为一个基类的对象可能是派生类对象的一部分，也可能不是。</p><pre class="line-numbers language-lang-c++"><code class="language-lang-c++">Quote base;Bulk_quote* bulkP = &base; //错误：不能将基类转换为派生类Bulk_quote& bulkRef = base; //错误：不能将基类转换为派生类<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li><p>在对象之间不存在类型转换。派生类向基类的自动类型转换只对指针或引用类型有效，在派生类类型和基类类型之间不存在这样的转换。在初始化或赋值一个类类型的对象时，实际是在调用某个函数。初始化调用构造函数；赋值调用赋值运算符。这些函数接受引用作为参数，因而我们可以向基类的拷贝/赋值操作传递一个派生类的对象。构造函数和赋值运算符不是虚函数，因而调用的函数是确定的。将派生类对象赋值给基类对象时会调用基类的赋值运算符，因而只会对基类中存在的数据成员进行赋值，而不会赋值派生类中的成员，这与我们所期望的将派生类对象赋值给基类对象的操作是不同的。也就是说，派生类对象不属于基类的部分会被舍弃。</p></li></ol><h4 id="派生类构造函数"><a href="#派生类构造函数" class="headerlink" title="派生类构造函数"></a>派生类构造函数</h4><p><strong>对于从基类中继承而来的成员，派生类也必须使用基类的构造函数对这些部分进行初始化</strong>。类似于初始化成员的过程，派生类构造函数同样时通过构造函数初始化列表来将实参传递给基类构造函数的。</p><pre class="line-numbers language-lang-c++"><code class="language-lang-c++">// 在派生类的构造函数中，需要调用基类的构造函数对基类部分进行初始化Bulk_quote::Bulk_quote(const std::string &book, double p, std::size_t qyt, double disc):                        Quote(book, p), min_qty(qyt), discount(disc){}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>如果我们没有显式指定初始化基类部分时所使用的构造函数，基类部分会执行默认初始化。可以通过基类名加圆括号内的实参列表的形式为构造函数提供初始值。</p><blockquote><p>首先初始化基类的部分，然后按照声明的顺序依次初始化派生类的成员。</p></blockquote><h3 id="继承和静态成员"><a href="#继承和静态成员" class="headerlink" title="继承和静态成员"></a>继承和静态成员</h3><p>如果基类定义了一个静态成员，则在整个继承体系中只存在该成员的唯一定义。不论从基类中派生出多少个派生类，对于每个静态成员来说都只存在唯一的实例。</p><h3 id="被用作基类的类"><a href="#被用作基类的类" class="headerlink" title="被用作基类的类"></a>被用作基类的类</h3><p>当我们想将某个类用作基类时，则该类需要已经被声明且被定义而不仅仅是被声明（类不能派生它本身）。</p><h3 id="虚函数"><a href="#虚函数" class="headerlink" title="虚函数"></a>虚函数</h3><p>在动态绑定时，直到运行时才能知道到底调用了那个版本的虚函数，所以所有虚函数都必须有定义。</p><blockquote><p>动态绑定只有在我们通过指针或者引用调用虚函数时才会发生。</p></blockquote><p>当我们通过一个具有普通类型（非引用或指针）的表达式调用虚函数时，在编译时就会将所调用的函数版本确定下来。</p><blockquote><p><strong>C++的多态性</strong></p><p>面向对象编程的核心思想是多态性。我们把具有继承关系的多个类型成为多态类型，因为我们能使用这些类型的“多种形式”而无须在意它们的差异。<strong>引用或指针的静态类型和动态类型不同这一事实正是C++语言支持多态性的根本所在</strong>。</p><p>当我们使用基类的引用或指针调用基类中定义的一个函数时，我们并不知道该函数真正作用的对象是什么类型，可能是基类对象也可能是派生类对象。如果该函数是虚函数，则直到运行时才决定到底执行哪个版本。</p><p>而对非虚函数的调用在编译时进行绑定。类似的，通过对象进行的函数（无论虚函数或非虚函数）调用也在编译时绑定。因为对象的静态类型和动态类型是完全一致的，因而所调用的函数版本必定是确定的。</p></blockquote><h4 id="派生类中的虚函数"><a href="#派生类中的虚函数" class="headerlink" title="派生类中的虚函数"></a>派生类中的虚函数</h4><p>一个函数一旦被声明为虚函数，则其在所有派生类中都是虚函数。当派生类覆盖了某个虚函数时，该函数在基类中的形参必须与派生类中的形参严格匹配，如果函数名相同，但形参或返回值不匹配，则会产生新的函数。这一错误会给编程造成较大的麻烦，我们可以在派生类中使用override关键字来要求强制覆盖基类中的虚函数，此时如果参数不匹配，则编译器会报错。</p><p>我们也可以使用final关键字来禁止以后的派生类对给函数进行覆盖。</p><h4 id="虚函数与默认实参"><a href="#虚函数与默认实参" class="headerlink" title="虚函数与默认实参"></a>虚函数与默认实参</h4><p>虚函数同样可以定义默认实参，但需要注意的是，如果虚函数的调用使用了默认实参，则实参值由调用该虚函数的<strong>静态类型</strong>所确定。也就是说，如果使用基类的引用或指针调用虚函数，则虚函数的默认实参由基类中定义的默认实参决定，即使在实际运行时使用的是派生类中的虚函数版本。因而，当基类中虚函数的默认实参与派生类中的虚函数的默认实参不一致时，很容易发生我们所不期望的结果。</p><blockquote><p>如果虚函数使用默认实参，则基类和派生类中定义的默认实参最好一致。</p></blockquote><h4 id="回避虚函数的机制"><a href="#回避虚函数的机制" class="headerlink" title="回避虚函数的机制"></a>回避虚函数的机制</h4><p>有时，我们希望调用特定版本的虚函数，则可以使用作用域运算符：</p><pre class="line-numbers language-lang-c++"><code class="language-lang-c++">double undiscounted = baseP->Quote::net_price(42);<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>什么时候需要回避虚函数的默认机制？通常是当一个派生类的虚函数调用它覆盖的基类的虚函数版本时。</p><blockquote><p>如果一个派生类虚函数需要调用它的基类版本，但是没有使用作用域运算符，则在运行时该调用将被解析为对派生类版本自身的调用，从而导致无限递归。</p></blockquote><h3 id="抽象基类"><a href="#抽象基类" class="headerlink" title="抽象基类"></a>抽象基类</h3><p>有时，不希望用户创建某个类的对象，该类只是一种通用的概念，不存在某种具体的含义。此时，我们可以将该类中的虚函数定义为<strong>纯虚函数</strong>，纯虚函数是没有实际意义的。和普通的虚函数不同，纯虚函数无须定义，在函数体的位置（声明语句的分号之前）书写<code>=0</code>即可将一个虚函数说明为纯虚函数，<code>=0</code>只能出现在类内部的虚函数声明语句处。</p><pre class="line-numbers language-lang-c++"><code class="language-lang-c++">class Disc_quote : public Quote() {public:    Disc_quote() = defalue;    Disc_quote(const std::string& book, double price, std::size_t qyt, double disc):                Quote(book, price), quantity(qty), discount(disc) { }    double net_price(std::size_t) const = 0;//声明为纯虚函数protected:    std::size_t quantity = 0; // 折扣适用的购买量    double discount = 0.0; // 表示折扣的小数值};<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>同样需要定义该类的默认构造函数和带有四个参数的构造函数，尽管用户无法创建该类的对象，但是在创建该类的派生类的对象时，派生类需要调用该类的构造函数创建派生类对象中的Disc_quote部分。</p><p>也可以为纯虚函数提供定义，但函数体必须定义在类的外部。</p><h4 id="含有纯虚函数的类是抽象基类"><a href="#含有纯虚函数的类是抽象基类" class="headerlink" title="含有纯虚函数的类是抽象基类"></a>含有纯虚函数的类是抽象基类</h4><p>含有（或者未经覆盖直接继承）纯虚函数的类是抽象基类。抽象基类负责定义借口，后续的派生类可以选择覆盖该接口。我们无法从创建抽象基类的对象，抽象基类的派生类必须给出自己的纯虚函数的定义，负责派生类同样无法创建对象。</p><h4 id="派生类的构造函数只能初始化其直接基类"><a href="#派生类的构造函数只能初始化其直接基类" class="headerlink" title="派生类的构造函数只能初始化其直接基类"></a>派生类的构造函数只能初始化其直接基类</h4><p>在派生类的构造函数中，只能初始化其直接基类的子对象，不能初始化其间接基类的子对象。</p><h3 id="访问控制与继承"><a href="#访问控制与继承" class="headerlink" title="访问控制与继承"></a>访问控制与继承</h3><p>每个类除了控制自己的成员的初始化过程之外，还需要控制其成员对于派生类是否可访问。</p><h4 id="受保护的成员"><a href="#受保护的成员" class="headerlink" title="受保护的成员"></a>受保护的成员</h4><p>一个类使用protected关键字来说明那些希望与派生类分享但不希望被其他公共访问的成员。</p><ol><li>和私有成员类似，受保护的成员对于类的用户来说不可访问。</li><li>和公有成员类似，受保护的成员对于派生类的成员和友元来说是可访问的。</li><li>但要注意，派生类的成员和友元只能通过派生类的对象对受保护的成员进行访问，派生类本身是无法访问受保护成员的。</li></ol><pre class="line-numbers language-lang-c++"><code class="language-lang-c++">class Base{protected:    int prot_mem; //受保护的成员};class Sneaky : public Base{    friend void clobber(Sneaky &);//正确，可以通过派生类的对象进行访问    friend void clobber(Base &);//错误，不能访问Base的受保护成员    int j;}void clobber(Sneaky &s) { s.j = s.prot_mem = 0; }void clobber(Base &b) { b.prot_mem = 0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如果派生类及其友元可以直接访问基类对象的受保护成员，那么只要定义一个Sneaky类便可规避protected提供的访问保护。这样一来，虽然clobber并非Base的友元，但同样可以访问Base的受保护成员。</p><p>为了阻止上述现象的发生，必须作出如下假设：</p><blockquote><p>派生类的成员和友元只能访问派生类对象中的基类部分的受保护成员；对于普通的基类对象中的成员不具有特殊的访问权限。</p></blockquote><h4 id="公有、私有和受保护继承"><a href="#公有、私有和受保护继承" class="headerlink" title="公有、私有和受保护继承"></a>公有、私有和受保护继承</h4><p>某个类对其继承而来的成员的访问权限受两个因素影响：</p><ol><li>在基类中该成员的访问说明符；</li><li>在派生类的派生列表中的访问说明符。</li></ol><p>派生访问说明符的目的是控制派生类用户（包括派生类的派生类在内）对于基类成员的访问权限，不影响派生类自身的成员和友元对基类成员的访问权限。</p><p>不考虑继承的情况下，可以认为一个类有两个不同的用户，一个是普通用户，一个是类的实现者。普通用户编写的代码使用类的对象，这部分代码只能访问类的公有成员；类的实现者则负责编写类的成员和友元，成员和友元既能访问类的公有部分，也可以访问类的私有部分。</p><p>在普通用户和类的实现者之间存在第三种用户，即派生类，基类将希望派生类使用而不希望普通用户使用的成员声明为受保护的。普通用户不能访问受保护部分，派生类的成员和友元不能访问私有部分。</p><h4 id="改变个别成员的可访问性"><a href="#改变个别成员的可访问性" class="headerlink" title="改变个别成员的可访问性"></a>改变个别成员的可访问性</h4><p>有时，我们需要改变派生类继承的某个名字的访问级别，通过使用<code>using</code>声明可以达到这一目的：</p><pre class="line-numbers language-lang-c++"><code class="language-lang-c++">class Base{public:    std::size_t size() const { return n; }protected:    std::size_t n;};class Dereived : private Base { // 私有继承public:    using Base::size; // 使用using改变访问级别，为在基类中的访问级别（public）protected:    using Base::n;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>派生类只能为那些它本身可以访问的成员（公有和受保护成员）提供using声明。</p></blockquote><h4 id="默认的继承保护级别"><a href="#默认的继承保护级别" class="headerlink" title="默认的继承保护级别"></a>默认的继承保护级别</h4><p>默认情况下，<code>class</code>关键字定义的派生类是私有继承，<code>struct</code>关键字定义的派生类是公有继承。</p><p>这两个关键字之间的唯一的差别就是，默认成员访问说明符和默认派生访问说明符。</p><h3 id="继承中的类作用域"><a href="#继承中的类作用域" class="headerlink" title="继承中的类作用域"></a>继承中的类作用域</h3><p>每个类定义自己的作用域，在该作用域内我们定义类的成员。</p><blockquote><p>当存在继承关系时，派生类的作用域嵌套在其基类的作用域之内。</p></blockquote><p>如果一个名字在派生类的作用域内无法正确解析，则编译器将继续在外层的基类作用域中寻找该名字的定义。</p><h4 id="在编译时进行名字查找"><a href="#在编译时进行名字查找" class="headerlink" title="在编译时进行名字查找"></a>在编译时进行名字查找</h4><p>一个对象、引用或指针的静态类型决定该对象的那些类型可见，静态类型在编译时就已经确定。对于派生类中的对象，使用基类的指针指向它，那么无法使用基类指针访问派生类中新增的成员。</p><pre class="line-numbers language-lang-c++"><code class="language-lang-c++">class Disc_quote : public Quote {public:    std::pair<size_t, double> discount_policy() const        { return {quantity, discount}; }};Bulk_quote bulk;Bulk_quote *bulkP = &bulk; //静态类型与动态类型一致Quote *itemP = &bulk;      //静态类型与动态类型不一致bulkP->discount_policy();  //正确：bulkP的类型是Bulk_quote*itemP->discount_policy();  //错误：itemP的类型是Quote*<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="名字冲突与继承"><a href="#名字冲突与继承" class="headerlink" title="名字冲突与继承"></a>名字冲突与继承</h4><p>定义在内层作用域（派生类）中的名字将隐藏定义在外城作用域（基类）的名字。</p><p>但我们可以使用作用域运算符使用被内层作用域隐藏的成员。</p><blockquote><p>除了覆盖继承而来的虚函数之外，派生类最好不要重用其他定义在基类中的名字。</p></blockquote><h5 id="名字查找与继承"><a href="#名字查找与继承" class="headerlink" title="名字查找与继承"></a>名字查找与继承</h5><p><code>p-&gt;mem()</code>或<code>obj.mem()</code>:</p><ol><li>编译器首先确定p或者obj的静态类型</li><li>在该静态类型对应的类中查找<code>mem</code>（依据名字进行查找，而不管形参列表），如果找不到，则依次在直接基类中不断查找直至到达继承链的顶端，如果查找完整个继承链仍旧未找到，编译器报错。</li><li>找到<code>mem</code>，则进行常规类型检查，以确定调用是否合法。</li><li>合法，则根据调用的是否时虚函数而进行不同的操作：<ol><li>如果是虚函数且使用引用或指针进行调用，则编译器产生的代码将在运行时确定虚函数的版本，依据对象的动态类型。</li><li>否则，编译器产生常规函数调用。</li></ol></li></ol><h4 id="名字查找先于类型检查"><a href="#名字查找先于类型检查" class="headerlink" title="名字查找先于类型检查"></a>名字查找先于类型检查</h4><blockquote><p>内层作用域的函数不会重载声明在外层作用域的函数，而是直接隐藏。因而定义派生类中的函数也不会重载其基类中的成员，如果派生类中的而成员与基类的成员重名，则即使两者的形参列表不同，派生类也将在其作用域内直接隐藏基类的成员。</p></blockquote><p>所以，基类与派生类中的虚函数必须具有相同的形参列表，否则无法通过基类的引用或指针调用派生类的虚函数。</p><h4 id="覆盖重载的函数"><a href="#覆盖重载的函数" class="headerlink" title="覆盖重载的函数"></a>覆盖重载的函数</h4><p>对于类来说，成员函数无论是否是虚函数都可以被重载。派生类可以覆盖重载函数的0个或多个实例。如果派生类希望所有的重载版本对于它来说都是可见的，那么它就需要覆盖所有的版本，或者一个都不覆盖。</p><p>正如上一小节所说，派生类一旦声明了一个和基类重载函数同名的函数，派生类将会覆盖基类的所有重载函数。有时候，我们只希望覆盖基类的重载函数集合中的而一个函数，继承剩余的重载函数，如果给每一个重载函数的版本都定义一个覆盖版本的化将会非常麻烦。</p><p>可以为重载的成员提供一条<code>using</code>声明语句，这样就无须覆盖基类的每一个重载版本。<code>using</code>只需要成员函数的名称即可，而不需形参列表，一条基类成员函数的<code>using</code>声明语句就可以把该函数的所有重载实例添加到派生类作用域中，派生类只需定义自己特定格式的函数即可。</p><h3 id="构造函数与拷贝控制"><a href="#构造函数与拷贝控制" class="headerlink" title="构造函数与拷贝控制"></a>构造函数与拷贝控制</h3><p>位于继承体系中的类也需要控制当其对象执行一系列操作时发生什么样的行为，包括创建、拷贝、移动、赋值和销毁。</p><h4 id="虚析构函数"><a href="#虚析构函数" class="headerlink" title="虚析构函数"></a>虚析构函数</h4><p>基类通常应该定义一个虚析构函数，以对继承体系中的对象进行动态分配。</p><p>delete一个动态分配的对象的指针时将执行析构函数。如果该动态指针指向继承体系中的某个类型，则有可能出现指针的静态类型与被删除对象的动态类型不符的情况。这时，如果使用静态类型的析构函数删除动态类型的对象，将会出现未定义的情况。为了避免这一情况，在基类中将析构函数定义为虚函数以确保执行正确的析构函数版本。</p><pre class="line-numbers language-lang-c++"><code class="language-lang-c++">class Quote{public:    // 如果我们删除的是一个指向派生类对象的基类指针，则需要虚析构函数    virtual ~Quote() = default;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>虚析构函数的虚属性也会被继承。只要基类的析构函数是虚函数，就能确保当我们delete基类指针时将运行正确的析构函数版本。</p><p>注意，基类有析构函数时，并不一定同样需要拷贝和赋值操作。</p><blockquote><p>虚析构函数将阻止编译器合成移动操作。</p></blockquote><h4 id="合成拷贝控制与继承"><a href="#合成拷贝控制与继承" class="headerlink" title="合成拷贝控制与继承"></a>合成拷贝控制与继承</h4><p>基类或派生类的合成拷贝控制成员的行为与其他合成的构造函数、赋值运算符或析构函数类似：他们对类本身的成员依次进行初始化、赋值或销毁操作。</p><p>除此之外，这些合成的成员还负责使用直接基类中对应的操作对一个对象的直接基类部分进行初始化、赋值或销毁的操作。</p><h4 id="派生类的拷贝控制成员"><a href="#派生类的拷贝控制成员" class="headerlink" title="派生类的拷贝控制成员"></a>派生类的拷贝控制成员</h4><p>派生类的构造函数在其初始化阶段不但要初始化派生类自己的数据成员，还要初始化其基类的成员。因此，派生类的拷贝和移动构造函数在拷贝和移动自由成员的同时，也要拷贝和移动基类部分的成员。同样，派生类的赋值运算符也必须为其基类部分的成员赋值。</p><p>不同的是，派生类的析构函数只负责销毁派生类自己的成员，派生类的基类部分是隐式自动销毁的。</p><blockquote><p>当派生类定义了拷贝和移动操作时，该操作负责拷贝和移动包括基类部分成员在内的整个对象。</p></blockquote><p>默认情况下，基类默认构造函数初始化派生类对象的基类部分，如果我们想拷贝（或移动）基类部分，则必须在派生类的构造函数初始值列表中显式地调用基类的拷贝（或移动）构造函数。</p>]]></content>
      
      
      <categories>
          
          <category> 编程基础 </category>
          
          <category> 编程语言 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 编程基础 </tag>
            
            <tag> C++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>C++基础-类基础</title>
      <link href="/2019/09/03/c/lei-ji-chu/"/>
      <url>/2019/09/03/c/lei-ji-chu/</url>
      
        <content type="html"><![CDATA[<h2 id="const成员函数"><a href="#const成员函数" class="headerlink" title="const成员函数"></a>const成员函数</h2><blockquote><p>指向非常量的常量指针无法被绑定至常量</p></blockquote><p>在默认情况下，类的this指针的类型是指向类类型非常量版本的常量指针，这一设定意味着我们无法将this指针绑定至类类型的常量上。也就是说我们无法使用常量对象调用普通的成员对象，为了提高程序的兼容性，可以将this声明为指向常量的常量指针，为了达到之一目的可以在成员函数的参数列表之后加入<code>const</code>关键字，表示this指向常量，称这样的成员函数为常量成员函数。</p><pre class="line-numbers language-lang-c++"><code class="language-lang-c++">std::string isbn() const { return bookNo; }<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="构造函数"><a href="#构造函数" class="headerlink" title="构造函数"></a>构造函数</h2><p>类通过一个或几个特殊的成员函数控制其对象的初始化过程，这些函数称为构造函数。构造函数初始化类对象的数据成员，只要有类的对象被创建，就会指向构造函数。</p><blockquote><p>类的构造函数不能被声明为const，因为直到构造函数完成初始化过程，对象才能真正获得常量属性，在此之前，我们需要向对象中写入数值。</p></blockquote><p>类通过一个特殊的构造函数控制默认初始化过程，这个函数叫做<strong>默认构造函数</strong>，编译器创建的构造函数又称为<strong>合成的默认构造函数。</strong>默认构造函数按照如下规则初始化类的数据成员：</p><ul><li>如果存在类内初始值，用它初始化成员。</li><li>否则，默认初始化。</li></ul><p><strong>有些类不能依赖于合成的默认构造函数</strong></p><p>原因如下：</p><ol><li>当我们定义了自己的构造函数时，编译器便不会为我们的类合成默认构造函数，需要自己定义默认构造函数。</li><li>合成的默认构造函数可能会执行错误的操作。如果类内包含有内置类型或者符合类型的成员，则只有当这些成员全部被赋予了类内的初始值时，该类才适合于使用合成的默认构造函数。</li><li>编译器无法为一些类合成默认构造函数，如类中包含的其他类没有默认的构造函数时。</li></ol><blockquote><p><strong>当我们定义了其他构造函数时，也必须定义一个默认构造函数</strong>。</p></blockquote><p>如果没有在构造函数的初始值列表中显示地初始化成员，则该成员将在构造函数体之前执行默认初始化。有时候，在构造函数中不使用初始化列表，而是在函数体中使用赋值操作。这一做法有时是没有问题的，但对于有些必须进行初始化的类型而言，这一做法便不可取。例如，当成员为const或者引用时，就必须对其进行初始化，而不能采用赋值操作为其赋值。</p><pre class="line-numbers language-lang-c++"><code class="language-lang-c++">class COnstRef{public:    ConstRef(int ii);private:    int i;    const int ci;    int &ri;}ConstRef::COnstRef(int ii){    i = ii;    ci = ii;//不能向const赋值    ri = i;//ri为引用，未被初始化}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>初始化const或者引用类型的数据成员的唯一机会就是通过构造函数初始值，因而该构造函数的正确形式为：</p><pre class="line-numbers language-lang-c++"><code class="language-lang-c++">ConstRef::ConstRef(int ii): i(ii), ci(ii), ri(i) {}<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><blockquote><p>如果成员是const、引用个、或者属于某种未提供默认构造函数的类类型，我们必须通过构造函数初始值列表为这些成员提供初值。</p></blockquote><p>在构造函数，成员的初始化顺序与它们在类定义中的出现顺序一致。不受初始值列表中的顺序的影响。</p><h3 id="默认构造函数的作用"><a href="#默认构造函数的作用" class="headerlink" title="默认构造函数的作用"></a>默认构造函数的作用</h3><p>当对象被默认初始化或值初始化时自动执行默认构造函数。</p><ol><li><p>默认初始化发生的情况：</p><ol><li>在块作用域内不适用任何初始值定义一个非静态变量或者数组。</li><li>一个类本身含有其他类类型的成员，同时该类使用合成的默认构造函数。</li><li>类类型的成员未在构造函数初始值列表中显式地初始化。</li></ol></li><li><p>值初始化</p><ol><li>数组初始化过程中提供的初始值数量小于数组的大小。</li><li>不使用初始值定义一个局部静态变量。</li><li>使用形如T()的表达式显式地请求值初始化。</li></ol></li></ol><h2 id="拷贝、赋值和析构"><a href="#拷贝、赋值和析构" class="headerlink" title="　拷贝、赋值和析构"></a>　拷贝、赋值和析构</h2><p>类还需要控制拷贝、赋值和销毁对象时发生的行为。当我们初始化变量、以值的方式传递或返回一个参数时会发生对象的拷贝操作；使用赋值运算符时会发生对象的赋值操作；当对象不在存在时会发生销毁操作。</p><h2 id="类的访问控制与封装"><a href="#类的访问控制与封装" class="headerlink" title="类的访问控制与封装"></a>类的访问控制与封装</h2><p>封装的作用就是限制用户对于类的接口的控制，我们使用<strong>访问说明符</strong>加强类的封装性。</p><ul><li><strong>public</strong>：该说明符之后的成员可以在整个程序内被访问，通常将类的接口定义为public；</li><li><strong>private</strong>：该说明符之后的成员可以被类的成员函数访问，但不能被使用该类的外部代码访问。</li></ul><h2 id="class和struct关键字"><a href="#class和struct关键字" class="headerlink" title="class和struct关键字"></a>class和struct关键字</h2><p>这两个关键字的<strong>唯一区别</strong>是默认访问权限不一样，类可以在它的第一个访问说明符之前定义成员，对于这些成员的访问权限取决于所使用的关键字，<strong>struct说明这些成员是public的，class说明这些成员是private的</strong>。</p><h2 id="友元"><a href="#友元" class="headerlink" title="友元"></a>友元</h2><p>有一些函数虽然属于类的接口，但由于其并非类的成员函数，因而无法访问类的私有成员。</p><p>为了解决这一问题，类可以允许其他类或者函数访问它的非公有成员，方法是令其他类或者函数成为它的友元，增加一条以friend关键字开头的函数声明语句即可。</p><p>友元在类内的具体为知不限，也不受其所在区域的访问控制级别的限制，但一般，最好在类定义的开始或结束前的位置集中声明友元。</p><p>我们可以将一个类声明为另一类的友元，这样第一个类将可以访问第二个类的所有成员。</p><pre class="line-numbers language-lang-c++"><code class="language-lang-c++">class Screen{    friend class Window_mgr;};<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><blockquote><p>需要特别注意：友元关系不存在传递性。</p></blockquote><p>也可以只将类的某一个成员函数声明为友元，需明确指出该成员函数所属的类：</p><pre class="line-numbers language-lang-c++"><code class="language-lang-c++">class Screen{    friend void Window_mgr::clear(ScreenIndex);};<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>要想令某个成员函数作为友元，必须仔细组织程序的结构以满足声明和定义的彼此依赖关系。</p><ul><li>首先定义Window_mgr类，其中声明clear函数，但不能定义它。因为在clear使用Screen的成员之前，必须首先定义Screen。</li><li>定义Screen，包括对clear的友元声明。</li><li>定义clear成员函数。</li></ul><p>友元声明的作用仅仅是影响访问权限，不具有函数声明的作用，在对一个友元函数进行声明之前是无法对其进行调用的，这一点要特别注意。即使在类的内部定义了该友元函数，也必须在类的外部提供该函数的声明。</p><p>不要求类和非成员函数的声明必须在它们的友元之前。</p><pre class="line-numbers language-lang-c++"><code class="language-lang-c++">struce X{    friend void f() {/*可以直接在类的内部对友元函数进行定义*/}    X() {f();} //错误，f()尚未声明    void g();    void h();};void X::g() {return f();}//错误，f()尚未声明void f();void X::h() {return f();}//正确，f()已声明<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="类的可变数据成员"><a href="#类的可变数据成员" class="headerlink" title="类的可变数据成员"></a>类的可变数据成员</h2><p>我们希望能够修改类的某个数据成员，即使在一个const成员函数内，可以通过在变量的声明中加入<strong>mutable</strong>关键字完成。</p><h2 id="返回-this的成员函数"><a href="#返回-this的成员函数" class="headerlink" title="返回*this的成员函数"></a>返回*this的成员函数</h2><p>当我们将成员函数的返回类型定义为引用时，同时该成员函数返回<code>*this</code>时，那么该成员函数的返回值为调用该成员函数的对象本身，如下所示：</p><pre class="line-numbers language-lang-c++"><code class="language-lang-c++">Screen &Screen::set(char c){    contents[cursor] = c;    return *this; //将this对象作为左值返回}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如果我们把一系列这样的操作连接成一条表达式：</p><pre class="line-numbers language-lang-c++"><code class="language-lang-c++">myScreen.move(4, 0).set("#");<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这些操作将在同一个对象上进行。</p><p>从const成员函数返回<code>*this</code>时，意味着该成员函数返回的是一个常量对象，那么我们将不能随意地将该成员函数嵌入一组动作的序列中去。</p><h2 id="基于const关键字进行区分的重载"><a href="#基于const关键字进行区分的重载" class="headerlink" title="基于const关键字进行区分的重载"></a>基于const关键字进行区分的重载</h2><p>需要明确一点，<strong>常量对象是无法调用非常量的成员函数的</strong>，因而我们只能在一个常量对象上调用const成员函数。虽然，也可以使用非常量对象调用常量成员函数，但非常量成员函数更为匹配。</p><h2 id="类的作用域"><a href="#类的作用域" class="headerlink" title="类的作用域"></a>类的作用域</h2><p><strong>一个类就是一个作用域</strong>，当我们在类的外部定义成员函数时，一旦遇到了类名，定义的剩余部分就是在类的作用域之内，剩余部分包括参数列表和函数体。而位于类名之前的函数的返回值部分位与类的作用域之外。</p>]]></content>
      
      
      <categories>
          
          <category> 编程基础 </category>
          
          <category> 编程语言 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 编程基础 </tag>
            
            <tag> C++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>八角卷积-一种高效的卷积方式</title>
      <link href="/2019/09/03/lun-wen-yue-du/octaveconv/"/>
      <url>/2019/09/03/lun-wen-yue-du/octaveconv/</url>
      
        <content type="html"><![CDATA[<h2 id="Drop-an-Octave-Reducing-Spatial-Redundancy-in-Convolutional-Neural-Networks-with-Octave-Convolution"><a href="#Drop-an-Octave-Reducing-Spatial-Redundancy-in-Convolutional-Neural-Networks-with-Octave-Convolution" class="headerlink" title="Drop an Octave: Reducing Spatial Redundancy in Convolutional Neural Networks with Octave Convolution"></a>Drop an Octave: Reducing Spatial Redundancy in Convolutional Neural Networks with Octave Convolution</h2><h3 id="作者"><a href="#作者" class="headerlink" title="作者"></a>作者</h3><p>Yunpeng Chen</p><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>在自然图像中包含高频和低频两部分，其中高频通常编码细节信息、低频通常编码全局结构信息。同样可以将卷积层的输出特征图划分为高频和低频部分。在本文中，作者提出了一种根据频率对混合特征图进行特征化的方法，并设计了一种新的八音阶卷积操作，该操作将空间低频特征表示为低空间分辨率，降低了存储和计算消耗。OctConv是一个单个、通用、即插即用的模块，可以直接替代现有卷积方式而不用对网络结构进行调整。</p><p><img src="/2019/09/03/lun-wen-yue-du/octaveconv/1560134418989-1567350542617.png" alt="1560134418989"></p><h3 id="内容"><a href="#内容" class="headerlink" title="内容"></a>内容</h3><p>之前的高效网络结构的设计都集中在降低模型参数量、降低特征图通道冗余度上，但实际上，特征图的空间通道同样存在冗余，特征图的相邻位置之间存在共有的信息。类似于自然图像可以分解为表示平滑变化结构的低频空间频率和描述快速变化细节的高频部分，本文中提出了特征图的多频特征表示，将高频特征和低频特征存储于不同的分组中，该分组在特征图通道上进行。将特征图划分为高频和低频分组之后，因为低频图像的相邻位置之间存在共享信息，因此可以放心地将低频部分的空间分辨率降低，在降低空间冗余度的同时，降低计算复杂度。</p><p>本文的贡献如下：</p><ol><li>将卷积特征图划分为具有不同空间频率的分组，并使用与空间频率相关的不同的卷积核对各个分组进行处理。低频特征图空间分辨率的降低节省了存储和计算消耗。同时使得每一层获得更大的感受野，以捕捉更多的背景信息。</li><li>设计了一个即插即用的卷积操作。</li><li>所提出的OctConv可以获得明显的性能提升。</li></ol><h3 id="八音阶特征表示"><a href="#八音阶特征表示" class="headerlink" title="八音阶特征表示"></a>八音阶特征表示</h3><p>为了降低特征图的空间冗余度，本文引入了八音阶特征表示方法<strong>将特征图依据频率高低划分为高频和低频两个部分</strong>。假设卷积层的输入特征图为$X \in R^{c\times h\times w}$，在通道维度将特征图划分为$X={X^H,X^L}$，其中高频部分为$X^H\in R^{(1-\alpha)c\times h\times w}$，低频部分为$X^L\in R^{\alpha c\times \frac{h}{2}\times \frac{w}{2}}$，其中$\alpha \in [0,1]$表示高频和低频部分占输入通道的比例，可以看出低频部分的空间分辨率减半。</p><p><img src="/2019/09/03/lun-wen-yue-du/octaveconv/1560134464472-1567350554278.png" alt="1560134464472"></p><h3 id="八音阶卷积（OctConv）"><a href="#八音阶卷积（OctConv）" class="headerlink" title="八音阶卷积（OctConv）"></a>八音阶卷积（OctConv）</h3><p>设计八音阶卷积的目的有如下两个：</p><ol><li>在高频和低频各自相关的频率张量中，分别对高频和低频部分进行高效处理。</li><li>使得八音阶特征表示的高频和低频部分之间能够进行有效的信息交流。</li></ol><p>使用$X$和$Y$分别表示输入和输出特征，输出特征图$Y={Y^H, Y^L}$的高频部分可以表示为$Y^H=Y^{H \to H}+Y^{L \to H}$，低频部分表示为$Y^L=Y^{L \to L}+Y^{H \to L}$，其中$Y^{A \to B}$表示从特征图分组A到特征图分组B的卷积更新，$Y^{H \to H}$，$Y^{L \to L}$表示频率内部更新，$Y^{H \to L}$，$Y^{L \to H}$表示频率间更新，如下图所示。</p><p><img src="/2019/09/03/lun-wen-yue-du/octaveconv/1560134674031-1567350564432.png" alt="1560134674031"></p><p>上图中，绿色箭头表示频率内信息更新，红色箭头表示频率间信息更新。</p><p><img src="/2019/09/03/lun-wen-yue-du/octaveconv/1560134913414-1567350573658.png" alt="1560134913414"></p><p>为了计算上述四个项目，如上图所示，将卷积和划分为两部分$S=[W^H, W^L]$，分别表示输入特征的高频、低频两部分的卷积。每一部分可进一步划分为$W^H=[W^{H \to H}, W^{L \to H}]$，$W^L=[W^{L \to L}, W^{L=H \to H=L}]$。对于高频部分，位置$[p,q]$处，频率内的特征更新使用普通的卷积操作，而在进行频率间特征更新时，为了避免计算和存储上采样得到的特征图，将上采样操作融合进卷积操作中，如下式所示：</p><p><img src="/2019/09/03/lun-wen-yue-du/octaveconv/Screenshot from 2019-06-10 10-28-06-1567350591251.png" alt=""></p><p>同样，对于低频部分，频率内卷积使用普通的卷积操作。对于频率间卷积，同样将下采样操作融合进卷积操作中。给p乘以2表示下采样操作，同时加上半个步长使得下采样图和输入相匹配。因为带步长的卷积会导致误匹配，因而使用平均池化得到近似值，如下式所示。</p><p><img src="/2019/09/03/lun-wen-yue-du/octaveconv/1560134957064.png" alt="1560134957064"></p><p>可以将卷积操作表示为下式：</p><p><img src="/2019/09/03/lun-wen-yue-du/octaveconv/1560135280812.png" alt="1560135280812"></p><p>可以看出低频部分由高频向低频的转换使用了池化操作，而非带步长的卷积，因为带步长的卷积会导致如下图所示的为知偏移。</p><p><img src="/2019/09/03/lun-wen-yue-du/octaveconv/1560135452420.png" alt="1560135452420"></p><p>上图中，首先使用步长为2的卷积将特征图的空间分辨率缩小为1/2，表示由高频向低频的变换，经过进一步卷积后得到低频部分的输出。紧接着，这一部分特征图将会在下一层中，经过上采样从低频变换至高频，本应在左上角的特征将会偏移至中心位置。</p><h3 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h3><p>如下图所示：</p><p><img src="/2019/09/03/lun-wen-yue-du/octaveconv/1560135726540.png" alt="1560135726540"></p><p>每一条曲线的黑色点表示原始的模型，横坐标表示FLOPS（log），纵坐标表示top-1准确率。通过调节比例$\alpha$可以在性能和模型大小之间进行权衡，在与原始模型性能持平的情况下，模型大小在50%左右，提升模型的大小，性能会超过原始模型的性能。可见，该卷积方式可以在保持甚至提升模型性能的情况下降低模型的大小。</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
          <category> 卷积方式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 论文阅读 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux基础指令</title>
      <link href="/2019/07/22/cao-zuo-xi-tong/linux/linux-ji-chu-zhi-ling/"/>
      <url>/2019/07/22/cao-zuo-xi-tong/linux/linux-ji-chu-zhi-ling/</url>
      
        <content type="html"><![CDATA[<h2 id="权限控制"><a href="#权限控制" class="headerlink" title="权限控制"></a>权限控制</h2><p>在Linux中，一个文件存在多种属性，包括<code>r</code>：读、<code>w</code>：写、<code>x</code>：执行等基本权限，以及是否为目录（<code>d</code>）、文件（<code>-</code>）或者连接文件（<code>l</code>）等属性。</p><p>可以使用下述属性对文件或文件夹的属性进行修改：</p><ul><li>chgrp：修改用户组</li><li>chown：修改文件所有者</li><li>chmod：修改文件权限</li></ul><p>当我们使用<code>ls -l</code>指令列出文件的权限时，一般如下所示：</p><pre class="line-numbers language-lang-shell"><code class="language-lang-shell">drwxrwxrwx<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>上述表示方法中，第一个字符表示文件的的属性，接下来的字符每三个为一组，分别表示文件所有者、用户组以及其它的属性。</p><h3 id="chmod"><a href="#chmod" class="headerlink" title="chmod"></a>chmod</h3><p>可以使用chmod指令修改文件或文件夹的权限，其用法如下：</p><ul><li><p>直接指定相应的权限</p><pre class="line-numbers language-lang-shell"><code class="language-lang-shell">chmod a=rwx test.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>指的是：给所有的用户都赋予<code>rwx</code>权限。</p></li><li><p>使用数字表示法</p><pre class="line-numbers language-lang-shell"><code class="language-lang-shell">chmod 777 test.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>r w x分别对应数字4 2 1，所赋予的权限即为对应数字之和，例如：上述命令表示：拥有者、用户组、其它所对应的使用权限均为rwx。</p></li></ul><h3 id="文件默认权限-umask"><a href="#文件默认权限-umask" class="headerlink" title="文件默认权限 umask"></a>文件默认权限 umask</h3><p>在创建文件时，其默认权限为（-rw-rw-rw-），即默认没有可执行权限，在创建目录时，其默认权限为（drwxrwxrwx），默认为所有权限均开放。</p><p>可以使用指令<code>umask</code>设定所创建的文件或目录的默认权限，需要注意的是：umask的分数指的是“该默认值需要减去的权限”。</p><p><code>umask</code>默认的分数为<code>022</code>，可以直接使用如下指令修改<code>umask</code>的分数：</p><pre class="line-numbers language-lang-shell"><code class="language-lang-shell">umask 002<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>新建文件时，若使用了<code>umask</code>指令，则默认权限为：</p><pre class="line-numbers language-lang-shell"><code class="language-lang-shell">(-rw-rw-rw-)-(-----w--w-)==>-rw-r--r--<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>新建目录时，默认权限为：</p><pre class="line-numbers language-lang-shell"><code class="language-lang-shell">(drwxrwxrwx)-(d----w--w-)==>drwxr-xr-x<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 操作系统 </category>
          
          <category> linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
            <tag> 操作系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch-tensor相关操作</title>
      <link href="/2019/07/19/pytorch/pytorch-tensor-xiang-guan-cao-zuo/"/>
      <url>/2019/07/19/pytorch/pytorch-tensor-xiang-guan-cao-zuo/</url>
      
        <content type="html"><![CDATA[<h1 id="Tensor及使用"><a href="#Tensor及使用" class="headerlink" title="Tensor及使用"></a>Tensor及使用</h1><h2 id="tensor-requires-grad"><a href="#tensor-requires-grad" class="headerlink" title="tensor.requires_grad"></a>tensor.requires_grad</h2><p>在创建张量后，如果未进行特殊指定，默认不对该张量进行梯度计算。需要注意的是，只有当一个张量的所有输入都不需要进行梯度计算时，该张量才不需要进行梯度计算。<br>在网络模型中，其中间参数是默认进行求导的，因而网络的输出也默认是需要求导的。<br>在写代码的过程中，<strong>不要</strong>把网络的输入和 Ground Truth 的 <code>requires_grad</code> 设置为 True。虽然这样设置不会影响反向传播，但是需要额外计算网络的输入和 Ground Truth 的导数，增大了计算量和内存占用不说，这些计算出来的导数结果也没啥用。因为我们只需要神经网络中的参数的导数，用来更新网络，其余的导数都不需要。<br>通过使用该方法，可以将模型的部分参数设置为不需要进行求导。这一做法常被用于迁移学习中，对模型的一部分参数进行冻结，只更新其余的参数，官方例子如下。</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">model = torchvision.models.resnet18(pretrained=True)for param in model.parameters():    param.requires_grad = False# 用一个新的 fc 层来取代之前的全连接层# 因为新构建的 fc 层的参数默认 requires_grad=Truemodel.fc = nn.Linear(512, 100)# 只更新 fc 层的参数optimizer = optim.SGD(model.fc.parameters(), lr=1e-2, momentum=0.9)# 通过这样，我们就冻结了 resnet 前边的所有层，# 在训练过程中只更新最后的 fc 层中的参数。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="torch-no-grad"><a href="#torch-no-grad" class="headerlink" title="torch.no_grad()"></a>torch.no_grad()</h2><p>虽然可以使用第一条所介绍的<code>requires_grad</code>方法对单个张量进行梯度设置，但一个模型中存在大量的张量，逐个进行张量的设置会非常麻烦。这时就使用这一方法，对张量进行批量管理。<br>在我们对已训练完成的模型进行评估时，出来使用<code>model.eval()</code>将模型设置为评估模式之外，如果为了节省内存、显存，可以使用<code>torch.no_grad()</code>将模型中的所有参数设置为不进行梯度计算的模式。</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">x = torch.randn(3, requires_grad = True)print(x.requires_grad)# Trueprint((x ** 2).requires_grad)# Truewith torch.no_grad():    print((x ** 2).requires_grad)    # Falseprint((x ** 2).requires_grad)# True<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="tensor-data"><a href="#tensor-data" class="headerlink" title="tensor.data"></a>tensor.data</h2><p>在0.4版本之后，<code>Variable</code>被取消，统一使用<code>tensor</code>代替，<code>.data</code>本来是被用来从<code>Variable</code>中获取<code>tensor</code>的，现在被用来从<code>tensor</code>中获取一个具有同样的数据和不进行梯度计算的版本，两者共享内存空间，也就是说修改两者中的任意一个都会导致另一个值被修改。</p><h2 id="tensor-detach"><a href="#tensor-detach" class="headerlink" title="tensor.detach()"></a>tensor.detach()</h2><p>Pytorch的自动求导系统不会跟踪<code>tensor.data</code>的变化，因而可能会导致求导结果出错。而<code>torch.detach()</code>会被自动求导系统追踪。如下例所示：</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">a = torch.tensor([7., 0, 0], requires_grad=True)b = a + 2print(b)# tensor([9., 2., 2.], grad_fn=<AddBackward0>)loss = torch.mean(b * b)b_ = b.detach()b_.zero_()print(b)# tensor([0., 0., 0.], grad_fn=<AddBackward0>)# 储存空间共享，修改 b_ , b 的值也变了loss.backward()# RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在上述例子中，pytorch的自动求导系统进行了报错，出错的原因在于，b的值在进行反向传播之前被修改，这一修改会导致求导出错。<code>.detach()</code>之后的修改会被追踪，但当我们使用<code>.data</code>时，pytorch不会进行报错。</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">a = torch.tensor([7., 0, 0], requires_grad=True)b = a + 2print(b)# tensor([9., 2., 2.], grad_fn=<AddBackward0>)loss = torch.mean(b * b)b_ = b.datab_.zero_()print(b)# tensor([0., 0., 0.], grad_fn=<AddBackward0>)loss.backward()print(a.grad)# tensor([0., 0., 0.])# 其实正确的结果应该是：# tensor([6.0000, 1.3333, 1.3333])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="设备的切换"><a href="#设备的切换" class="headerlink" title="设备的切换"></a>设备的切换</h2><p>在0.4之前，一般使用<code>.cuda()</code>方法将张量或模型移动至GPU中，在需要进行设备的切换时，这一做法显得比较麻烦。0.4之后增加了<code>.to(device)</code>操作，这样，只需要在程序的开始指定所使用的设备即可。</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")a = torch.rand([3,3]).to(device)# 干其他的活b = torch.rand([3,3]).to(device)# 干其他的活c = torch.rand([3,3]).to(device)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="GPU-Tensor-gt-Numpy"><a href="#GPU-Tensor-gt-Numpy" class="headerlink" title="GPU Tensor -&gt; Numpy"></a>GPU Tensor -&gt; Numpy</h4><p>在我们想把 GPU tensor 转换成 Numpy 变量的时候，需要先将 tensor 转换到 CPU 中去，因为 Numpy 是 CPU-only 的。其次，如果 tensor 需要求导的话，还需要加一步 detach（防止求导出错），再转成 Numpy 。</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">x  = torch.rand([3,3], device='cuda')x_ = x.cpu().numpy()y  = torch.rand([3,3], requires_grad=True, device='cuda').y_ = y.cpu().detach().numpy()# y_ = y.detach().cpu().numpy() 也可以# 二者好像差别不大？我们来比比时间：start_t = time.time()for i in range(10000):    y_ = y.cpu().detach().numpy()print(time.time() - start_t)# 1.1049120426177979start_t = time.time()for i in range(10000):    y_ = y.detach().cpu().numpy()print(time.time() - start_t)# 1.115112543106079# 时间差别不是很大，当然，这个速度差别可能和电脑配置# （比如 GPU 很贵，CPU 却很烂）有关。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="tensor-item"><a href="#tensor-item" class="headerlink" title="tensor.item()"></a>tensor.item()</h2><p>该方法只适用于tensor中包含单个值的情况，使用该方法会直接得到该tensor中所包含的值。当tensor中包含多个元素时，可以使用<code>tensor.tolist()</code>。</p><hr><center>![](https://pic2.zhimg.com/80/v2-7a79e86e8006918808455318cf425d61_hd.jpg)</center>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
          <category> 深度学习框架 </category>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 深度学习框架 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>目标检测评价指标-AP、mAP</title>
      <link href="/2019/05/26/shen-du-xue-xi/ji-chu-zhi-shi/mu-biao-jian-ce-ping-jie-zhi-biao-ap-map/"/>
      <url>/2019/05/26/shen-du-xue-xi/ji-chu-zhi-shi/mu-biao-jian-ce-ping-jie-zhi-biao-ap-map/</url>
      
        <content type="html"><![CDATA[<h2 id="AP、mAP的计算"><a href="#AP、mAP的计算" class="headerlink" title="AP、mAP的计算"></a>AP、mAP的计算</h2><h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><p>当我们完成目标检测模型的训练之后，需要合适的指标对模型的性能进行度量，常用的指标有AP、mAP两种。要了解AP和mAP，需要首先了解精度和召回率的概念，所谓精度指的是所有分类为正的样本中，真的为正的样本所占得比例；召回率指的是分类为正的样本占所有正样本的比例，即原始的正样本中有多少被模型正确地划分为正，形象的解释可以理解为下图：</p><p><center><img src="/2019/05/26/shen-du-xue-xi/ji-chu-zhi-shi/mu-biao-jian-ce-ping-jie-zhi-biao-ap-map/05/26/shen-du-xue-xi/ji-chu-zhi-shi/mu-biao-jian-ce-ping-jie-zhi-biao-ap-map/精度-召回率示意.png" title="精度-召回率示意"></center><br>图中false表示模型的划分结果为错，positive表示模型将样本划分为正样本，精度和召回率如图下部分所示。<br>以分类器为例，精度和召回率一般是无法同时满足的，精度高那么召回率便会降低。假设将所有的样本都划分为正样本，此时精度会很低，而召回率为1，即所有的正样本都被正确划分。单纯使用精度或者召回率是很难完整地度量一个模型的性能的，为了解决这一问题，便提出了AP(average precision)的概念。那么何为AP，将AP定义为精度、召回率曲线下的面积，如下图所示，以二分类问题为例。</p><p><center>![](https://arleyzhang.github.io/articles/c521a01c/1527520824881-1542379892017.png)</center></p><h2 id="AP的计算"><a href="#AP的计算" class="headerlink" title="AP的计算"></a>AP的计算</h2><p>由精度-召回率（RP）曲线可知，每一个召回率对应一个精度，那么如何得到不同的召回率和精度呢？</p><p><strong>1. 统计为TP的预测</strong><br>首先需要知道如何计算召回率和精度，在目标检测中，对于每一个样本图像，模型会给出多个预测框。我们需要首先统计出所给出的预测框中为TruePositive的预测框。一个预测框被判定为TruePositive需要满足的条件是：</p><blockquote><p>该预测框和与之匹配的ground truth（在所有的ground truth中具有最大的重合度，即IoU）的IoU大于给定的重合度阈值。</p></blockquote><p>对于模型给出的所有预测框，按照该条件找出其中所有为TruePositive的预测框。<br><strong>2. 得到精度-召回率曲线</strong><br>经过第一步的计算，所有的预测框都被打上了是否为TruePositive的标签，为了得到精度-召回率曲线，我们必须得到多个不同的召回率和精度。在VOC的计算方式中，是依据预测框所对应的置信度值进行计算。首先，针对某一个特定的类别，挑选出属于该类的预测框；然后在挑选得到的预测框中，给定一个置信度阈值，大于该阈值的被标记为TruePositive的预测框将被最终记作TruePositive，剩余的预测框将被标记为FalsePositive。设定不同的置信度阈值就会得到不同个数的TruePositive预测框，使用这些TruePositive预测框依据下述公式便可以分别计算得到该类别精度和召回率，每一个置信度对应一对精度、召回率值。</p><p><center>$Precision = \frac{TP}{TP+FP}$</center></p><p><center>$Recall = \frac{TP}{TP+FN}$</center><br>在实际编程实现时，可以首先按照置信度对预测框进行降序排列，然后从高到低依次对TruePositive的数目进行累加，这样相当于设定了0-1的置信度阈值，进而可以计算得到一系列的精度、召回率值。<br><strong>3. 对精度-召回率曲线下的面积进行积分得到AP</strong><br>经过第二步的计算，对于不同的类别，我们已经得到了相对应的精度-召回率曲线，接下来就是计算曲线下的面积，这里，我们采用积分的方式计算面积。在计算机中是无法精确计算得到曲线的积分值的，只能使用数值积分的方式。<br>采用近似AP的方式计算，公式如下：</p><p><center>$AP=\sum_{k=1}^N P(k) \Delta r(k)$</center><br>其中：</p><p><center>$\Delta r(k)=r(k)-r(k-1)$</center><br>以二分类问题得到的曲线为例，取相邻两点之间较大的精度为积分点。</p><p><center>![](https://arleyzhang.github.io/articles/c521a01c/1527520902790.png)</center><br><strong>4. 计算得到mAP</strong><br>经过第三步的计算，我们可以针对所有类别，分别得到各自的AP，接着，只需要对对所有类别的AP进行求和，除以类别数目便可得到mAP。</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
          <category> 目标检测 </category>
          
          <category> 评价指标 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 目标检测 </tag>
            
            <tag> 评价指标 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Faster R-CNN具体实现详解</title>
      <link href="/2019/05/08/shen-du-xue-xi/mu-biao-jian-ce/faster-r-cnn-ju-ti-shi-xian-xiang-jie/"/>
      <url>/2019/05/08/shen-du-xue-xi/mu-biao-jian-ce/faster-r-cnn-ju-ti-shi-xian-xiang-jie/</url>
      
        <content type="html"><![CDATA[<h2 id="Faster-R-CNN具体实现详解"><a href="#Faster-R-CNN具体实现详解" class="headerlink" title="Faster R-CNN具体实现详解"></a>Faster R-CNN具体实现详解</h2><p>本文翻译自：<a href="http://www.telesens.co/2018/03/11/object-detection-and-classification-using-r-cnns/" target="_blank" rel="noopener">原文</a></p><h3 id="图像预处理"><a href="#图像预处理" class="headerlink" title="图像预处理"></a>图像预处理</h3><p>在将图片送入网络之前首先执行如下的网络预处理步骤。在训练和前向传播过程中，以下步骤必须一致。均值向量（大小$1*3$，每一个图像通道一个均值）并非当前图像像素值的均值，而是针对所有训练和测试图片所设置的一个统一的初始值。图像预处理流程如下：</p><p><img src="/2019/05/08/shen-du-xue-xi/mu-biao-jian-ce/faster-r-cnn-ju-ti-shi-xian-xiang-jie/img_5aa46e9e0bbd7.png" alt=""></p><p>$tatgetSize$和$maxSize$分别为600，1000.</p><h4 id="网络组织"><a href="#网络组织" class="headerlink" title="网络组织"></a>网络组织</h4><p>R-CNN使用神经网络主要解决如下两个问题：</p><ol><li>识别输入图片中可能包含前景目标的区域（Region of Interest - RoI）。</li><li>计算每一个RoI中的类别概率分布-例如，计算RoI中包含特定类别的目标的概率，在此基础上，可以选择具有最高概率的类别作为分类结果。</li></ol><p>R-CNN主要包含三种类型的神经网络：</p><ol><li>Head</li><li>区域建议网络（Region Proposal Network, RPN）</li><li>分类网络</li></ol><p>R-CNN使用预训练网络（例如ResNet）的前几层从输入图片中提取特征，这一做法由迁移学习理论作为支持（将在一个数据集上训练得到的网络用于不同的问题是可能的）。网络的前几层检测一些通用的特征（如，边、颜色块等在不同的问题中都具有较好的区分性的特征）,而后几层学习到的更多是与特定问题相关的高层特征。在我们搭建的网路中，可以直接将后面几层移除或者在反向传播过程中对其参数进行更新。这些从预训练的网络的前几层迁移过来的层构成了”head”网络。</p><p>由”head”网络产生的卷积特征图将被送入RPN网络中，RPN网络使用一系列的卷积层和全连接层产生可能存在前景目标的RoI区域。接着将使用这些RoI区域从”head”网络产生的特征图中裁剪出相应的特征图区域，称为“crop pooling”.由裁剪池化得到的特征图区域将被送入分类网络，进而经过学习得到该RoI区域所包含的目标种类。</p><p>另一方面，ResNet的权重也可以使用如下方式进行初始化：</p><pre class="line-numbers language-lang-python"><code class="language-lang-python">n = m.kernel_size[0] * m.kernel_size[1] * m.out_channelsm.weight.data.normal_(0, math.sqrt(2. / n))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h3><p>下图分别展示了上述几种不同的网络模块，图中给出了每一层网络输出和输入特征的大小，这将有助于理解网络中的特征是如何进行转换的，$w,h$表示经过预测后的图片的大小。</p><p><img src="/2019/05/08/shen-du-xue-xi/mu-biao-jian-ce/faster-r-cnn-ju-ti-shi-xian-xiang-jie/img_5a9ffec911c19.png" alt=""></p><h3 id="实现细节：训练"><a href="#实现细节：训练" class="headerlink" title="实现细节：训练"></a>实现细节：训练</h3><p>在本节将详细介绍训练R-CNN所涉及到的步骤。一旦理解了训练的流程，理解推理过程将很容易，因为推理只用到了训练过程的一个子集。训练的目标是调整RPN、分类网络以及Head的权重。RPN的任务是产生RoIs区域，分类网络的任务是对每一个RoI给定一个类别分数。为了训练这些网络，我们需要得到相应的ground truths（即图片中所出现的目标的bounding boxes的坐标以及这些目标的类别）。这些信息已经由数据集的标定文件给出，这里有一些常用的通用数据集：</p><ol><li>PASCAL VOC: The <a href="http://host.robots.ox.ac.uk/pascal/VOC/voc2007/index.html" target="_blank" rel="noopener">VOC 2007 </a>database contains 9963 training/validation/test images with 24,640 annotations for 20 object classes.<ul><li>_Person:_ person</li><li>_Animal:_ bird, cat, cow, dog, horse, sheep</li><li>_Vehicle:_ aeroplane, bicycle, boat, bus, car, motorbike, train</li><li>_Indoor:_ bottle, chair, dining table, potted plant, sofa, tv/monitor<br>如下图：</li></ul></li></ol><p><img src="/2019/05/08/shen-du-xue-xi/mu-biao-jian-ce/faster-r-cnn-ju-ti-shi-xian-xiang-jie/person_06-1568626159382.jpg" alt=""></p><ol><li>COCO (Common Objects in Context): The <a href="http://cocodataset.org/#home" target="_blank" rel="noopener">COCO</a> dataset is much larger. It contains &gt; 200K labelled images with 90 object categories.</li></ol><p>在本次实现中，使用VOC2007数据集。</p><p>下面介绍两个常用概念:</p><ol><li><strong>Bounding Boxes Regression Coefficients</strong>(也称为regression coefficients或regression targets)<br>R-CNN的目标之一就是产生与目标边界尽可能匹配的bounding boxes。R-CNN通过使用回归系数对给定的bounding boxes（给定左上角坐标、宽、高）进行调整来得到匹配的bounding boxes。回归系数由如下方式得出：<br>分别将目标bounding boxes和原始bounding boxes的左上角坐标表示为：$T_x, T_y, O_x, O_y$，width/height表示为$T_w, T_h, O_w, O_h$。那么回归目标（将原始boxes转换为目标boxes的方程的系数）计算如下：</li></ol><script type="math/tex; mode=display">t _ { x } = \frac { \left( T _ { x } - O _ { x } \right) } { O _ { w } } , t _ { y } = \frac { \left( T _ { y } - O _ { y } \right) } { O _ { h } } , t _ { w } = \log \left( \frac { T _ { w } } { O _ { w } } \right) , t _ { h } = \log \left( \frac { T _ { h } } { O _ { h } } \right)</script><p>上述方程是可翻转的，给定回归系数以及原始boxes的左上角坐标、宽和高，便可以计算得到目标boxes的左上角坐标、宽和高。这一系数对无切仿射变换具有不变性，这一性质在计算分类损失时非常重要。因为目标的回归系数在原始比例的图片上计算得到的，而分类网络输出的回归系数是在由RoI池化所得到的正方形特征图上计算得到的。</p><p><img src="/2019/05/08/shen-du-xue-xi/mu-biao-jian-ce/faster-r-cnn-ju-ti-shi-xian-xiang-jie/img_5bac3708478ce-1024x479.png" alt=""></p><ol><li><p><strong>Intersection over Union (IoU) Overlap</strong><br> 我们需要一种度量给定得bounding boxes与另一bounding boxes得接近程度（与所使用的度量bounding boxes大小的单位无关）。这一度量方法需要满足，当两个bounding boxes完全重合时，结果为1，当两个bounding boxes完全不重合时，结果为0,同时要易于计算。常用的度量方式为交并比，计算方式如下所示：</p><p><img src="/2019/05/08/shen-du-xue-xi/mu-biao-jian-ce/faster-r-cnn-ju-ti-shi-xian-xiang-jie/img_5aa6f44a0a9c7-1568628026330.png" alt=""></p><p><img src="/2019/05/08/shen-du-xue-xi/mu-biao-jian-ce/faster-r-cnn-ju-ti-shi-xian-xiang-jie/img_5aa6f476535f7-300x292.png" alt=""></p></li></ol><p>有了以上概念之后，可以将训练过程划分为以下模块。一个封装了一系列逻辑步骤（例如，数据的流通）的层以及其他步骤，如，bounding boxes重合度的比较，执行nms等。</p><ul><li><p><strong>Anchors生成层</strong><br><strong>这一层生成固定数目的anchors</strong>。首先生成9个具有不同尺度、比例的anchors，接着将这9个anchors复制给输入图片上的每一个经过归一化的格子处（每一个格子都包含9个具有不同尺度、比例的anchors，格子的个数由输入图片大小和网络尺度缩小的stride决定）。</p></li><li><p><strong>Proposal Layer</strong><br>在anchors生成层产生的anchors的基础上，依据bounding boxes回归系数来产生经过转化的anchors。然后以每一个anchor属于前景目标的分数为依据，对anchors进行非极大抑制，以对anchors的数目进行进一步的微调。</p></li><li><p><strong>Anchor Target Layer</strong><br><strong>Anchor Target Layer</strong>的目的是产生一些好的anchors以及相对应的前景/背景类标、目标回归系数，以用于RPN的训练。该层的输出仅用于训练RPN，不用于分类层的训练。给定由anchors生成层生成的anchors，anchors target层将对前景/背景目标进行识别，其中与真实标定的重合率高于设定阈值的anchors将被识别为前景目标；与真实标定的重合率低于某一阈值的anchors将被识别为背景目标。</p></li><li><p><strong>RPN Loss</strong><br>RPN损失函数将在训练RPN网络是被最小化。由以下两部分构成：</p><ol><li>RPN所产生的bounding boxes中被正确划分为前景/背景的比例。</li><li>预测的bounding boxe与目标bounding boxes的回归系数的差距。</li></ol></li><li><p><strong>Proposal Target Layer</strong><br>对Proposal Layer产生的anchor进行微调，同时产生类别相关的bounding boxes回归目标，这些目标用于对分类网络进行训练，以得到好类别以及目标回归系数。</p></li><li><p><strong>ROI Pooling Layer</strong><br>依据proposal target layer产生的建议区域的bounding boxes坐标，使用空间转换网络对输入特征图进行采样，这些坐标一般不会位于整型边界，因而需要进行插值采样。</p></li><li><p><strong>Classification Layer</strong><br>分类层以ROI池化层的输出作为输入，将其通过一系列的卷积层后，送入两层全连接层，第一层对于每一个建议区域分别产生类别概率分布；第二层产生类别相关的回归系数。</p></li><li><p><strong>Classification Loss</strong><br>与RPN损失相似，在训练分类层时会最小化分类误差。在反向传播的过程中，误差的梯度同样会流入RPN网络，所以对分类层进行训练时同样也会修改RPN网络的权重。分类误差由以下部分构成：</p><ol><li>由RPN产生的建议区域被正确分类的比例。</li><li>预测的回归系数与目标回归系数之间的差距。</li></ol></li></ul><p>下面将详细介绍每一层：</p><h4 id="Anchor-Generation-Layer"><a href="#Anchor-Generation-Layer" class="headerlink" title="Anchor Generation Layer"></a>Anchor Generation Layer</h4><p>针对整幅输入图像，产生一系列的具有不同尺度和比例的bounding boxes，即anchor boxes。对于所有图片来说，产生的anchor boxes是一样的，例如，与图片的内容无关。Anchor boxes中的一些将包含有目标，而大多数不包含目标。RPN的目标则是识别好的anchor boxes（那些更有可能包含目标的anchor）以及产生bounding boxes回归系数（将anchors转换为更好的bounding boxes）。<br>下图展示了如何生成这些anchor boxes。</p><p><img src="/2019/05/08/shen-du-xue-xi/mu-biao-jian-ce/faster-r-cnn-ju-ti-shi-xian-xiang-jie/img_5aa05d3ecef3e-1568626559915.png" alt=""></p><h4 id="Region-Proposal-Layer"><a href="#Region-Proposal-Layer" class="headerlink" title="Region Proposal Layer"></a>Region Proposal Layer</h4><p>目标检测算法需要将区域建议系统作为输入，区域建议网络会产生一系列稀疏（选择搜索法）或稠密（在deformable part models中使用的特征）的特征。R-CNN的第一个版本使用选择搜索法产生建议区域。在Faster R-CNN中，基于滑窗的技术被用于产生一系列稠密的候选框。接着RPN依据区域包含目标的概率对候选区域进行评分。Region Proposal Layer有两个目的：</p><ol><li>从一系列的anchor中，识别出前景和背景目标。</li><li>通过使用边框回归系数，对anchor的坐标和宽高进行调整，以得到更为精确的anchors（使其更加匹配真正的目标）。</li></ol><p>Region Proposal Layer包含RPN以及Proposal Layer、Anchor Target Layer 和Proposal Target Layer。具体细节描述如下：</p><h4 id="Region-Proposal-Network"><a href="#Region-Proposal-Network" class="headerlink" title="Region Proposal Network"></a>Region Proposal Network</h4><p><img src="/2019/05/08/shen-du-xue-xi/mu-biao-jian-ce/faster-r-cnn-ju-ti-shi-xian-xiang-jie/img_5aa0695484e3e-1568626586231.png" alt=""></p><p>RPN的输入为head网络产生的特征图，将该特征图经过一层卷积层（rpn_net）进行处理，后接ReLU激活。激活后的特征图再分别通过两个并行的大小为1x1的卷积层，分别产生前景/背景类别分数和相应的boundig boxes回归系数。Head networks的步长长度与产生anchors时的步长长度相匹配。</p><h3 id="Proposal-Layer"><a href="#Proposal-Layer" class="headerlink" title="Proposal Layer"></a>Proposal Layer</h3><p>Proposal Layer以anchor generation layer产生的anchors为输入，依据各anchors包含前景目标的概率对anchors进行NMS，以达到减少anchors数目的目的。同时，依据由RPN产生的边框回归系数对anchors进行转换。<br><img src="/2019/05/08/shen-du-xue-xi/mu-biao-jian-ce/faster-r-cnn-ju-ti-shi-xian-xiang-jie/img_5aa5766d53b63-1568626598678.png" alt=""></p><p>我们可以看出，在Proposal Layer中未引入任何的真实标定信息，只是在RPN网络所产生的候选框之间进行竞争，使用NMS留下那些得分较高的候选框。</p><h3 id="Anchor-Target-Layer"><a href="#Anchor-Target-Layer" class="headerlink" title="Anchor Target Layer"></a>Anchor Target Layer</h3><p>该层的目的是选择好的anchor boxes，用于训练RPN网络以达到以下目的：</p><ol><li>更好地区别前景和背景目标。</li><li>对于前景目标产生更优的边框回归系数。</li></ol><p>在进一步讲解Anchor Target Layer之前，我们将首先了解RPN损失是如何计算的。</p><h4 id="计算RPN-Loss"><a href="#计算RPN-Loss" class="headerlink" title="计算RPN Loss"></a>计算RPN Loss</h4><p>我们已经知道RPN层的目标是产生好的bounding boxes。为了达到这一目标，RPN必须学会从给定的anchor boxes中区分出前景和背景目标，并计算边框回归系数以对前景anchor boxes的位置、宽和高进行修正，使其更好地匹配前景目标。RPN损失正是以这种方式使得网络学到更好的行为。</p><p>RPN损失可以看作分类损失和边框回归损失之和。分类损失使用交叉熵损失对未被正确分类的boxes进行惩罚，边框回归损失使用真实边框回归系数（使用与前景anchor boxes最为匹配的ground truth boxes计算得到）与预测的边框回归系数（由RPN网络结构中的rpn_bbox_pred_net给出）之间的距离函数计算得出。</p><p>RPN损失如下：</p><p><img src="/2019/05/08/shen-du-xue-xi/mu-biao-jian-ce/faster-r-cnn-ju-ti-shi-xian-xiang-jie/quicklatex.com-142d5b70256748a64605bfc6e2f30ea9_l3.svg" alt=""></p><p><strong>Classification Loss:</strong></p><script type="math/tex; mode=display">cross\_entropy(predicted\_class, actual\_class)</script><p><strong>Bounding Box Regression Loss:</strong></p><p><img src="/2019/05/08/shen-du-xue-xi/mu-biao-jian-ce/faster-r-cnn-ju-ti-shi-xian-xiang-jie/quicklatex.com-79e8cbe4b5682f6abc719c54d768a4ae_l3.svg" alt=""></p><p>将所有前景anchor boxes的回归损失相加。不计算背景anchor boxes的回归损失，因为不存在ground truths与背景anchor boxes匹配。回归损失计算如下：</p><p><img src="/2019/05/08/shen-du-xue-xi/mu-biao-jian-ce/faster-r-cnn-ju-ti-shi-xian-xiang-jie/quicklatex.com-f26b9d082be79d08e06cdbeb5cfc1e3a_l3.svg" alt=""></p><p>分别对位置坐标和宽、高计算偏差，再求和，其中smooth_l1损失如下：</p><p><img src="/2019/05/08/shen-du-xue-xi/mu-biao-jian-ce/faster-r-cnn-ju-ti-shi-xian-xiang-jie/quicklatex.com-dae64c7ea8affa572e4b38b84688e1fd_l3-1568628171796.svg" alt=""></p><p>上式中$\sigma$任意选定（代码中设定为3）。注意，再python实现中，使用表示前景目标的mask aray（bbox_inside_weights）以向量运算的形式来计算损失，以避免for-if循环。</p><p>因而，为了计算损失，我们需要计算如下量：</p><ol><li>类标（前景或背景）以及anchor boxes的分数。</li><li>前景anchor boxes的目标回归系数。</li></ol><p>下面将展示anchor target layer是如何计算得出上述量的。首先选择出在图片内部的anchor boxes；接着，通过计算图像内的所有anchor boxes与所有ground truth boxes的IoU来选出好的前景boxes。基于重合度，以下两类boxesb被标记为<strong>前景</strong>：</p><ol><li>对于每一个ground truth box，与其有着最大重合度的anchor被设定为前景框。</li><li>与一些ground truth boxes的最大重合度超过了设定的阈值。</li></ol><p>如下图所示：</p><p><img src="/2019/05/08/shen-du-xue-xi/mu-biao-jian-ce/faster-r-cnn-ju-ti-shi-xian-xiang-jie/img_5aa13d4d911d3.png" alt=""></p><p>注意，只有与一些ground truth boxes的重合度超过给定的阈值的anchor boxes才会被选定为前景框。这一做法的目的是为了避免RPN进行一些无谓的学习任务（学习一些与最匹配的ground truth boxes相距较远的anchor boxes）。同样，重合度低于负样本阈值的anchor boxes将被归类为背景框。并不是所有未被划分为前景框的目标都会被划分为背景框。这些既未被划分为前景框，也未被划分未背景框的anchor boxes是不被关心的。在计算RPN损失时，不计算这些框。</p><p>有两个参数与我们最终得到的背景目标和前景目标的总数有关，分别是前景目标和背景目标的总数、前景目标占两者的比例。如果通过测试的前景目标的数目超过了阈值，我们便将这些超过部分的前景框随机标记为“don’t care”，同样，背景框中超出的部分将被标记未“don’t care”。</p><p>接着，我们计算前景框和与其相对应的ground truths boxes的边框回归系数。这一步是很容易的，依据给定公式进行计算即可。</p><p>总结该层的输入、输出如下：</p><p><strong>参数：</strong></p><ul><li>TRAIN.RPN_POSITIVE_OVERLAP: 确定anchor box是否是好的前景框 (Default: 0.7)</li><li>TRAIN.RPN_NEGATIVE_OVERLAP: 如果一个anchor与最匹配的ground truth box的重合度小于该阈值，则将其标定为背景。阈值大于RPN_NEGATIVE_OVERLAP但小于RPN_POSITIVE_OVERLAP的框被标记为“don’t care”。(Default: 0.3)</li><li>TRAIN.RPN_BATCHSIZE: 前景和背景框的总数。 (default: 256)</li><li>TRAIN.RPN_FG_FRACTION: 前景框所占比例 (default: 0.5).如果前景框的数目大于<br>TRAIN.RPN_BATCHSIZE$\times$TRAIN.RPN_FG_FRACTION, 超出的部分将被标记为 (随机选择索引) “don’t care”.</li></ul><p><strong>输入：</strong></p><ul><li>RPN Network Outputs (predicted foreground/background class labels, regression coefficients)</li><li>Anchor boxes (由anchor generation layer生成)</li><li>Ground truth boxes</li></ul><p><strong>输出：</strong></p><ul><li>好的foreground/background boxes以及相关类标。</li><li>目标框回归系数。</li></ul><p>其它几层，proposal target layer、RoI pooling layer、classfication layer用于产生计算分类损失所需的信息。正如我们介绍anchor target layer那样，将首先介绍计算分类层损失所需的信息。</p><h3 id="Calculating-Classification-Layer-Loss"><a href="#Calculating-Classification-Layer-Loss" class="headerlink" title="Calculating Classification Layer Loss"></a>Calculating Classification Layer Loss</h3><p>与RPN损失类似，分类层损失可以分为两部分-分类损失和边框回归损失。<br><img src="http://www.telesens.co/wp-content/ql-cache/quicklatex.com-a01bdc80cc44f16d0971e77943f816b7_l3.svg" alt=""></p><blockquote><p>RPN层与分类层的主要不同在于：RPN解决两分类问题-前景和背景，分类层需要处理所有的目标类别（外加背景类）。</p></blockquote><p>分类损失等于真实类别与预测类别之间的交叉熵损失，计算方式如下：<br><img src="/2019/05/08/shen-du-xue-xi/mu-biao-jian-ce/faster-r-cnn-ju-ti-shi-xian-xiang-jie/img_5aa1cd250f265-1.png" alt=""><br>在上述矩阵中，每一行表示一个样本属于各个类的分数，最后一列表示当前样本的真实类别索引（0表示背景）。交叉熵计算如下：<br><img src="/2019/05/08/shen-du-xue-xi/mu-biao-jian-ce/faster-r-cnn-ju-ti-shi-xian-xiang-jie/img_5aa1bf41503d4-1.png" alt=""></p><p>这里的bounding boxes的回归损失的计算方式与RPN中的计算方式类似，除了这里的回归系数是与类别相关的。网络针对每一个目标种类分别计算一个边框回归系数。很明显，目标回归系数只对正确的类别有效，正确的类别即与给定的anchor box有着最大的重合度的ground truth的类别。在计算回归系数损失时，使用mask矩阵标定anchor box所对应的正确类别。不正确的类别的回归系数则被忽略。mask矩阵的使用避免了复杂的for循环，而采用矩阵乘法的形式，更为高效。</p><p>在计算classification layer loss需要以下数值：</p><ul><li>预测的类标及网络回归系数（由分类网络输出）。</li><li>每一个anchor box的类别。</li><li>目标边框回归系数。</li></ul><p>下面将展示这些数值是如何通过proposal target和分类层得到的。</p><h3 id="Proposal-Target-Layer"><a href="#Proposal-Target-Layer" class="headerlink" title="Proposal Target Layer"></a>Proposal Target Layer</h3><p>Proposal Target Layer的作用是从proposal layer输出的RoIs中选择出有可能存在目标的RoIs。这些RoIs将被用于对head layer产生的特征图进行裁剪池化(crop pooling)，裁剪得到的小的特征图将被传入网络的剩余部分，进而计算得出预测的类别分数和边框回归系数。</p><p>与anchor target layer类似，选择好的proposals（与gt boxes有着最大重合度的）传入classification layer是很重要的。否则，classification layer所学习的将是无望的学习任务。</p><p>传入proposal layer target层的是由proposal layer计算得出的RoIs。使用每一个RoI与gt的重合度中最大的一个将RoI划分为前景或背景目标。最大重合度超过给定阈值（TRAIN.FG_THRESH, default: 0.5）的将被设定为前景目标。最大重合度位于阈值区间 TRAIN.BG_THRESH_LO 和 TRAIN.BG_THRESH_HI (default 0.1, 0.5)中的将被设定为背景目标。下面是一个称为“hard negative mining”的方法，该方法将识别起来较为困难的样本传入分类层。</p><p>该方法的目标是使得正样本和负样本的数目保持为常数。为了避免出现背景目标过少的情况，该算法通过随机重复一些背景目标的索引来补足batch中的差额。</p><p>接着，边框回归系数误差将在每一个RoI及其匹配的gt之间计算得到（包括背景RoI,因为对于这些背景目标，同样存在与其重叠的gt）。这些回归目标将被扩充至所有的类别，如下图所示：</p><p><img src="/2019/05/08/shen-du-xue-xi/mu-biao-jian-ce/faster-r-cnn-ju-ti-shi-xian-xiang-jie/img_5aa32302afc0b-1-1568626786970.png" alt=""></p><p>图中的bbox_inside_weights是一个掩模矩阵，只有前景目标所对应的正确的类别处的值为1，其他值为0，同样，背景目标所对应的值为0。因为在计算classification layer loss时，只有前景目标的边框回归损失才被包括在内，背景目标的边框回归损失不计。但在计算classification loss时，要计算背景目标，因为背景目标所属的类别为0.</p><p><strong>输入：</strong></p><ol><li>由 proposal layer产生的RoIs。</li><li>ground truth信息。</li></ol><p><strong>输出：</strong></p><ol><li>符合重合度标准的前景和背景目标。</li><li>RoIs的类别相关的目标回归系数。</li></ol><p><strong>参数：</strong></p><ol><li>TRAIN.FG_THRESH:（default: 0.5）用于选择前景目标。与gt的最大重合度高于该阈值的RoI被设定为前景目标。</li><li>TRAIN.BG_THRESH_HI: (default 0.5)</li><li>TRAIN.BG_THRESH_LO: (default 0.1)这俩个参数用于选择背景目标，最大重合度位于这两个数所指定的区间内的RoI被设定为背景目标。</li><li>TRAIN.BATCH_SIZE：（default 128）前景和被选中的背景目标的总数。</li><li>TRAIN.FG_FRACTION：（default 0.25）前景目标的数目不能超过BATCH_SIZE*FG_FRACTION。</li></ol><h3 id="Crop-Pooling"><a href="#Crop-Pooling" class="headerlink" title="Crop Pooling"></a>Crop Pooling</h3><p>Proposal target layer产生可能的ROIs，我们使用这些ROIs进行分类，同时使用边框回归系数进行训练。下一步是使用这些ROIs从由head network产生的特征图中抽取对应的特征。这些抽取得到的特征图将被用于剩下的网络层，进一步产生目标类别概率分布和每一个ROIs的边框回归系数。裁剪池化（Crop Pooling）的作用就是从卷积特征图中抽取ROIs对应的特征图。</p><p>裁剪池化的核心内容描述于“Spatial Transformation Networks” <a href="http://www.telesens.co/2018/03/11/object-detection-and-classification-using-r-cnns/#ITEM-1455-7" target="_blank" rel="noopener">(Anon. 2016)</a><a href="https://arxiv.org/pdf/1506.02025.pdf" target="_blank" rel="noopener">*</a>。<strong>目标是在输入特征图上使用一个扭曲函数(warping function)（2x3的仿射变换矩阵）来输出经过旋转的矩阵</strong>，如下图所示。\</p><p><img src="/2019/05/08/shen-du-xue-xi/mu-biao-jian-ce/faster-r-cnn-ju-ti-shi-xian-xiang-jie/img_5aa402baba3a1-1-1568626801970.png" alt=""></p><p>裁剪池化涉及以下两个步骤：</p><ol><li><p>对一个集合的目标坐标应用仿射变换，得到一个方格的源坐标。仿射变换的公式为：$\left[ \begin{array} { c } { x _ { i } ^ { s } } \\ { y _ { i } ^ { s } } \end{array} \right] = \left[ \begin{array} { l l l } { \theta _ { 11 } } &amp; { \theta _ { 12 } } &amp; { \theta _ { 13 } } \\ { \theta _ { 21 } } &amp; { \theta _ { 22 } } &amp; { \theta _ { 23 } } \end{array} \right] \left[ \begin{array} { l } { x _ { i } ^ { t } } \\ { y _ { i } ^ { t } } \\ { 1 } \end{array} \right]$，其中，$x _ { i } ^ { s } , y _ { i } ^ { s } , x _ { i } ^ { t } , y _ { i } ^ { t }$都是各自使用width/height归一化的坐标，因而$- 1 \leq x _ { i } ^ { s } , y _ { i } ^ { s } , x _ { i } ^ { t } , y _ { i } ^ { t } \leq 1$。</p></li><li><p>第二步，使用第一步产生的源坐标对输入（source）特征图进行采样得到目标（destination）特征图。每一对$\left( x _ { i } ^ { S } , y _ { i } ^ { s } \right)$都对应输入特征图中的一个空间位置，接着使用采样核（如双线性采样核）对该位置进行采样，最终得到输出图像上相对应的特定位置的值。</p></li></ol><p>Spatial transformation中所描述的采样方法是可微的，因而损失的梯度可以直接反向传播回输入特征图和采样的方格坐标。</p><p>幸运的是，pytroch提供了裁剪池化对应的API，API中的两个函数分别对应上述两个步骤。<code>torch.nn.functional.affine_grid</code>以仿射变换矩阵为输入，输出一个集合的采样坐标，<code>torch.nn.functional.grid_sample</code>对这些坐标处的格子进行采样。Pytorch自动进行误差梯度的反向传播。</p><p>为了使用裁剪池化，我们需要进行如下操作：</p><ol><li><p>将RoI的坐标除以head network的stride长度。Proposal target layer产生的是原始输入图像上的坐标（800x600）.为了将这些坐标转换至”head”网络所输出的特征图上，我们必须将这些坐标除以stride（本次实现中为16）。</p></li><li><p>为了使用API，我们需要提供仿射变换矩阵，仿射变换矩阵的计算方法如下所示。</p></li><li><p>我们同样需要知道目标特征图中x、y两个维度上的点的个数。这一参数由<code>cfg.POOLING_SIZE</code>(default 7）提供。因而，在进行裁剪池化时，非正方形RoI将被用于从卷积特征图上裁剪出大小恒定的正方形特征图。必须执行裁剪池化操作，因为接下来的卷积操作要求输入的特征图大小是固定的。</p></li></ol><p>仿射变换矩阵的计算方法如下：</p><p><img src="/2019/05/08/shen-du-xue-xi/mu-biao-jian-ce/faster-r-cnn-ju-ti-shi-xian-xiang-jie/img_5aa4255fdacb6-1568626824447.png" alt=""></p><p>我们所需要的是未经过扭曲的变换，由于我们已经知道了源坐标（对预测得出的RoI的坐标进行归一化得到）和目标坐标的值（池化得到的特征图的对角坐标是固定的，如上图所示），使用简单的矩阵运算即可得出仿射变换矩阵。由于每一个RoI的坐标都是不同的，所以对于每一个RoI都需要单独计算一个仿射变换矩阵。</p><h3 id="Classification-Layer"><a href="#Classification-Layer" class="headerlink" title="Classification Layer"></a>Classification Layer</h3><p>裁剪池化层以proposal target layer输出的RoIs和head network输出的特征图为输入，输出固定大小的输出特征图。该输出特征图将被传入后接最大池化（用于改变特征图的空间大小）的四层ResNet。结果（代码中为”fc7”）是，对于每一个RoI将得到一个一维的特征向量。流程如下：</p><p><img src="/2019/05/08/shen-du-xue-xi/mu-biao-jian-ce/faster-r-cnn-ju-ti-shi-xian-xiang-jie/img_5aa55c81eac0a.png" alt=""></p><p>所产生的一维特征将被传入另个全连接层bbox_pred_net和cls_score_net。针对每一个bounding boxes，cls_score_net layer将产生类别分数（可以使用softmax将其转换为概率）。bbox_pred_net layer将产生类别相关的边框回归系数，该回归系数将和由proposal target layer产生的原始的边框回归系数一起产生最后的bounding boxes。流程如下：</p><p><img src="/2019/05/08/shen-du-xue-xi/mu-biao-jian-ce/faster-r-cnn-ju-ti-shi-xian-xiang-jie/img_5aa55c97f3287-1568626844808.png" alt=""></p><p>有必要回顾一下两个边框回归系数的差别-第一个由RPN网络产生，第二个由分类网络产生。第一个用于引导RPN网络产生好的前景目标框（与目标边界框贴合地更加紧）。目标回顾系数由anchor target layer产生。很难清楚地解释学习过程是如何发生地，但我可以假设，卷积网络和全连接网络会将由神经网络产生的不同的图像特征图转换为尽可能好的目标边界框。我们将会在前向推理章节介绍回归系数的使用方法。</p><p>第二个边框回归系数由classification layer层产生。这些回归系数是类别相关的，即，对于每一个RoI,会针对每一个类别分别产生一个边框回归系数。这些回归系数的目标回归系数是由proposal target layer产生的。要注意到，classification layer作用于由仿射变化所产生的正方形特征图上。然而，因为回归系数对于无裁剪的仿射变换具有不变性，由proposal target layer产生的目标回归系数才可以和classification layer产生的边框回归系数进行比较，并作为一个有效的学习信号。</p><p>要注意的是，在训练classification layer时，误差的梯度同样反向传播至RPN层。这时由于在进行裁剪池化时所用的RoI坐标正是网络的输出本身，这些坐标正是将RPN的输出施加在anchor boxes上得出的。在反向传播过程中，误差的梯度将通过裁剪池化传播至RPN。计算和实现这些梯度运算是存在一定的难度的，庆幸的是这些运算pytorch中已经给出了实现。</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
          <category> 目标检测 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 目标检测 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mask R-CNN论文解读</title>
      <link href="/2019/05/05/lun-wen-yue-du/mask-r-cnn-lun-wen-jie-du/"/>
      <url>/2019/05/05/lun-wen-yue-du/mask-r-cnn-lun-wen-jie-du/</url>
      
        <content type="html"><![CDATA[<h1 id="Mask-R-CNN"><a href="#Mask-R-CNN" class="headerlink" title="Mask R-CNN"></a>Mask R-CNN</h1><h2 id="作者"><a href="#作者" class="headerlink" title="作者"></a>作者</h2><p>何凯明 Geeorgia Gkioxari Piotr Dollar Ross Girshick</p><h2 id="内容"><a href="#内容" class="headerlink" title="内容"></a>内容</h2><p>在本文中，作者提出了一种用于目标实例分割的方法。该方法在检测目标的同时针对每一个目标实例产生一个高质量的分割蒙板。Mask R-CNN通过在Faster R-CNN现有的用于目标检测的分支的基础上添加用于目标mask预测的分支实现。</p><h2 id="目标检测、目标实例分割、语义分割"><a href="#目标检测、目标实例分割、语义分割" class="headerlink" title="目标检测、目标实例分割、语义分割"></a>目标检测、目标实例分割、语义分割</h2><p>如下图所示：</p><center>![](https://img-blog.csdn.net/20171121232307984?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGlhbWVudGluZ3Rhbw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)</center><ul><li>图片分类<br>仅需要识别出一张图片中存在哪几类目标即可。</li><li>目标检测<br>需要给出图片中目标的类别和具体位置。</li><li>语义分割<br>对图片中的目标进行像素级分割，但只需要区分不同类别目标即可，统一类别的目标不需要区分。</li><li>实例分割<br>对图片中的目标进行像素级分割，但需要区分不同的实例，同一类别的不同个体同样需要进行区分。</li></ul><h2 id="Mask-R-CNN-解决实例分割问题"><a href="#Mask-R-CNN-解决实例分割问题" class="headerlink" title="Mask R-CNN:解决实例分割问题"></a>Mask R-CNN:解决实例分割问题</h2><p><strong>R-CNN的网络结构：</strong></p><center><img src="/2019/05/05/lun-wen-yue-du/mask-r-cnn-lun-wen-jie-du/05/05/lun-wen-yue-du/mask-r-cnn-lun-wen-jie-du/5d9736d2-0b1a-43fa-912a-60be077b0387.jpg"></center><p><strong>Fast R-CNN的网络结构：</strong></p><center><img src="/2019/05/05/lun-wen-yue-du/mask-r-cnn-lun-wen-jie-du/05/05/lun-wen-yue-du/mask-r-cnn-lun-wen-jie-du/b65ae552-1ac7-478c-91d8-82ae6e23d285.jpg"></center><p><strong>Faster R-CNN的网络结构</strong></p><center><img src="/2019/05/05/lun-wen-yue-du/mask-r-cnn-lun-wen-jie-du/05/05/lun-wen-yue-du/mask-r-cnn-lun-wen-jie-du/b19b660d-8e82-48cf-817d-1429475f15be.jpg"></center><p><strong>Mask R-CNN的总体框架如图所示：</strong></p><center><img src="/2019/05/05/lun-wen-yue-du/mask-r-cnn-lun-wen-jie-du/05/05/lun-wen-yue-du/mask-r-cnn-lun-wen-jie-du/27847427-802c-4928-8626-e535429eae7a.jpg"></center><center><img src="/2019/05/05/lun-wen-yue-du/mask-r-cnn-lun-wen-jie-du/05/05/lun-wen-yue-du/mask-r-cnn-lun-wen-jie-du/d1f5ad89-4152-4cf0-b22b-6b307397dee6.jpg"></center><p>作者在Faster R-CNN原有的用于预测目标bounding boxes的子网络的基础上，添加用于预测mask的分支，使用FCN(全卷积网络)对每一个RoI分别进行预测。Faster R-CNN并不是为网络输入与输出之间的像素级的匹配而设计的，这一问题主要是由RoIPool层的空间量化操作所导致的。为了解决这一问题，作者提出了一种简单的、无需量化的层，即RoIAlign，该层的引入极大地保证了空间位置地准确性。RoIAlign层对最终的检测结果有着极大的影响。<br>除此之外，作者发现很有必要对mask预测和类别预测进行解耦和。针对每一类分别预测一层mask，类别之间不存在竞争关系，将类别预测任务交给RoI的分类分支。</p><h3 id="RoIAlign"><a href="#RoIAlign" class="headerlink" title="RoIAlign"></a>RoIAlign</h3><p>给定特征图如下所示：</p><center><img src="/2019/05/05/lun-wen-yue-du/mask-r-cnn-lun-wen-jie-du/05/05/lun-wen-yue-du/mask-r-cnn-lun-wen-jie-du/ee623a5f-c1f5-4a2a-98f7-4c94fa379a3a.jpg"></center><p>传统的RoIPool层针对每一个RoI分别产生一层小的特征图。RoIPool的步骤如下：</p><ol><li>首先对RoI的浮点坐标、大小参数进行量化，将其对应到特征图中。<br><center><img src="/2019/05/05/lun-wen-yue-du/mask-r-cnn-lun-wen-jie-du/05/05/lun-wen-yue-du/mask-r-cnn-lun-wen-jie-du/bf8dcd4c-4274-44c7-ab9d-0ed1ebea64fa.jpg"></center></li></ol><p>&lt;/center&gt;</p><ol><li>接着经过量化的RoI将被划分为格子，针对每一个格子内部进行池化操作，进而得到固定大小的特征图。<br><center><img src="/2019/05/05/lun-wen-yue-du/mask-r-cnn-lun-wen-jie-du/05/05/lun-wen-yue-du/mask-r-cnn-lun-wen-jie-du/82c99a99-edf8-4c09-9e5c-b7f9ea190722.jpg"></center></li></ol><p>&lt;/center&gt;</p><p>在上述操作中，共存在两步取整操作，一个是将RoI对应至特征图时，一个是对量化后的RoI进行划分。这两步取整量化操作会导致原始RoI与抽取出的特征图在空间位置上不匹配。这一问题不会对目标的分类造成大的影响，但会对mask预测造成极大的负面影响。</p><p>为了解决这一问题，作者提出了RoIAlign层，RoIAlign去除了量化取整操作，使得抽取的特征图与输入图片有着精确的位置对应。对于RoI中的每一个格子，使用双线性插值法计算其对应的值，双线性插值法需要的原始值来自于格子四角位置上的值。如下图所示：</p><center><img src="/2019/05/05/lun-wen-yue-du/mask-r-cnn-lun-wen-jie-du/05/05/lun-wen-yue-du/mask-r-cnn-lun-wen-jie-du/86330610-af9b-4205-9736-3240e2bcadb2.jpg"></center>整体步骤如下：1. 使用浮点运算，将RoI对应至特征图的相应位置<center><img src="/2019/05/05/lun-wen-yue-du/mask-r-cnn-lun-wen-jie-du/05/05/lun-wen-yue-du/mask-r-cnn-lun-wen-jie-du/2e9be7aa-3b8d-4bc1-ab91-c7a24239e866.jpg"></center><ol><li>将每一个格子划分为四个小格子<br><center><img src="/2019/05/05/lun-wen-yue-du/mask-r-cnn-lun-wen-jie-du/05/05/lun-wen-yue-du/mask-r-cnn-lun-wen-jie-du/6424cdaa-67a6-4774-8d71-662bbba20f6c.jpg"></center></li></ol><p>&lt;/center&gt;</p><ol><li>使用双线性插值法计算每一个格子的值，取四角的值为原始值<br><center></center></li></ol><p>&lt;/center&gt;</p><ol><li>对每一个格子进行池化操作，得到最终结果<br><center></center></li></ol><p>&lt;/center&gt;</p><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>损失函数由类别损失、边框回归损失、mask损失三部分构成，与其他方法不同，计算mask损失时，对预测的各个类别的mask分别使用sigmoid函数进行激活（而不是使用softmax函数对所有类别的mask进行激活），接着使用二维交叉熵计算损失。</p><h3 id="实现细节"><a href="#实现细节" class="headerlink" title="实现细节"></a>实现细节</h3><p>用于预测mask的子网络的结构如图所示：</p><center><img src="/2019/05/05/lun-wen-yue-du/mask-r-cnn-lun-wen-jie-du/05/05/lun-wen-yue-du/mask-r-cnn-lun-wen-jie-du/e0da9a7e-36b8-468e-8860-db023a099a91.jpg"></center><p>左侧使用resnet-c4作为前面的卷积网络，将rpn生成的roi映射到C4的输出，并进行roi pooling，最后进行分叉预测三个目标。右侧即使用Faster R-CNN加FPN的结构。</p><h3 id="对比实验"><a href="#对比实验" class="headerlink" title="对比实验"></a>对比实验</h3><p>与FCIS+++的对比，如下图所示：</p><p><center><br><img src="/2019/05/05/lun-wen-yue-du/mask-r-cnn-lun-wen-jie-du/05/05/lun-wen-yue-du/mask-r-cnn-lun-wen-jie-du/170fbc97-7e4f-44bd-bf89-dbeae157b64a.jpg"></center></p><p>&lt;/center&gt;<br>在FCIS++的预测中会在目标重合位置出现一条直线，而Mask R-CNN的预测结果则没有。</p><p><strong>消融实验</strong><br>结果如图所示：</p><p><center><br><img src="/2019/05/05/lun-wen-yue-du/mask-r-cnn-lun-wen-jie-du/05/05/lun-wen-yue-du/mask-r-cnn-lun-wen-jie-du/3095a77a-a0f9-4b7f-9482-42fde3b002fd.jpg"></center></p><p>&lt;/center&gt;<br>作者分别给出了不同backbone、多任务和独立任务、使用RoIAligh和不使用、使用FPN进行结果预测和使用全连接层的对比结果。</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
          <category> 实例分割 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 论文阅读 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SSD论文阅读及核心代码解析</title>
      <link href="/2019/04/30/shen-du-xue-xi/mu-biao-jian-ce/ssd-lun-wen-yue-du-ji-he-xin-dai-ma-jie-xi/"/>
      <url>/2019/04/30/shen-du-xue-xi/mu-biao-jian-ce/ssd-lun-wen-yue-du-ji-he-xin-dai-ma-jie-xi/</url>
      
        <content type="html"><![CDATA[<h2 id="SSD-Single-Shot-MultiBox-Detector"><a href="#SSD-Single-Shot-MultiBox-Detector" class="headerlink" title="SSD:Single Shot MultiBox Detector"></a>SSD:Single Shot MultiBox Detector</h2><hr><h2 id="作者"><a href="#作者" class="headerlink" title="作者"></a>作者</h2><p><strong>Wei Liu</strong></p><h2 id="内容"><a href="#内容" class="headerlink" title="内容"></a>内容</h2><p>在本文中,作者提出了一种使用单个神经网络进行目标检测的框架,该框架的特点如下:</p><ol><li><p>将网络的bounding boxes的输出空间划分为default boxes的集合,这些boxes具有不同的尺度和比例.对于被选中用于目标预测的feature maps,网络会针对该特征图中的每一个位置预测多个default boxes,这些default boxes又称为anchors.<br>对于每一个default box,网络给出其存在目标的分数(每一个类别分别预测一个),同时给出在default box的基础上进行形状调整的参数.</p></li><li><p>为了应对目标的尺度变化,SSD在来自于网络的多个具有不同分辨率的feature maps上进行预测.其中,靠近网络前侧,具有较高分辨率的feature map适用于进行小目标的检测,而后侧的feature maps适用于大目标的检测.</p></li></ol><p>作者将本文的贡献总结如下:</p><ol><li>SSD的核心是:在事先设定的固定大小,比例的default boxes的基础上,使用较小的卷积核预测目标隶属于某一类的分数以及box的偏差.</li><li>为了获得较高的检测准确率,在具有不同大小的feature maps上产生具有不同尺度的预测,且这些预测又可以具有不同的长宽比.</li><li>网络可以进行end-to-end训练,同时取得不错的准确率.</li></ol><h2 id="SSD网络结构"><a href="#SSD网络结构" class="headerlink" title="SSD网络结构"></a>SSD网络结构</h2><h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>SSD方法基于前馈神经网络,该网络产生固定数目的bounding boxes集合,同时给出这些boxes中存在某一类别的目标的分数,在这些bounding boxes的基础上,使用NMS算法求出最后的结果.网络的结构如下:</p><center><img src="/2019/04/30/shen-du-xue-xi/mu-biao-jian-ce/ssd-lun-wen-yue-du-ji-he-xin-dai-ma-jie-xi/04/30/shen-du-xue-xi/mu-biao-jian-ce/ssd-lun-wen-yue-du-ji-he-xin-dai-ma-jie-xi/SSD网络结构.png" title="SSD网络结构"></center><p>由上图可以发现,总共选取了6层具有不同大小的feature maps用于目标检测,与R-CNN等方法使用全连接层给出预测结果不同,SSD使用较小的卷积计算得到预测结果.对于每一层feature map,使用一个卷积核计算得到各个default boxes属于某一类的分数,使用另一个卷积核得到在各个default boxes位置的基础上的偏差.</p><h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><h4 id="匹配策略"><a href="#匹配策略" class="headerlink" title="匹配策略"></a>匹配策略</h4><p>在进行训练的时候,需要决定哪一个default boxes与ground truth相关联,只有被选中的default boxes才会参与训练.所采取的策略为:<strong>首先将每一个ground truth和与其覆盖率最大的default boxes进行匹配,接着将与ground truth的jaccard重合率高于设定阈值的default boxes视为匹配</strong>,这样,在第一步保证每一个ground truth都会有匹配的default boxes的基础上,第二步使得多个default boxes可以匹配同一个ground truth.这一设定简化了学习问题,使得网络可以对多个重合的default boxes给出较高的预测分数,而不是仅仅选择具有最高重合率的一个.<br>匹配代码如下:</p><pre class="line-numbers language-lang-python"><code class="language-lang-python"># ./layers/box_utils.pydef point_form(boxes):    # 将(cx, cy, w, h) 形式的box坐标转换成 (xmin, ymin, xmax, ymax) 形式    return torch.cat( (boxes[:2] - boxes[2:]/2), # xmin, ymin                    (boxes[:2] + boxes[2:]/2), 1) # xmax, ymaxdef intersect(box_a, box_b):    # box_a: (truths), (tensor:[num_obj, 4])    # box_b: (priors), (tensor:[num_priors, 4], 即[8732, 4])    # return: (tensor:[num_obj, num_priors]) box_a 与 box_b 两个集合中任意两个 box 的交集, 其中res[i][j]代表box_a中第i个box与box_b中第j个box的交集.(非对称矩阵)    # 思路: 先将两个box的维度扩展至相同维度: [num_obj, num_priors, 4], 然后计算面积的交集    # 两个box的交集可以看成是一个新的box, 该box的左上角坐标是box_a和box_b左上角坐标的较大值, 右下角坐标是box_a和box_b的右下角坐标的较小值    A = box_a.size(0)    B = box_b.size(0)    # box_a 左上角/右下角坐标 expand以后, 维度会变成(A,B,2), 其中, 具体可看 expand 的相关原理. box_b也是同理, 这样做是为了得到a中某个box与b中某个box的左上角(min_xy)的较大者(max)    # unsqueeze 为增加维度的数量, expand 为扩展维度的大小    min_xy = torch.max(box_a[:, :2].unsqueeze(1).expand(A,B,2),                        box_b[:, :2].unsqueeze(0).expand(A,B,2)) # 在box_a的 A 和 2 之间增加一个维度, 并将维度扩展到 B. box_b 同理    # 求右下角(max_xy)的较小者(min)    max_xy = torch.min(box_a[:, 2:].unsqueeze(1).expand(A,B,2),                        box_b[:, 2:].unsqueeze(0).expand(A,B,2))    inter = torch.clamp((max_xy, min_xy), min=0) # 右下角减去左上角, 如果为负值, 说明没有交集, 置为0    return inter[:, :, 0] * inter[:, :, 0] # 高×宽, 返回交集的面积, shape 刚好为 [A, B]def jaccard(box_a, box_b):    # A ∩ B / A ∪ B = A ∩ B / (area(A) + area(B) - A ∩ B)    # box_a: (truths), (tensor:[num_obj, 4])    # box_b: (priors), (tensor:[num_priors, 4], 即[8732, 4])    # return: (tensor:[num_obj, num_priors]), 代表了 box_a 和 box_b 两个集合中任意两个 box之间的交并比    inter = intersect(box_a, box_b) # 求任意两个box的交集面积, shape为[A, B], 即[num_obj, num_priors]    area_a = ((box_a[:,2]-box_a[:,0]) * (box_a[:,3]-box_a[:,1])).unsqueeze(1).expand_as(inter) # [A,B]    area_b = ((box_b[:,2]-box_b[:,0]) * (box_b[:,3]-box_b[:,1])).unsqueeze(0).expand_as(inter) # [A,B], 这里会将A中的元素复制B次    union = area_a + area_b - inter    return inter / union # [A, B], 返回任意两个box之间的交并比, res[i][j] 代表box_a中的第i个box与box_b中的第j个box之间的交并比.def encode(matched, priors, variances):    # 对边框坐标进行编码, 需要宽度方差和高度方差两个参数, 具体公式可以参见原文公式(2)    # matched: [num_priors,4] 存储的是与priorbox匹配的gtbox的坐标. 形式为(xmin, ymin, xmax, ymax)    # priors: [num_priors, 4] 存储的是priorbox的坐标. 形式为(cx, cy, w, h)    # return : encoded boxes: [num_priors, 4]    g_cxy = (matched[:, :2] + matched[:, 2:])/2 - priors[:, :2] # 用互相匹配的gtbox的中心坐标减去priorbox的中心坐标, 获得中心坐标的偏移量    g_cxy /= (variances[0]*priors[:, 2:]) # 令中心坐标分别除以 d_i^w 和 d_i^h, 正如原文公式所示    #variances[0]为0.1, 令其分别乘以w和h, 得到d_i^w 和 d_i^h    g_wh = (matched[:, 2:] - matched[:, :2]) / priors[:, 2:] # 令互相匹配的gtbox的宽高除以priorbox的宽高.    g_wh = torch.log(g_wh) / variances[1] # 这里这个variances[1]=0.2 不太懂是为什么.    return torch.cat([g_cxy, g_wh], 1) # 将编码后的中心坐标和宽高``连接起来, 返回 [num_priors, 4]def match(threshold, truths, priors, variances, labels, loc_t, conf_t, idx):    # threshold: (float) 确定是否匹配的交并比阈值    # truths: (tensor: [num_obj, 4]) 存储真实 box 的边框坐标    # priors: (tensor: [num_priors, 4], 即[8732, 4]), 存储推荐框的坐标, 注意, 此时的框是 default box, 而不是 SSD 网络预测出来的框的坐标, 预测的结果存储在 loc_data中, 其 shape 为[num_obj, 8732, 4].    # variances: cfg['variance'], [0.1, 0.2], 用于将坐标转换成方便训练的形式(参考RCNN系列对边框坐标的处理)    # labels: (tensor: [num_obj]), 代表了每个真实 box 对应的类别的编号    # loc_t: (tensor: [batches, 8732, 4]),    # conf_t: (tensor: [batches, 8732]),    # idx: batches 中图片的序号, 标识当前正在处理的 image 在 batches 中的序号    overlaps = jaccard(truths, point_form(priors)) # [A, B], 返回任意两个box之间的交并比, overlaps[i][j] 代表box_a中的第i个box与box_b中的第j个box之间的交并比.    # 二部图匹配(Bipartite Matching)    # [num_objs,1], 得到对于每个 gt box 来说的匹配度最高的 prior box, 前者存储交并比, 后者存储prior box在num_priors中的位置    best_prior_overlap, best_prior_idx = overlaps.max(1, keepdim=True) # keepdim=True, 因此shape为[num_objs,1]    # [1, num_priors], 即[1,8732], 同理, 得到对于每个 prior box 来说的匹配度最高的 gt box    best_truth_overlap, best_truth_idx = overlaps.max(0, keepdim=True)    best_prior_idx.squeeze_(1) # 上面特意保留了维度(keepdim=True), 这里又都把维度 squeeze/reduce 了, 实际上只需用默认的 keepdim=False 就可以自动 squeeze/reduce 维度.    best_prior_overlap.squeeze_(1)    best_truth_idx.squeeze_(0)    best_truth_overlap.squeeze_(0)    best_truth_overlap.index_fill_(0, best_prior_idx, 2)    # 维度压缩后变为[num_priors], best_prior_idx 维度为[num_objs],    # 该语句会将与gt box匹配度最好的prior box 的交并比置为 2, 确保其最大, 以免防止某些 gtbox 没有匹配的 priorbox.    # 假想一种极端情况, 所有的priorbox与某个gtbox(标记为G)的交并比为1, 而其他gtbox分别有一个交并比    # 最高的priorbox, 但是肯定小于1(因为其他的gtbox与G的交并比肯定小于1), 这样一来, 就会使得所有    # 的priorbox都与G匹配, 为了防止这种情况, 我们将那些对gtbox来说, 具有最高交并比的priorbox,    # 强制进行互相匹配, 即令best_truth_idx[best_prior_idx[j]] = j, 详细见下面的for循环    # 注意!!: 因为 gt box 的数量要远远少于 prior box 的数量, 因此, 同一个 gt box 会与多个 prior box 匹配.    for j in range(best_prior_idx.size(0)): # range:0~num_obj-1        best_truth_idx[best_prior_idx[j]] = j        # best_prior_idx[j] 代表与box_a的第j个box交并比最高的 prior box 的下标, 将与该 gtbox        # 匹配度最好的 prior box 的下标改为j, 由此,完成了该 gtbox 与第j个 prior box 的匹配.        # 这里的循环只会进行num_obj次, 剩余的匹配为 best_truth_idx 中原本的值.        # 这里处理的情况是, priorbox中第i个box与gtbox中第k个box的交并比最高,        # 即 best_truth_idx[i]= k        # 但是对于best_prior_idx[k]来说, 它却与priorbox的第l个box有着最高的交并比,        # 即best_prior_idx[k]=l        # 而对于gtbox的另一个边框gtbox[j]来说, 它与priorbox[i]的交并比最大,        # 即但是对于best_prior_idx[j] = i.        # 那么, 此时, 我们就应该将best_truth_idx[i]= k 修改成 best_truth_idx[i]= j.        # 即令 priorbox[i] 与 gtbox[j]对应.        # 这样做的原因: 防止某个gtbox没有匹配的 prior box.    mathes = truths[best_truth_idx]    # truths 的shape 为[num_objs, 4], 而best_truth_idx是一个指示下标的列表, 列表长度为 8732,    # 列表中的下标范围为0~num_objs-1, 代表的是与每个priorbox匹配的gtbox的下标    # 上面的表达式会返回一个shape为 [num_priors, 4], 即 [8732, 4] 的tensor, 代表的就是与每个priorbox匹配的gtbox的坐标值.    conf = labels[best_truth_idx]+1 # 与上面的语句道理差不多, 这里得到的是每个prior box匹配的类别编号, shape 为[8732]    conf[best_truth_overlap < threshold] = 0 # 将与gtbox的交并比小于阈值的置为0 , 即认为是非物体框    loc = encode(matches, priors, variances) # 返回编码后的中心坐标和宽高.    loc_t[idx] = loc # 设置第idx张图片的gt编码坐标信息    conf_t[idx] = conf # 设置第idx张图片的编号信息.(大于0即为物体编号, 认为有物体, 小于0认为是背景)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>代码流程为</strong>:</p><ol><li>计算出每一个ground truth与每一个default boxes的jaccard overlap;</li><li>挑出与每一个ground truth最匹配(重复度最高)的default boxes;</li><li>挑出与每一个default boxes最匹配的ground truth;</li><li>注意,最终的匹配结果要保证在每一个ground truth都有与之匹配的default boxes的基础上,可以存在多个default boxes匹配同一个ground truth,这就是<pre><code>for j in range(best_prior_idx.size(0)):   best_truth_idx[best_prior_idx[j]] = j</code></pre> 这一for循环完成的功能.</li><li>将重复率低于阈值的标记为背景目标.</li></ol><h4 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h4><p>模型的整体损失函数如下:</p><center>$L ( x , c , l , g ) = \frac { 1 } { N } \left( L _ { c o n f } ( x , c ) + \alpha L _ { l o c } ( x , l , g ) \right)$</center><p>其中N表示匹配的default boxes的数目,其中定位误差的计算方式如下:</p><center>$L _ { l o c } ( x , l , g ) = \sum _ { i \in P o s } ^ { N } \sum _ { m \in \{ c x , c y , w , h \} } x _ { i j } ^ { k } \operatorname { smooth } _ { \mathrm { LI } } \left( l _ { i } ^ { m } - \hat { g } _ { j } ^ { m } \right)$$\hat { g } _ { j } ^ { c x } = \left( g _ { j } ^ { c x } - d _ { i } ^ { c x } \right) / d _ { i } ^ { w } \quad \hat { g } _ { j } ^ { c y } = \left( g _ { j } ^ { c y } - d _ { i } ^ { c y } \right) / d _ { i } ^ { h }$$\hat { g } _ { j } ^ { w } = \log \left( \frac { g _ { j } ^ { w } } { d _ { i } ^ { w } } \right) \quad \hat { g } _ { j } ^ { h } = \log \left( \frac { g _ { j } ^ { h } } { d _ { i } ^ { h } } \right)$</center><p>与Faster R-CNN类似,预测相对于default boxes的中心坐标的偏差,以及其宽和高.其中$x_ij^p$表示,将第i个default boxes与类别p的第j个ground truth进行匹配,这里,要将ground truth转换为相对于default boxes的偏移量.<br>置信度损失如下:</p><center>$L _ { c o n f } ( x , c ) = - \sum _ { i \in P o s } ^ { N } x _ { i j } ^ { p } \log \left( \hat { c } _ { i } ^ { p } \right) - \sum _ { i \in N e g } \log \left( \hat { c } _ { i } ^ { 0 } \right) \quad  where  \quad \hat { c } _ { i } ^ { p } = \frac { \exp \left( c _ { i } ^ { p } \right) } { \sum _ { p } \exp \left( c _ { i } ^ { p } \right) }$</center><p>其中$\alpha$设置为1.<br>代码如下:</p><pre class="line-numbers language-lang-python"><code class="language-lang-python"># layers/modules/multibox_loss.pyclass MultiBoxLoss(nn.Module):    # 计算目标:    # 输出那些与真实框的iou大于一定阈值的框的下标.    # 根据与真实框的偏移量输出localization目标    # 用难样例挖掘算法去除大量负样本(默认正负样本比例为1:3)    # 目标损失:    # L(x,c,l,g) = (Lconf(x,c) + αLloc(x,l,g)) / N    # 参数:    # c: 类别置信度(class confidences)    # l: 预测的框(predicted boxes)    # g: 真实框(ground truth boxes)    # N: 匹配到的框的数量(number of matched default boxes)    def __init__(self, num_classes, overlap_thresh, prior_for_matching, bkg_label, neg_mining, neg_pos, neg_overlap, encode_target, use_gpu=True):        super(MultiBoxLoss, self).__init__()        self.use_gpu = use_gpu        self.num_classes= num_classes # 列表数        self.threshold = overlap_thresh # 交并比阈值, 0.5        self.background_label = bkg_label # 背景标签, 0        self.use_prior_for_matching = prior_for_matching # True 没卵用        self.do_neg_mining = neg_mining # True, 没卵用        self.negpos_ratio = neg_pos # 负样本和正样本的比例, 3:1        self.neg_overlap = neg_overlap # 0.5 判定负样本的阈值.        self.encode_target = encode_target # False 没卵用        self.variance = cfg["variance"]    def forward(self, predictions, targets):        loc_data, conf_data, priors = predictions        # loc_data: [batch_size, 8732, 4]        # conf_data: [batch_size, 8732, 21]        # priors: [8732, 4] default box 对于任意的图片, 都是相同的, 因此无需带有 batch 维度        num = loc_data.size(0) # num = batch_size        priors = priors[:loc_data.size(1), :] # loc_data.size(1) = 8732, 因此 priors 维持不变        num_priors = (priors.size(0)) # num_priors = 8732        num_classes = self.num_classes # num_classes = 21 (默认为voc数据集)        # 将priors(default boxes)和ground truth boxes匹配        loc_t = torch.Tensor(num, num_priors, 4) # shape:[batch_size, 8732, 4]        conf_t = torch.LongTensor(num, num_priors) # shape:[batch_size, 8732]        for idx in range(num):            # targets是列表, 列表的长度为batch_size, 列表中每个元素为一个 tensor,            # 其 shape 为 [num_objs, 5], 其中 num_objs 为当前图片中物体的数量, 第二维前4个元素为边框坐标, 最后一个元素为类别编号(1~20)            truths = targets[idx][:, :-1].data # [num_objs, 4]            labels = targets[idx][:, -1].data # [num_objs] 使用的是 -1, 而不是 -1:, 因此, 返回的维度变少了            defaults = priors.data # [8732, 4]            # from ..box_utils import match            # 关键函数, 实现候选框与真实框之间的匹配, 注意是候选框而不是预测结果框! 这个函数实现较为复杂, 会在后面着重讲解            match(self.threshold, truths, defaults, self.variance, labels, loc_t, conf_t, idx) # 注意! 要清楚 Python 中的参数传递机制, 此处在函数内部会改变 loc_t, conf_t 的值, 关于 match 的详细讲解可以看后面的代码解析        if self.use_gpu:            loc_t = loc_t.cuda()            conf_t = conf_t.cuda()        # 用Variable封装loc_t, 新版本的 PyTorch 无需这么做, 只需要将 requires_grad 属性设置为 True 就行了        loc_t = Variable(loc_t, requires_grad=False)        conf_t = Variable(conf_t, requires_grad=False)        pos = conf_t > 0 # 筛选出 >0 的box下标(大部分都是=0的)        num_pos = pos.sum(dim=1, keepdim=True) # 求和, 取得满足条件的box的数量, [batch_size, num_gt_threshold]        # 位置(localization)损失函数, 使用 Smooth L1 函数求损失        # loc_data:[batch, num_priors, 4]        # pos: [batch, num_priors]        # pos_idx: [batch, num_priors, 4], 复制下标成坐标格式, 以便获取坐标值        pos_idx = pos.unsqueeze(pos.dim()).expand_as(loc_data)        loc_p = loc_data[pos_idx].view(-1, 4)# 获取预测结果值        loc_t = loc_t[pos_idx].view(-1, 4) # 获取gt值        loss_l = F.smooth_l1_loss(loc_p, loc_t, size_average=False) # 计算损失        # 计算最大的置信度, 以进行难负样本挖掘        # conf_data: [batch, num_priors, num_classes]        # batch_conf: [batch, num_priors, num_classes]        batch_conf = conf_data.view(-1, self.num_classes) # reshape        # conf_t: [batch, num_priors]        # loss_c: [batch*num_priors, 1], 计算每个priorbox预测后的损失        loss_c = log_sum_exp(batch_conf) - batch_conf.gather(1, conf_t.view(-1,1))        # 难负样本挖掘, 按照loss进行排序, 取loss最大的负样本参与更新        loss_c[pos.view(-1, 1)] = 0 # 将所有的pos下标的box的loss置为0(pos指示的是正样本的下标)        # 将 loss_c 的shape 从 [batch*num_priors, 1] 转换成 [batch, num_priors]        loss_c = loss_c.view(num, -1) # reshape        # 进行降序排序, 并获取到排序的下标        _, loss_idx = loss_c.sort(1, descending=True)        # 将下标进行升序排序, 并获取到下标的下标        _, idx_rank = loss_idx.sort(1)        # num_pos: [batch, 1], 统计每个样本中的obj个数        num_pos = pos.long().sum(1, keepdim=True)        # 根据obj的个数, 确定负样本的个数(正样本的3倍)        num_neg = torch.clamp(self.negpos_ratio*num_pos, max=pos.size(1)-1)        # 获取到负样本的下标        neg = idx_rank < num_neg.expand_as(idx_rank)        # 计算包括正样本和负样本的置信度损失        # pos: [batch, num_priors]        # pos_idx: [batch, num_priors, num_classes]        pos_idx = pos.unsqueeze(2).expand_as(conf_data)        # neg: [batch, num_priors]        # neg_idx: [batch, num_priors, num_classes]        neg_idx = neg.unsqueeze(2).expand_as(conf_data)        # 按照pos_idx和neg_idx指示的下标筛选参与计算损失的预测数据        conf_p = conf_data[(pos_idx+neg_idx).gt(0)].view(-1, self.num_classes)        # 按照pos_idx和neg_idx筛选目标数据        targets_weighted = conf_t[(pos+neg).gt(0)]        # 计算二者的交叉熵        loss_c = F.cross_entropy(conf_p, targets_weighted, size_average=False)        # 将损失函数归一化后返回        N = num_pos.data.sum()        loss_l = loss_l / N        loss_c = loss_c / N        return loss_l, loss_c<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="确定default-boxes的尺度以及比率"><a href="#确定default-boxes的尺度以及比率" class="headerlink" title="确定default boxes的尺度以及比率"></a>确定default boxes的尺度以及比率</h4><p>实验表明使用低层的feature maps可以提高语义分割质量,因为底层的feature maps包含输入目标的细节信息.<br>来自于一个网络不同层的feature maps具有不同的感受野,在SSD网络中,default boxes不需要与每一层的真实的感受野严格匹配.作者将default boxes的大小设计为与特定尺度的目标相关联.假设在模型中使用了m层特征图.每一层特征图的default boxes的尺度计算如下:</p><center>$s _ { k } = s _ { \min } + \frac { s _ { \max } - s _ { \min } } { m - 1 } ( k - 1 ) , \quad k \in [ 1 , m ]$</center><p>其中$s_{min}$为$0.2$,$s_{max}$为$0.9$,分别代表最低、最高层的尺度.<br>对于,每一层中的default又引入了五种不同的比率,即:</p><center>${ 1,2,3 , \frac { 1 } { 2 } , \frac { 1 } { 3 }}$</center><p>依据比率，得出宽的计算公式为:</p><center>$w _ { k } ^ { a } = s _ { k } \sqrt { a _ { r } }$</center><p>高的计算公式为:</p><center>$h _ { k } ^ { a } = s _ { k } / \sqrt { a _ { r } }$</center><p>对于比率1,又额外定义了一个尺度,计算如下:</p><center>$s _ { k } ^ { \prime } = \sqrt { S _ { k } S _ { k + 1 } }$</center><p>这样,每一层特征图的每一个位置上便有六个不同比率的default boxes,将每一个位置上的6个default boxes的中心坐标设置为:</p><center>$\left( \frac { i + 0.5 } { \left| f _ { k } \right| } , \frac { j + 0.5 } { \left| f _ { k } \right| } \right)$</center><p>其中 $\left| f _ { k } \right|$表示第k个特征图的大小，$i , j \in \left[ 0 , \left| f _ { k } \right|\right.]$,对应特征图上所有可能的位置点.</p><p>实际中,不同的数据集适用于不同的尺度以及比例,若数据集中包含有更多的小目标,则需要设计更多的小尺度default boxes,相应的,若包含有更多的大目标,则需要设计更多的大尺度default boxes.<br>实现这一功能的代码如下:借鉴自:<a href="https://hellozhaozheng.github.io/z_post/PyTorch-SSD/#MultiBox," title="代码出处" target="_blank" rel="noopener">代码出处 </a></p><pre class="line-numbers language-lang-python"><code class="language-lang-python"># `layers/functions/prior_box.py`class PriorBox(object):    # 所谓priorbox实际上就是网格中每一个cell推荐的box    def __init__(self, cfg):        # 在SSD的init中, cfg=(coco, voc)[num_classes=21]        # coco, voc的相关配置都来自于data/cfg.py 文件        super(PriorBox, self).__init__()        self.image_size = cfg["min_dim"]        self.num_priors = len(cfg["aspect_ratios"])        self.variance = cfg["variance"] or [0.1]        self.min_sizes = cfg["min_sizes"]        self.max_sizes = cfg["max_sizes"]        self.steps = cfg["steps"]        self.aspect_ratios = cfg["aspect_ratios"]        self.clip = cfg["clip"]        self.version = cfg["name"]        for v in self.variance:            if v <= 0:                raise ValueError("Variances must be greater than 0")    def forward(self):        mean = []        for k, f in enumerate(self.feature_maps): # 存放的是feature map的尺寸:38,19,10,5,3,1            # from itertools import product as product            for i, j in product(range(f), repeat=2):                # 这里实际上可以用最普通的for循环嵌套来代替, 主要目的是产生anchor的坐标(i,j)                f_k = self.image_size / self.steps[k] # steps=[8,16,32,64,100,300]. f_k大约为feature map的尺寸                # 求得center的坐标, 浮点类型. 实际上, 这里也可以直接使用整数类型的 `f`, 计算上没太大差别                cx = (j + 0.5) / f_k                cy = (i + 0.5) / f_k # 这里一定要特别注意 i,j 和cx, cy的对应关系, 因为cy对应的是行, 所以应该零cy与i对应.                # aspect_ratios 为1时对应的box                s_k = self.min_sizes[k]/self.image_size                mean += [cx, cy, s_k, s_k]                # 根据原文, 当 aspect_ratios 为1时, 会有一个额外的 box, 如下:                # rel size: sqrt(s_k * s_(k+1))                s_k_prime = sqrt(s_k * (self.max_sizes[k]/self.image_size))                mean += [cx, cy, s_k_prime, s_k_prime]                # 其余(2, 或 2,3)的宽高比(aspect ratio)                for ar in self.aspect_ratios[k]:                    mean += [cx, cy, s_k*sqrt(ar), s_k/sqrt(ar)]                    mean += [cx, cy, s_k/sqrt(ar), s_k*sqrt(ar)]                # 综上, 每个卷积特征图谱上每个像素点最终产生的 box 数量要么为4, 要么为6, 根据不同情况可自行修改.        output = torch.Tensor(mean).view(-1,4)        if self.clip:            output.clamp_(max=1, min=0) # clamp_ 是clamp的原地执行版本        return output # 输出default box坐标(可以理解为anchor box)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="Hard-negative-mining"><a href="#Hard-negative-mining" class="headerlink" title="Hard negative mining"></a>Hard negative mining</h4><p>这一策略主要用于解决正负样本数目不均衡的问题,在进行边框匹配之后,大多数的default boxes都是负样本.这一结果会导致样本不平衡.因而在训练时,没有使用所有的负样本,而是首先依据每一个default box的置信度损失进行排序,选出最高的几个,使得正负样本的比例为1:3.使用选出的样本进行训练.</p><h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><div class="table-container"><table><thead><tr><th>模型</th><th>mAP</th><th>FPS</th></tr></thead><tbody><tr><td>SSD 300</td><td>74.3%</td><td>59</td></tr><tr><td>SSD 512</td><td>76.9%</td><td>-</td></tr><tr><td>Faster R-CNN</td><td>73.2%</td><td>7</td></tr><tr><td>YOLOV1</td><td>63.4%</td><td>45</td></tr></tbody></table></div>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
          <category> 目标检测 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 目标检测 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ResNet论文解读</title>
      <link href="/2019/04/30/lun-wen-yue-du/resnet-lun-wen-jie-du/"/>
      <url>/2019/04/30/lun-wen-yue-du/resnet-lun-wen-jie-du/</url>
      
        <content type="html"><![CDATA[<h2 id="Deep-Residual-Learning-for-Image-Recogition"><a href="#Deep-Residual-Learning-for-Image-Recogition" class="headerlink" title="Deep Residual Learning for Image Recogition"></a>Deep Residual Learning for Image Recogition</h2><hr><h2 id="作者"><a href="#作者" class="headerlink" title="作者"></a>作者</h2><p><strong>Kaiming He</strong>    Xiangyu Zhang       Shaoqing Ren    Jian Sun</p><p><strong>何凯明大佬</strong></p><center>![](http://kaiminghe.com/img/me.jpg)</center><h2 id="内容"><a href="#内容" class="headerlink" title="内容"></a>内容</h2><p>这篇论文主要用于解决网络层数加深时,模型的训练问题.</p><h3 id="深度网络的退化问题"><a href="#深度网络的退化问题" class="headerlink" title="深度网络的退化问题"></a>深度网络的退化问题</h3><p>如下图所示,为历年ISLVRC竞赛中取得冠军的各个网络结构,观察该图片可知,随着网络层数的增加,模型的复杂度不断提升,进而可以提取更为丰富的特征,因而也得到了更好的结果.</p><center><img src="/2019/04/30/lun-wen-yue-du/resnet-lun-wen-jie-du/04/30/lun-wen-yue-du/resnet-lun-wen-jie-du/ISLVRC冠军结构.jpg" title="ISLVRC冠军结构"></center><p>但事实上,模型的表达能力和模型复杂度并不是成正比关系的,在论文中,作者指出,随着深度的增加,模型出现了退化问题(Degradation problem),如下图所示.</p><center><img src="/2019/04/30/lun-wen-yue-du/resnet-lun-wen-jie-du/04/30/lun-wen-yue-du/resnet-lun-wen-jie-du/模型退化问题.jpg" title="模型退化问题"></center><p>网络深度增加时，网络准确度出现饱和，甚至出现下降.这一问题并不是由过拟合所导致的,因为在图中,56层网络的训练误差同样很大.</p><p>在深层网络存在着梯度消失或者爆炸的问题，这使得深度学习模型很难训练。但是现在已经存在一些技术手段,如BatchNorm来缓解这个问题。因此，出现深度网络的退化问题是非常令人诧异的。</p><h3 id="残差学习"><a href="#残差学习" class="headerlink" title="残差学习"></a>残差学习</h3><p>深度网络的退化问题至少说明深度网络不容易训练。但是我们考虑这样一个事实：现在你有一个浅层网络，你想通过向上堆积新层来建立深层网络，一个极端情况是这些增加的层什么也不学习，仅仅复制浅层网络的特征，即这样新层是恒等映射（Identity mapping）。在这种情况下，深层网络应该至少和浅层网络性能一样，不应该出现退化现象。</p><p>为了解决这一问题,在本文中作者提出了残差学习的思想.对于一个堆积层结构（几层堆积而成）当输入为$x$时其学习到的特征记为$H(x)$，现在我们希望其可以学习到残差$F(x)=H(x)-x$，这样其实原始的学习特征是$F(x)+x$。之所以这样是因为残差学习相比原始特征直接学习更容易。当残差为0时，此时堆积层仅仅做了恒等映射，至少网络性能不会下降，实际上残差不会为0，这也会使得堆积层在输入特征基础上学习到新的特征，从而拥有更好的性能。残差学习的结构如下图所示。这有点类似与电路中的“短路”，所以是一种短路连接（shortcut connection）。</p><center><img src="/2019/04/30/lun-wen-yue-du/resnet-lun-wen-jie-du/04/30/lun-wen-yue-du/resnet-lun-wen-jie-du/残差模块.jpg" title="残差模块"></center><p>从数学角度解释残差学习更为容易的原因.</p><p>将残差单元表示为:</p><center>$y_l=h(x_l)+F(x_l, W_l)$$x_{l+1}=f(y_l)$</center><p>其中,$h(x_l)$表示恒等映射,$F(x_l, W_l)$表示残差映射,$f$为ReLU激活函数,那么从浅层$l$到深层$L$的特征为:</p><center>$x_L=x_l+\sum_{i=l}^{L-1}F(x_i, W_i)$</center><p>使用链式求导法则可以得到损失相对于第$x_l$层的梯度为:</p><center>$\frac{\partial loss}{\partial x_l} = \frac{\partial loss}{partial x_L} \cdot \frac{\partial x_L}{\partial x_l} =  \frac{\partial loss}{\partial x_L} \cdot (1 + \frac{\partial}{\partial x_l} \sum_{i=l}^{L-1}F(x_i, W_i))$</center><p>由上式我们可以发现,小括号中的1表明短路机制可以无损地传播梯度，而另外一项残差梯度则需要经过带有weights的层，梯度不是直接传递过来的。残差梯度不会那么巧全为-1，而且就算其比较小，有1的存在也不会导致梯度消失。所以残差学习会更容易(上面的推导并不是严格的证明)。</p><h3 id="ResNet的网络结构"><a href="#ResNet的网络结构" class="headerlink" title="ResNet的网络结构"></a>ResNet的网络结构</h3><p>ResNet网络是参考了VGG19网络，在其基础上进行了修改，并通过短路机制加入了残差单元，如图所示。变化主要体现在ResNet直接使用stride=2的卷积做下采样，并且用global average pool层替换了全连接层。ResNet的一个重要设计原则是：<strong>当feature map大小降低一半时，feature map的数量增加一倍</strong>，这保持了网络层的复杂度。从图中可以看到，ResNet相比普通网络每两层间增加了短路机制，这就形成了残差学习，其中虚线表示feature map数量发生了改变。图中展示的34-layer的ResNet，还可以构建更深的网络如表所示。从表中可以看到，对于18-layer和34-layer的ResNet，其进行的两层间的残差学习，当网络更深时，其进行的是三层间的残差学习，三层卷积核分别是1x1，3x3和1x1，一个值得注意的是隐含层的feature map数量是比较小的，并且是输出feature map数量的1/4。</p><center><img src="/2019/04/30/lun-wen-yue-du/resnet-lun-wen-jie-du/04/30/lun-wen-yue-du/resnet-lun-wen-jie-du/resnet结构.jpg" title="resnet结构">ResNet网络结构</center><center><img src="/2019/04/30/lun-wen-yue-du/resnet-lun-wen-jie-du/04/30/lun-wen-yue-du/resnet-lun-wen-jie-du/不同的resnet结构.jpg" title="不同的resnet结构">不同的ResNet网络结构</center><h4 id="残差单元"><a href="#残差单元" class="headerlink" title="残差单元"></a>残差单元</h4><p>ResNet使用两种残差单元，如图所示。左图对应的是浅层网络，而右图对应的是深层网络。对于短路连接，当输入和输出维度一致时，可以直接将输入加到输出上。但是当维度不一致时（对应的是维度增加一倍），这就不能直接相加。有两种策略：（1）采用zero-padding增加维度，此时一般要先做一个downsample，可以采用strde=2的pooling，这样不会增加参数；（2）采用新的映射（projection shortcut），一般采用1x1的卷积(可以改变维度)，这样会增加参数，也会增加计算量。短路连接除了直接使用恒等映射，当然都可以采用projection shortcut。</p><center><img src="/2019/04/30/lun-wen-yue-du/resnet-lun-wen-jie-du/04/30/lun-wen-yue-du/resnet-lun-wen-jie-du/残差单元.jpg" title="残差单元">残差单元示意图(左侧为浅层网络使用的残差单元,右侧为深层网络)</center><h2 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h2><p>如图所示,左侧为不使用残差模块的普通深度网络,右侧为ResNet.</p><center><img src="/2019/04/30/lun-wen-yue-du/resnet-lun-wen-jie-du/04/30/lun-wen-yue-du/resnet-lun-wen-jie-du/结果对比.jpg" title="结果对比">结果示意图</center><p>从图中我们可以看出,在左侧,未使用残差模块的网络明显出现了退化现象,而右侧则无此问题.</p><h2 id="一种更为优秀的残差模块"><a href="#一种更为优秀的残差模块" class="headerlink" title="一种更为优秀的残差模块"></a>一种更为优秀的残差模块</h2><p>采用前置激活可以提升残差模块的性能,如图所示:</p><center><img src="/2019/04/30/lun-wen-yue-du/resnet-lun-wen-jie-du/04/30/lun-wen-yue-du/resnet-lun-wen-jie-du/残差模块改进.jpg" title="残差模块改进"></center>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
          <category> 经典网络结构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 论文阅读 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
