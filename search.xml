<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>目标检测评价指标-AP、mAP</title>
      <link href="/2019/05/26/mu-biao-jian-ce-ping-jie-zhi-biao-ap-map/"/>
      <url>/2019/05/26/mu-biao-jian-ce-ping-jie-zhi-biao-ap-map/</url>
      
        <content type="html"><![CDATA[<h2 id="AP、mAP的计算"><a href="#AP、mAP的计算" class="headerlink" title="AP、mAP的计算"></a>AP、mAP的计算</h2><h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><p>当我们完成目标检测模型的训练之后，需要合适的指标对模型的性能进行度量，常用的指标有AP、mAP两种。要了解AP和mAP，需要首先了解精度和召回率的概念，所谓精度指的是所有分类为正的样本中，真的为正的样本所占得比例；召回率指的是分类为正的样本占所有正样本的比例，即原始的正样本中有多少被模型正确地划分为正，形象的解释可以理解为下图：</p><p><center><br><img src="/2019/05/26/mu-biao-jian-ce-ping-jie-zhi-biao-ap-map/精度-召回率示意.png" title="精度-召回率示意"><br></center><br>图中false表示模型的划分结果为错，positive表示模型将样本划分为正样本，精度和召回率如图下部分所示。<br>以分类器为例，精度和召回率一般是无法同时满足的，精度高那么召回率便会降低。假设将所有的样本都划分为正样本，此时精度会很低，而召回率为1，即所有的正样本都被正确划分。单纯使用精度或者召回率是很难完整地度量一个模型的性能的，为了解决这一问题，便提出了AP(average precision)的概念。那么何为AP，将AP定义为精度、召回率曲线下的面积，如下图所示，以二分类问题为例。</p><p><center><br><img src="https://arleyzhang.github.io/articles/c521a01c/1527520824881-1542379892017.png" alt=""><br></center></p><h2 id="AP的计算"><a href="#AP的计算" class="headerlink" title="AP的计算"></a>AP的计算</h2><p>由精度-召回率（RP）曲线可知，每一个召回率对应一个精度，那么如何得到不同的召回率和精度呢？</p><p><strong>1. 统计为TP的预测</strong><br>首先需要知道如何计算召回率和精度，在目标检测中，对于每一个样本图像，模型会给出多个预测框。我们需要首先统计出所给出的预测框中为TruePositive的预测框。一个预测框被判定为TruePositive需要满足的条件是：</p><blockquote><p>该预测框和与之匹配的ground truth（在所有的ground truth中具有最大的重合度，即IoU）的IoU大于给定的重合度阈值。</p></blockquote><p>对于模型给出的所有预测框，按照该条件找出其中所有为TruePositive的预测框。<br><strong>2. 得到精度-召回率曲线</strong><br>经过第一步的计算，所有的预测框都被打上了是否为TruePositive的标签，为了得到精度-召回率曲线，我们必须得到多个不同的召回率和精度。在VOC的计算方式中，是依据预测框所对应的置信度值进行计算。首先，针对某一个特定的类别，挑选出属于该类的预测框；然后在挑选得到的预测框中，给定一个置信度阈值，大于该阈值的被标记为TruePositive的预测框将被最终记作TruePositive，剩余的预测框将被标记为FalsePositive。设定不同的置信度阈值就会得到不同个数的TruePositive预测框，使用这些TruePositive预测框依据下述公式便可以分别计算得到该类别精度和召回率，每一个置信度对应一对精度、召回率值。</p><p><center><br>$Precision = \frac{TP}{TP+FP}$<br></center></p><p><center><br>$Recall = \frac{TP}{TP+FN}$<br></center><br>在实际编程实现时，可以首先按照置信度对预测框进行降序排列，然后从高到低依次对TruePositive的数目进行累加，这样相当于设定了0-1的置信度阈值，进而可以计算得到一系列的精度、召回率值。<br><strong>3. 对精度-召回率曲线下的面积进行积分得到AP</strong><br>经过第二步的计算，对于不同的类别，我们已经得到了相对应的精度-召回率曲线，接下来就是计算曲线下的面积，这里，我们采用积分的方式计算面积。在计算机中是无法精确计算得到曲线的积分值的，只能使用数值积分的方式。<br>采用近似AP的方式计算，公式如下：</p><p><center><br>$AP=\sum_{k=1}^N P(k) \Delta r(k)$<br></center><br>其中：</p><p><center><br>$\Delta r(k)=r(k)-r(k-1)$<br></center><br>以二分类问题得到的曲线为例，取相邻两点之间较大的精度为积分点。</p><p><center><br><img src="https://arleyzhang.github.io/articles/c521a01c/1527520902790.png" alt=""><br></center><br><strong>4. 计算得到mAP</strong><br>经过第三步的计算，我们可以针对所有类别，分别得到各自的AP，接着，只需要对对所有类别的AP进行求和，除以类别数目便可得到mAP。</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
          <category> 目标检测 </category>
          
          <category> 评价指标 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 目标检测 </tag>
            
            <tag> 评价指标 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Faster R-CNN具体实现详解</title>
      <link href="/2019/05/08/faster-r-cnn-ju-ti-shi-xian-xiang-jie/"/>
      <url>/2019/05/08/faster-r-cnn-ju-ti-shi-xian-xiang-jie/</url>
      
        <content type="html"><![CDATA[<h2 id="Faster-R-CNN具体实现详解"><a href="#Faster-R-CNN具体实现详解" class="headerlink" title="Faster R-CNN具体实现详解"></a>Faster R-CNN具体实现详解</h2><p>本文翻译自：<a href="http://www.telesens.co/2018/03/11/object-detection-and-classification-using-r-cnns/" target="_blank" rel="noopener">原文</a></p><h3 id="图像预处理"><a href="#图像预处理" class="headerlink" title="图像预处理"></a>图像预处理</h3><p>在将图片送入网络之前首先执行如下的网络预处理步骤。在训练和前向传播过程中，以下步骤必须一致。均值向量（大小$1*3$，每一个图像通道一个均值）并非当前图像像素值的均值，而是针对所有训练和测试图片所设置的一个统一的初始值。图像预处理流程如下：</p><center><br><img src="/2019/05/08/faster-r-cnn-ju-ti-shi-xian-xiang-jie/img_5aa46e9e0bbd7-1024x421.png"><br></center><p>$tatgetSize$和$maxSize$分别为600，1000.</p><h4 id="网络组织"><a href="#网络组织" class="headerlink" title="网络组织"></a>网络组织</h4><p>R-CNN使用神经网络主要解决如下两个问题：</p><ol><li>识别输入图片中可能包含前景目标的区域（Region of Interest - RoI）。</li><li>计算每一个RoI中的类别概率分布-例如，计算RoI中包含特定类别的目标的概率，在此基础上，可以选择具有最高概率的类别作为分类结果。</li></ol><p>R-CNN主要包含三种类型的神经网络：</p><ol><li>Head</li><li>区域建议网络（Region Proposal Network, RPN）</li><li>分类网络</li></ol><p>R-CNN使用预训练网络（例如ResNet）的前几层从输入图片中提取特征，这一做法由迁移学习理论作为支持（将在一个数据集上训练得到的网络用于不同的问题是可能的）。网络的前几层检测一些通用的特征（如，边、颜色块等在不同的问题中都具有较好的区分性的特征）,而后几层学习到的更多是与特定问题相关的高层特征。在我们搭建的网路中，可以直接将后面几层移除或者在反向传播过程中对其参数进行更新。这些从预训练的网络的前几层迁移过来的层构成了”head”网络。</p><p>由”head”网络产生的卷积特征图将被送入RPN网络中，RPN网络使用一系列的卷积层和全连接层产生可能存在前景目标的RoI区域。接着将使用这些RoI区域从”head”网络产生的特征图中裁剪出相应的特征图区域，称为“crop pooling”.由裁剪池化得到的特征图区域将被送入分类网络，进而经过学习得到该RoI区域所包含的目标种类。</p><p>另一方面，ResNet的权重也可以使用如下方式进行初始化：</p><pre class=" language-python"><code class="language-python">n <span class="token operator">=</span> m<span class="token punctuation">.</span>kernel_size<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">*</span> m<span class="token punctuation">.</span>kernel_size<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">*</span> m<span class="token punctuation">.</span>out_channelsm<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>data<span class="token punctuation">.</span>normal_<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> math<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">.</span> <span class="token operator">/</span> n<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><h3 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h3><p>下图分别展示了上述几种不同的网络模块，图中给出了每一层网络输出和输入特征的大小，这将有助于理解网络中的特征是如何进行转换的，$w,h$表示经过预测后的图片的大小。</p><center><br><img src="http://www.telesens.co/wp-content/uploads/2018/03/img_5a9ffec911c19.png" alt=""><br></center><h3 id="实现细节：训练"><a href="#实现细节：训练" class="headerlink" title="实现细节：训练"></a>实现细节：训练</h3><p>在本节将详细介绍训练R-CNN所涉及到的步骤。一旦理解了训练的流程，理解推理过程将很容易，因为推理只用到了训练过程的一个子集。训练的目标是调整RPN、分类网络以及Head的权重。RPN的任务是产生RoIs区域，分类网络的任务是对每一个RoI给定一个类别分数。为了训练这些网络，我们需要得到相应的ground truths（即图片中所出现的目标的bounding boxes的坐标以及这些目标的类别）。这些信息已经由数据集的标定文件给出，这里有一些常用的通用数据集：</p><ol><li>PASCAL VOC: The <a href="http://host.robots.ox.ac.uk/pascal/VOC/voc2007/index.html" target="_blank" rel="noopener">VOC 2007 </a>database contains 9963 training/validation/test images with 24,640 annotations for 20 object classes.<ul><li><em>Person:</em> person</li><li><em>Animal:</em> bird, cat, cow, dog, horse, sheep</li><li><em>Vehicle:</em> aeroplane, bicycle, boat, bus, car, motorbike, train</li><li><em>Indoor:</em> bottle, chair, dining table, potted plant, sofa, tv/monitor<br>如下图：</li></ul></li></ol><center><br><img src="/2019/05/08/faster-r-cnn-ju-ti-shi-xian-xiang-jie/person_06.jpg"><br></center><ol start="2"><li>COCO (Common Objects in Context): The <a href="http://cocodataset.org/#home" target="_blank" rel="noopener">COCO</a> dataset is much larger. It contains &gt; 200K labelled images with 90 object categories.</li></ol><p>在本次实现中，使用VOC2007数据集。</p><p>下面介绍两个常用概念:</p><ol><li><strong>Bounding Boxes Regression Coefficients</strong>(也成为regression coefficients或regression targets)<br>R-CNN的目标之一就是产生与目标边界尽可能匹配的bounding boxes。R-CNN通过使用回归系数对给定的bounding boxes（给定左上角坐标、宽、高）进行调整来得到匹配的bounding boxes。回归系数由如下方式得出：<br>分别将目标bounding boxes和原始bounding boxes的左上角坐标表示为：$T_x, T_y, O_x, O_y$，width/height表示为$T_w, T_h, O_w, O_h$。那么回归目标（将原始boxes转换为目标boxes的方程的系数）计算如下：<br><center><br>$t _ { x } = \frac { \left( T _ { x } - O _ { x } \right) } { O _ { w } } , t _ { y } = \frac { \left( T _ { y } - O _ { y } \right) } { O _ { h } } , t _ { w } = \log \left( \frac { T _ { w } } { O _ { w } } \right) , t _ { h } = \log \left( \frac { T _ { h } } { O _ { h } } \right)$<br></center><br>上述方程是可翻转的，给定回归系数以及原始boxes的左上角坐标、宽和高，便可以计算得到目标boxes的左上角坐标、宽和高。这一系数对无切仿射变换具有不变性，这一性质在计算分类损失时非常重要。因为目标的回归系数在原始比例的图片上计算得到的，而分类网络输出的回归系数是在由RoI池化所得到的正方形特征图上计算得到的。<br><center><img src="/2019/05/08/faster-r-cnn-ju-ti-shi-xian-xiang-jie/img_5bac3708478ce-1024x479.png"></center></li></ol><p></p><ol start="2"><li><strong>Intersection over Union (IoU) Overlap</strong><br>我们需要一种度量给定得bounding boxes与另一bounding boxes得接近程度（与所使用的度量bounding boxes大小的单位无关）。这一度量方法需要满足，当两个bounding boxes完全重合时，结果为1，当两个bounding boxes完全不重合时，结果为0,同时要易于计算。常用的度量方式为交并比，计算方式如下所示：<br><center><img src="/2019/05/08/faster-r-cnn-ju-ti-shi-xian-xiang-jie/img_5aa6f44a0a9c7.png"><img src="/2019/05/08/faster-r-cnn-ju-ti-shi-xian-xiang-jie/img_5aa6f476535f7-300x292.png"></center></li></ol><p></p><p>有了以上概念之后，可以将训练过程划分为以下模块。一个封装了一系列逻辑步骤（例如，数据的流通）的层以及其他步骤，如，bounding boxes重合度的比较，执行nms等。</p><center><br><img src="/2019/05/08/faster-r-cnn-ju-ti-shi-xian-xiang-jie/img_5aa0053323ac5.png"><br><br></center><ul><li><p><strong>Anchors生成层</strong><br><strong>这一层生成固定数目的anchors</strong>。首先生成9个具有不同尺度、比例的anchors，接着将这9个anchors复制给输入图片上的每一个经过归一化的格子处（每一个格子都包含9个具有不同尺度、比例的anchors，格子的个数由输入图片大小和网络尺度缩小的stride决定）。</p></li><li><p><strong>Proposal Layer</strong><br>在anchors生成层产生的anchors的基础上，依据bounding boxes回归系数来产生经过转化的anchors。然后以每一个anchor属于前景目标的分数为依据，对anchors进行非极大抑制，以对anchors的数目进行进一步的微调。</p></li><li><p><strong>Anchor Target Layer</strong><br><strong>Anchor Target Layer</strong>的目的是产生一些好的anchors以及相对应的前景/背景类标、目标回归系数，以用于RPN的训练。该层的输出仅用于训练RPN，不用于分类层的训练。给定由anchors生成层生成的anchors，anchors target层将对前景/背景目标进行识别，其中与真实标定的重合率高于设定阈值的anchors将被识别为前景目标；与真实标定的重合率低于某一阈值的anchors将被识别为背景目标。</p></li><li><p><strong>RPN Loss</strong><br>RPN损失函数将在训练RPN网络是被最小化。由以下两部分构成：</p><ol><li>RPN所产生的bounding boxes中被正确划分为前景/背景的比例。</li><li>预测的bounding boxe与目标bounding boxes的回归系数的差距。</li></ol></li><li><p><strong>Proposal Target Layer</strong><br>对Proposal Layer产生的anchor进行微调，同时产生类别相关的bounding boxes回归目标，这些目标用于对分类网络进行训练，以得到好类别以及目标回归系数。</p></li><li><p><strong>ROI Pooling Layer</strong><br>依据proposal target layer产生的建议区域的bounding boxes坐标，使用空间转换网络对输入特征图进行采样，这些坐标一般不会位于整型边界，因而需要进行插值采样。</p></li><li><p><strong>Classification Layer</strong><br>分类层以ROI池化层的输出作为输入，将其通过一系列的卷积层后，送入两层全连接层，第一层对于每一个建议区域分别产生类别概率分布；第二层产生类别相关的回归系数。</p></li><li><p><strong>Classification Loss</strong><br>与RPN损失相似，在训练分类层时会最小化分类误差。在反向传播的过程中，误差的梯度同样会流入RPN网络，所以对分类层进行训练时同样也会修改RPN网络的权重。分类误差由以下部分构成：</p><ol><li>由RPN产生的建议区域被正确分类的比例。</li><li>预测的回归系数与目标回归系数之间的差距。</li></ol></li></ul><p>下面将详细介绍每一层：</p><h4 id="Anchor-Generation-Layer"><a href="#Anchor-Generation-Layer" class="headerlink" title="Anchor Generation Layer"></a>Anchor Generation Layer</h4><p>针对整幅输入图像，产生一系列的具有不同尺度和比例的bounding boxes，即anchor boxes。对于所有图片来说，产生的anchor boxes是一样的，例如，与图片的内容无关。Anchor boxes中的一些将包含有目标，而大多数不包含目标。RPN的目标则是识别好的anchor boxes（那些更有可能包含目标的anchor）以及产生bounding boxes回归系数（将anchors转换为更好的bounding boxes）。<br>下图展示了如何生成这些anchor boxes。</p><center><br><img src="/2019/05/08/faster-r-cnn-ju-ti-shi-xian-xiang-jie/img_5aa05d3ecef3e.png"><br><br></center><h4 id="Region-Proposal-Layer"><a href="#Region-Proposal-Layer" class="headerlink" title="Region Proposal Layer"></a>Region Proposal Layer</h4><p>目标检测算法需要将区域建议系统作为输入，区域建议网络会产生一系列稀疏（选择搜索法）或稠密（在deformable part models中使用的特征）的特征。R-CNN的第一个版本使用选择搜索法产生建议区域。在Faster R-CNN中，基于滑窗的技术被用于产生一系列稠密的候选框。接着RPN依据区域包含目标的概率对候选区域进行评分。Region Proposal Layer有两个目的：</p><ol><li>从一系列的anchor中，识别出前景和背景目标。</li><li>通过使用边框回归系数，对anchor的坐标和宽高进行调整，以得到更为精确的anchors（使其更加匹配真正的目标）。</li></ol><p>Region Proposal Layer包含RPN以及Proposal Layer、Anchor Target Layer 和Proposal Target Layer。具体细节描述如下：</p><h4 id="Region-Proposal-Network"><a href="#Region-Proposal-Network" class="headerlink" title="Region Proposal Network"></a>Region Proposal Network</h4><img src="/2019/05/08/faster-r-cnn-ju-ti-shi-xian-xiang-jie/img_5aa0695484e3e.png"><p>RPN的输入为head网络产生的特征图，将该特征图经过一层卷积层（rpn_net）进行处理，后接ReLU激活。激活后的特征图再分别通过两个并行的大小为1x1的卷积层，分别产生前景/背景类别分数和相应的boundig boxes回归系数。Head networks的步长长度与产生anchors时的步长长度相匹配。</p><h3 id="Proposal-Layer"><a href="#Proposal-Layer" class="headerlink" title="Proposal Layer"></a>Proposal Layer</h3><p>Proposal Layer以anchor generation layer产生的anchors为输入，依据各anchors包含前景目标的概率对anchors进行NMS，以达到减少anchors数目的目的。同时，依据由RPN产生的边框回归系数对anchors进行转换。<br><img src="/2019/05/08/faster-r-cnn-ju-ti-shi-xian-xiang-jie/img_5aa5766d53b63.png"></p><h3 id="Anchor-Target-Layer"><a href="#Anchor-Target-Layer" class="headerlink" title="Anchor Target Layer"></a>Anchor Target Layer</h3><p>该层的目的是选择好的anchor boxes，用于训练RPN网络以达到以下目的：</p><ol><li>更好地区别前景和背景目标。</li><li>对于前景目标产生更优的边框回归系数。</li></ol><p>在进一步讲解Anchor Target Layer之前，我们将首先了解RPN损失是如何计算的。</p><h4 id="计算RPN-Loss"><a href="#计算RPN-Loss" class="headerlink" title="计算RPN Loss"></a>计算RPN Loss</h4><p>我们已经知道RPN层的目标是产生好的bounding boxes。为了达到这一目标，RPN必须学会从给定的anchor boxes中区分出前景和背景目标，并计算边框回归系数以对前景anchor boxes的位置、宽和高进行修正，使其更好地匹配前景目标。RPN损失正是以这种方式使得网络学到更好的行为。</p><p>RPN损失可以看作分类损失和边框回归损失之和。分类损失使用交叉熵损失对未被正确分类的boxes进行惩罚，边框回归损失使用真实边框回归系数（使用与前景anchor boxes最为匹配的ground truth boxes计算得到）与预测的边框回归系数（由RPN网络结构中的rpn_bbox_pred_net给出）之间的距离函数计算得出。</p><p>RPN损失如下：</p><center><br><img src="http://www.telesens.co/wp-content/ql-cache/quicklatex.com-142d5b70256748a64605bfc6e2f30ea9_l3.svg" alt=""><br></center><p><strong>Classification Loss:</strong></p><center><br>$cross_entropy(predicted_class, actual_class)$<br></center><p><strong>Bounding Box Regression Loss:</strong></p><center><br><img src="http://www.telesens.co/wp-content/ql-cache/quicklatex.com-79e8cbe4b5682f6abc719c54d768a4ae_l3.svg" alt=""><br></center><p>将所有前景anchor boxes的回归损失相加。不计算背景anchor boxes的回归损失，因为不存在ground truths与背景anchor boxes匹配。回归损失计算如下：</p><center><br><img src="http://www.telesens.co/wp-content/ql-cache/quicklatex.com-f26b9d082be79d08e06cdbeb5cfc1e3a_l3.svg" alt=""><br></center><p>分别对位置坐标和宽、高计算偏差，再求和，其中smooth_l1损失如下：</p><center><br><img src="http://www.telesens.co/wp-content/ql-cache/quicklatex.com-dae64c7ea8affa572e4b38b84688e1fd_l3.svg" alt=""><br></center><p>上式中$\sigma$任意选定（代码中设定为3）。注意，再python实现中，使用表示前景目标的mask aray（bbox_inside_weights）以向量运算的形式来计算损失，以避免for-if循环。</p><p>因而，为了计算损失，我们需要计算如下量：</p><ol><li>类标（前景或背景）以及anchor boxes的分数。</li><li>前景anchor boxes的目标回归系数。</li></ol><p>下面将展示anchor target layer是如何计算得出上述量的。首先选择出在图片内部的anchor boxes；接着，通过计算图像内的所有anchor boxes与所有ground truth boxes的IoU来选出好的前景boxes。基于重合度，以下两类boxesb被标记为前景：</p><ol><li>对于每一个ground truth box，与其有着最大重合度的anchor被设定为前景框。</li><li>与一些ground truth boxes的最大重合度超过了设定的阈值。</li></ol><p>如下图所示：</p><center><br><img src="http://www.telesens.co/wp-content/uploads/2018/03/img_5aa13d4d911d3.png" alt=""><br></center><p>注意，只有与一些ground truth boxes的重合度超过给定的阈值的anchor boxes才会被选定为前景框。这一做法的目的是为了避免RPN进行一些无望的学习任务（学习一些与最匹配的ground truth boxes相距较远的anchor boxes）。同样，重合度低于负样本阈值的anchor boxes将被归类为背景框。并不是所有未被划分为前景框的目标都会被划分为背景框。这些既未被划分为前景框，也未被划分未背景框的anchor boxes是不被关心的。再计算RPN损失时，不计算这些框。</p><p>有两个阈值与我们想要的到的总的背景目标和前景目标的数目有关，数目的小数部分被记作前景。如果通过测试的前景目标的数目超过了阈值，我们便将这些超过部分的前景框随机标记为“don’t care”。同样的做法被应用与背景框。</p><p>接着，我们计算前景框和与其相对应的ground truths boxes的边框回归系数。这一步是很容易的，依据给定公式进行计算即可。</p><p>总结该层的输入、输出如下：</p><p><strong>参数：</strong></p><ul><li>TRAIN.RPN_POSITIVE_OVERLAP: 确定anchor box是否是好的前景框 (Default: 0.7)</li><li>TRAIN.RPN_NEGATIVE_OVERLAP: 如果一个anchor与最匹配的ground truth box的重合度小于该阈值，则将其标定为背景。阈值大于RPN_NEGATIVE_OVERLAP但小于RPN_POSITIVE_OVERLAP的框被标记为“don’t care”。(Default: 0.3)</li><li>TRAIN.RPN_BATCHSIZE: 前景和背景框的总数。 (default: 256)</li><li>TRAIN.RPN_FG_FRACTION: 前景框所占比例 (default: 0.5).如果前景框的数目大于<br>TRAIN.RPN_BATCHSIZE$\times$TRAIN.RPN_FG_FRACTION, 超出的部分将被标记为 (随机选择索引) “don’t care”.</li></ul><p><strong>输入：</strong></p><ul><li>RPN Network Outputs (predicted foreground/background class labels, regression coefficients)</li><li>Anchor boxes (由anchor generation layer生成)</li><li>Ground truth boxes</li></ul><p><strong>输出：</strong></p><ul><li>好的foreground/background boxes以及相关类标。</li><li>目标框回归系数。</li></ul><p>其它几层，proposal target layer、RoI pooling layer、classfication layer用于产生计算分类损失所需的信息。正如我们介绍anchor target layer那样，将首先介绍计算分类层损失所需的信息。</p><h3 id="Calculating-Classification-Layer-Loss"><a href="#Calculating-Classification-Layer-Loss" class="headerlink" title="Calculating Classification Layer Loss"></a>Calculating Classification Layer Loss</h3><p>与RPN损失类似，分类层损失可以分为两部分-分类损失和边框回归损失。<br><img src="http://www.telesens.co/wp-content/ql-cache/quicklatex.com-a01bdc80cc44f16d0971e77943f816b7_l3.svg" alt=""><br>RPN层与分类层的主要不同是RPN解决两分类问题-前景和背景，分类层需要处理所有的目标类别（外加背景类）。</p><p>分类损失等于真实类别与预测类别之间的交叉熵损失，计算方式如下：<br><img src="http://www.telesens.co/wp-content/uploads/2018/03/img_5aa1cd250f265-1.png" alt=""><br>在上述矩阵中，每一行表示一个样本属于各个类的分数，最后一列表示当前样本的真实类别索引（0表示背景）。交叉熵计算如下：<br><img src="http://www.telesens.co/wp-content/uploads/2018/03/img_5aa1bf41503d4-1.png" alt=""></p><p>这里的bounding boxes的回归损失的计算方式与RPN中的计算方式类似，除了这里的回归系数是与类别相关的。网络针对每一个目标种类分别计算一个边框回归系数。很明显，目标回归系数只对正确的类别有效，正确的类别即与给定的anchor box有着最大的重合度的ground truth的类别。在计算回归私塾损失时，使用mask矩阵标定anchor box所对应的正确类别。不正确的类别的回归系数则被忽略。mask矩阵的使用避免了复杂的for循环，而采用矩阵乘法的形式，更为高效。</p><p>在计算classification layer loss需要以下数值：</p><ul><li>预测的类标及网络回归系数（由分类网络输出）。</li><li>每一个anchor box的类别。</li><li>目标边框回归系数。</li></ul><p>下面将展示这些数值是如何通过proposal target和分类层得到的。</p><h3 id="Proposal-Target-Layer"><a href="#Proposal-Target-Layer" class="headerlink" title="Proposal Target Layer"></a>Proposal Target Layer</h3><p>Proposal Target Layer的作用是从proposal layer输出的RoIs中选择出有可能存在目标的RoIs。这些RoIs将被用于对head layer产生的特征图进行裁剪池化(crop pooling)，裁剪得到的小的特征图将被传入网络的剩余部分，进而计算得出预测的类别分数和边框回归系数。</p><p>与anchor target layer类似，选择好的proposals（与gt boxes有着最大重合度的）传入classification layer是很重要的。否则，classification layer所学习的将是无望的学习任务。</p><p>传入proposal layer target层的是由proposal layer计算得出的RoIs。使用每一个RoI与gt的重合度中最大的一个将RoI划分为前景或背景目标。最大重合度超过给定阈值（TRAIN.FG_THRESH, default: 0.5）的将被设定为前景目标。最大重合度位于阈值区间 TRAIN.BG_THRESH_LO 和 TRAIN.BG_THRESH_HI (default 0.1, 0.5)中的将被设定为背景目标。下面是一个称为“hard negative mining”的方法，该方法将识别起来较为困难的样本传入分类层。</p><p>该方法的目标是使得正样本和负样本的数目保持为常数。为了避免出现背景目标过少的情况，该算法通过随机重复一些背景目标的索引来补足batch中的差额。</p><p>接着，边框回归系数误差将在每一个RoI及其匹配的gt之间计算得到（包括背景RoI,因为对于这些背景目标，同样存在与其重叠的gt）。这些回归目标将被扩充至所有的类别，如下图所示：</p><center><br><img src="/2019/05/08/faster-r-cnn-ju-ti-shi-xian-xiang-jie/img_5aa32302afc0b-1.png"><br></center><p>图中的bbox_inside_weights是一个掩模矩阵，只有前景目标所对应的正确的类别处的值为1，其他值为0，同样，背景目标所对应的值为0。因为在计算classification layer loss时，只有前景目标的边框回归损失才被包括在内，背景目标的边框回归损失不计。但在计算classification loss时，要计算背景目标，因为背景目标所属的类别为0.</p><p><strong>输入：</strong></p><ol><li>由 proposal layer产生的RoIs。</li><li>ground truth信息。</li></ol><p><strong>输出：</strong></p><ol><li>符合重合度标准的前景和背景目标。</li><li>RoIs的类别相关的目标回归系数。</li></ol><p><strong>参数：</strong></p><ol><li>TRAIN.FG_THRESH:（default: 0.5）用于选择前景目标。与gt的最大重合度高于该阈值的RoI被设定为前景目标。</li><li>TRAIN.BG_THRESH_HI: (default 0.5)</li><li>TRAIN.BG_THRESH_LO: (default 0.1)这俩个参数用于选择背景目标，最大重合度位于这两个数所指定的区间内的RoI被设定为背景目标。</li><li>TRAIN.BATCH_SIZE：（default 128）前景和被选中的背景目标的总数。</li><li>TRAIN.FG_FRACTION：（default 0.25）前景目标的数目不能超过BATCH_SIZE*FG_FRACTION。</li></ol><h3 id="Crop-Pooling"><a href="#Crop-Pooling" class="headerlink" title="Crop Pooling"></a>Crop Pooling</h3><p>Proposal target layer产生可能的ROIs，我们使用这些ROIs进行分类，同时使用边框回归系数进行训练。下一步是使用这些ROIs从由head network产生的特征图中抽取对应的特征。这些抽取得到的特征图将被用于剩下的网络层，进一步产生目标类别概率分布和每一个ROIs的边框回归系数。裁剪池化（Crop Pooling）的作用就是从卷积特征图中抽取ROIs对应的特征图。</p><p>裁剪池化的核心内容描述于“Spatial Transformation Networks” <a href="http://www.telesens.co/2018/03/11/object-detection-and-classification-using-r-cnns/#ITEM-1455-7" target="_blank" rel="noopener">(Anon. 2016)</a><a href="https://arxiv.org/pdf/1506.02025.pdf" target="_blank" rel="noopener">*</a>。<strong>目标是在输入特征图上使用一个扭曲函数(warping function)（2x3的仿射变换矩阵）来输出经过旋转的矩阵</strong>，如下图所示。</p><center><br><img src="/2019/05/08/faster-r-cnn-ju-ti-shi-xian-xiang-jie/img_5aa402baba3a1-1.png"><br><br></center><p>裁剪池化涉及以下两个步骤：</p><ol><li><p>对一个集合的目标坐标应用仿射变换，得到一个方格的源坐标。仿射变换的公式为：$\left[ \begin{array} { c } { x _ { i } ^ { s } } \ { y _ { i } ^ { s } } \end{array} \right] = \left[ \begin{array} { l l l } { \theta _ { 11 } } &amp; { \theta _ { 12 } } &amp; { \theta _ { 13 } } \ { \theta _ { 21 } } &amp; { \theta _ { 22 } } &amp; { \theta _ { 23 } } \end{array} \right] \left[ \begin{array} { l } { x _ { i } ^ { t } } \ { y _ { i } ^ { t } } \ { 1 } \end{array} \right]$，其中，$x _ { i } ^ { s } , y _ { i } ^ { s } , x _ { i } ^ { t } , y _ { i } ^ { t }$都是各自使用width/height归一化的坐标，因而$- 1 \leq x _ { i } ^ { s } , y _ { i } ^ { s } , x _ { i } ^ { t } , y _ { i } ^ { t } \leq 1$。</p></li><li><p>第二步，使用第一步产生的源坐标对输入（source）特征图进行采样得到目标（destination）特征图。每一对$\left( x _ { i } ^ { S } , y _ { i } ^ { s } \right)$都对应输入特征图中的一个空间位置，接着使用采样核（如双线性采样核）对该位置进行采样，最终得到输出图像上相对应的特定位置的值。</p></li></ol><p>Spatial transformation中所描述的采样方法是可微的，因而损失的梯度可以直接反向传播回输入特征图和采样的方格坐标。</p><p>幸运的是，pytroch提供了裁剪池化对应的API，API中的两个函数分别对应上述两个步骤。<code>torch.nn.functional.affine_grid</code>以仿射变换矩阵为输入，输出一个集合的采样坐标，<code>torch.nn.functional.grid_sample</code>对这些坐标处的格子进行采样。Pytorch自动进行误差梯度的反向传播。</p><p>为了使用裁剪池化，我们需要进行如下操作：</p><ol><li><p>将RoI的坐标除以head network的stride长度。Proposal target layer产生的是原始输入图像上的坐标（800x600）.为了将这些坐标转换至”head”网络所输出的特征图上，我们必须将这些坐标除以stride（本次实现中为16）。</p></li><li><p>为了使用API，我们需要提供仿射变换矩阵，仿射变换矩阵的计算方法如下所示。</p></li><li><p>我们同样需要知道目标特征图中x、y两个维度上的点的个数。这一参数由<code>cfg.POOLING_SIZE</code>(default 7）提供。因而，在进行裁剪池化时，非正方形RoI将被用于从卷积特征图上裁剪出大小恒定的正方形特征图。必须执行裁剪池化操作，因为接下来的卷积操作要求输入的特征图大小是固定的。</p></li></ol><p>仿射变换矩阵的计算方法如下：</p><center><br><img src="/2019/05/08/faster-r-cnn-ju-ti-shi-xian-xiang-jie/img_5aa4255fdacb6.png"><br><br></center><p>我们所需要的是未经过扭曲的变换，由于我们已经知道了源坐标（对预测得出的RoI的坐标进行归一化得到）和目标坐标的值（池化得到的特征图的对角坐标是固定的，如上图所示），使用简单的矩阵运算即可得出仿射变换矩阵。由于每一个RoI的坐标都是不同的，所以对于每一个RoI都需要单独计算一个仿射变换矩阵。</p><h3 id="Classification-Layer"><a href="#Classification-Layer" class="headerlink" title="Classification Layer"></a>Classification Layer</h3><p>裁剪池化层以proposal target layer输出的RoIs和head network输出的特征图为输入，输出固定大小的输出特征图。该输出特征图将被传入后接最大池化（用于改变特征图的空间大小）的四层ResNet。结果（代码中为”fc7”）是，对于每一个RoI将得到一个一维的特征向量。流程如下：</p><center><br><img src="/2019/05/08/faster-r-cnn-ju-ti-shi-xian-xiang-jie/img_5aa55c81eac0a-1024x757.png"><br><br></center><p>所产生的一维特征将被传入另个全连接层bbox_pred_net和cls_score_net。针对每一个bounding boxes，cls_score_net layer将产生类别分数（可以使用softmax将其转换为概率）。bbox_pred_net layer将产生类别相关的边框回归系数，该回归系数将和由proposal target layer产生的原始的边框回归系数一起产生最后的bounding boxes。流程如下：</p><center><br><img src="/2019/05/08/faster-r-cnn-ju-ti-shi-xian-xiang-jie/img_5aa55c97f3287.png"><br><br></center><p>有必要回顾一下两个边框回归系数的差别-第一个由RPN网络产生，第二个由分类网络产生。第一个用于引导RPN网络产生好的前景目标框（与目标边界框贴合地更加紧）。目标回顾系数由anchor target layer产生。很难清楚地解释学习过程是如何发生地，但我可以假设，卷积网络和全连接网络会将由神经网络产生的不同的图像特征图转换为尽可能好的目标边界框。我们将会在前向推理章节介绍回归系数的使用方法。</p><p>第二个边框回归系数由classification layer层产生。这些回归系数是类别相关的，即，对于每一个RoI,会针对每一个类别分别产生一个边框回归系数。这些回归系数的目标回归系数是由proposal target layer产生的。要注意到，classification layer作用于由仿射变化所产生的正方形特征图上。然而，因为回归系数对于无裁剪的仿射变换具有不变性，由proposal target layer产生的目标回归系数才可以和classification layer产生的边框回归系数进行比较，并作为一个有效的学习信号。</p><p>要注意的是，在训练classification layer时，误差的梯度同样反向传播至RPN层。这时由于在进行裁剪池化时所用的RoI坐标正是网络的输出本身，这些坐标正是将RPN的输出施加在anchor boxes上得出的。在反向传播过程中，误差的梯度将通过裁剪池化传播至RPN。计算和实现这些梯度运算是存在一定的难度的，庆幸的是这些运算pytorch中已经给出了实现。</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
          <category> 目标检测 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 目标检测 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mask R-CNN论文解读</title>
      <link href="/2019/05/05/mask-r-cnn-lun-wen-jie-du/"/>
      <url>/2019/05/05/mask-r-cnn-lun-wen-jie-du/</url>
      
        <content type="html"><![CDATA[<h1 id="Mask-R-CNN"><a href="#Mask-R-CNN" class="headerlink" title="Mask R-CNN"></a>Mask R-CNN</h1><h2 id="作者"><a href="#作者" class="headerlink" title="作者"></a>作者</h2><p>何凯明 Geeorgia Gkioxari Piotr Dollar Ross Girshick</p><h2 id="内容"><a href="#内容" class="headerlink" title="内容"></a>内容</h2><p>在本文中，作者提出了一种用于目标实例分割的方法。该方法在检测目标的同时针对每一个目标实例产生一个高质量的分割蒙板。Mask R-CNN通过在Faster R-CNN现有的用于目标检测的分支的基础上添加用于目标mask预测的分支实现。</p><h2 id="目标检测、目标实例分割、语义分割"><a href="#目标检测、目标实例分割、语义分割" class="headerlink" title="目标检测、目标实例分割、语义分割"></a>目标检测、目标实例分割、语义分割</h2><p>如下图所示：</p><center><br><img src="https://img-blog.csdn.net/20171121232307984?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGlhbWVudGluZ3Rhbw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt=""><br><br></center><ul><li>图片分类<br>仅需要识别出一张图片中存在哪几类目标即可。</li><li>目标检测<br>需要给出图片中目标的类别和具体位置。</li><li>语义分割<br>对图片中的目标进行像素级分割，但只需要区分不同类别目标即可，统一类别的目标不需要区分。</li><li>实例分割<br>对图片中的目标进行像素级分割，但需要区分不同的实例，同一类别的不同个体同样需要进行区分。</li></ul><h2 id="Mask-R-CNN-解决实例分割问题"><a href="#Mask-R-CNN-解决实例分割问题" class="headerlink" title="Mask R-CNN:解决实例分割问题"></a>Mask R-CNN:解决实例分割问题</h2><p><strong>R-CNN的网络结构：</strong></p><center><br><img src="/2019/05/05/mask-r-cnn-lun-wen-jie-du/5d9736d2-0b1a-43fa-912a-60be077b0387.jpg"><br></center><p><strong>Fast R-CNN的网络结构：</strong></p><center><br><img src="/2019/05/05/mask-r-cnn-lun-wen-jie-du/b65ae552-1ac7-478c-91d8-82ae6e23d285.jpg"><br><br></center><p><strong>Faster R-CNN的网络结构</strong></p><center><br><img src="/2019/05/05/mask-r-cnn-lun-wen-jie-du/b19b660d-8e82-48cf-817d-1429475f15be.jpg"><br><br></center><p><strong>Mask R-CNN的总体框架如图所示：</strong></p><center><br><img src="/2019/05/05/mask-r-cnn-lun-wen-jie-du/27847427-802c-4928-8626-e535429eae7a.jpg"><br><br></center><br><center><br><img src="/2019/05/05/mask-r-cnn-lun-wen-jie-du/d1f5ad89-4152-4cf0-b22b-6b307397dee6.jpg"><br><br></center><p>作者在Faster R-CNN原有的用于预测目标bounding boxes的子网络的基础上，添加用于预测mask的分支，使用FCN(全卷积网络)对每一个RoI分别进行预测。Faster R-CNN并不是为网络输入与输出之间的像素级的匹配而设计的，这一问题主要是由RoIPool层的空间量化操作所导致的。为了解决这一问题，作者提出了一种简单的、无需量化的层，即RoIAlign，该层的引入极大地保证了空间位置地准确性。RoIAlign层对最终的检测结果有着极大的影响。<br>除此之外，作者发现很有必要对mask预测和类别预测进行解耦和。针对每一类分别预测一层mask，类别之间不存在竞争关系，将类别预测任务交给RoI的分类分支。</p><h3 id="RoIAlign"><a href="#RoIAlign" class="headerlink" title="RoIAlign"></a>RoIAlign</h3><p>给定特征图如下所示：</p><center><br><img src="/2019/05/05/mask-r-cnn-lun-wen-jie-du/ee623a5f-c1f5-4a2a-98f7-4c94fa379a3a.jpg"><br><br></center><p>传统的RoIPool层针对每一个RoI分别产生一层小的特征图。RoIPool的步骤如下：</p><ol><li>首先对RoI的浮点坐标、大小参数进行量化，将其对应到特征图中。<br><center><img src="/2019/05/05/mask-r-cnn-lun-wen-jie-du/bf8dcd4c-4274-44c7-ab9d-0ed1ebea64fa.jpg"></center></li></ol><p></p><ol start="2"><li>接着经过量化的RoI将被划分为格子，针对每一个格子内部进行池化操作，进而得到固定大小的特征图。<br><center><img src="/2019/05/05/mask-r-cnn-lun-wen-jie-du/82c99a99-edf8-4c09-9e5c-b7f9ea190722.jpg"></center></li></ol><p></p><p>在上述操作中，共存在两步取整操作，一个是将RoI对应至特征图时，一个是对量化后的RoI进行划分。这两步取整量化操作会导致原始RoI与抽取出的特征图在空间位置上不匹配。这一问题不会对目标的分类造成大的影响，但会对mask预测造成极大的负面影响。</p><p>为了解决这一问题，作者提出了RoIAlign层，RoIAlign去除了量化取整操作，使得抽取的特征图与输入图片有着精确的位置对应。对于RoI中的每一个格子，使用双线性插值法计算其对应的值，双线性插值法需要的原始值来自于格子四角位置上的值。如下图所示：</p><center><br><img src="/2019/05/05/mask-r-cnn-lun-wen-jie-du/86330610-af9b-4205-9736-3240e2bcadb2.jpg"><br><br></center><br>整体步骤如下：<br>1. 使用浮点运算，将RoI对应至特征图的相应位置<br><center><br><img src="/2019/05/05/mask-r-cnn-lun-wen-jie-du/2e9be7aa-3b8d-4bc1-ab91-c7a24239e866.jpg"><br><br></center><ol start="2"><li>将每一个格子划分为四个小格子<br><center><img src="/2019/05/05/mask-r-cnn-lun-wen-jie-du/6424cdaa-67a6-4774-8d71-662bbba20f6c.jpg"></center></li></ol><p></p><ol start="3"><li>使用双线性插值法计算每一个格子的值，取四角的值为原始值<br><center></center></li></ol><p></p><ol start="4"><li>对每一个格子进行池化操作，得到最终结果<br><center></center></li></ol><p></p><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>损失函数由类别损失、边框回归损失、mask损失三部分构成，与其他方法不同，计算mask损失时，对预测的各个类别的mask分别使用sigmoid函数进行激活（而不是使用softmax函数对所有类别的mask进行激活），接着使用二维交叉熵计算损失。</p><h3 id="实现细节"><a href="#实现细节" class="headerlink" title="实现细节"></a>实现细节</h3><p>用于预测mask的子网络的结构如图所示：</p><center><br><img src="/2019/05/05/mask-r-cnn-lun-wen-jie-du/e0da9a7e-36b8-468e-8860-db023a099a91.jpg"><br><br></center><p>左侧使用resnet-c4作为前面的卷积网络，将rpn生成的roi映射到C4的输出，并进行roi pooling，最后进行分叉预测三个目标。右侧即使用Faster R-CNN加FPN的结构。</p><h3 id="对比实验"><a href="#对比实验" class="headerlink" title="对比实验"></a>对比实验</h3><p>与FCIS+++的对比，如下图所示：</p><p><center><br><img src="/2019/05/05/mask-r-cnn-lun-wen-jie-du/170fbc97-7e4f-44bd-bf89-dbeae157b64a.jpg"></center></p><p><br>在FCIS++的预测中会在目标重合位置出现一条直线，而Mask R-CNN的预测结果则没有。</p><p><strong>消融实验</strong><br>结果如图所示：</p><p><center><br><img src="/2019/05/05/mask-r-cnn-lun-wen-jie-du/3095a77a-a0f9-4b7f-9482-42fde3b002fd.jpg"></center></p><p><br>作者分别给出了不同backbone、多任务和独立任务、使用RoIAligh和不使用、使用FPN进行结果预测和使用全连接层的对比结果。</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
          <category> 实例分割 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 论文阅读 </tag>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SSD论文阅读及核心代码解析</title>
      <link href="/2019/04/30/ssd-lun-wen-yue-du-ji-he-xin-dai-ma-jie-xi/"/>
      <url>/2019/04/30/ssd-lun-wen-yue-du-ji-he-xin-dai-ma-jie-xi/</url>
      
        <content type="html"><![CDATA[<h2 id="SSD-Single-Shot-MultiBox-Detector"><a href="#SSD-Single-Shot-MultiBox-Detector" class="headerlink" title="SSD:Single Shot MultiBox Detector"></a>SSD:Single Shot MultiBox Detector</h2><hr><h2 id="作者"><a href="#作者" class="headerlink" title="作者"></a>作者</h2><p><strong>Wei Liu</strong></p><h2 id="内容"><a href="#内容" class="headerlink" title="内容"></a>内容</h2><p>在本文中,作者提出了一种使用单个神经网络进行目标检测的框架,该框架的特点如下:</p><ol><li><p>将网络的bounding boxes的输出空间划分为default boxes的集合,这些boxes具有不同的尺度和比例.对于被选中用于目标预测的feature maps,网络会针对该特征图中的每一个位置预测多个default boxes,这些default boxes又称为anchors.<br>对于每一个default box,网络给出其存在目标的分数(每一个类别分别预测一个),同时给出在default box的基础上进行形状调整的参数.</p></li><li><p>为了应对目标的尺度变化,SSD在来自于网络的多个具有不同分辨率的feature maps上进行预测.其中,靠近网络前侧,具有较高分辨率的feature map适用于进行小目标的检测,而后侧的feature maps适用于大目标的检测.</p></li></ol><p>作者将本文的贡献总结如下:</p><ol><li>SSD的核心是:在事先设定的固定大小,比例的default boxes的基础上,使用较小的卷积核预测目标隶属于某一类的分数以及box的偏差.</li><li>为了获得较高的检测准确率,在具有不同大小的feature maps上产生具有不同尺度的预测,且这些预测又可以具有不同的长宽比.</li><li>网络可以进行end-to-end训练,同时取得不错的准确率.</li></ol><h2 id="SSD网络结构"><a href="#SSD网络结构" class="headerlink" title="SSD网络结构"></a>SSD网络结构</h2><h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>SSD方法基于前馈神经网络,该网络产生固定数目的bounding boxes集合,同时给出这些boxes中存在某一类别的目标的分数,在这些bounding boxes的基础上,使用NMS算法求出最后的结果.网络的结构如下:</p><center><br><img src="/2019/04/30/ssd-lun-wen-yue-du-ji-he-xin-dai-ma-jie-xi/SSD网络结构.png" title="SSD网络结构"><br></center><p>由上图可以发现,总共选取了6层具有不同大小的feature maps用于目标检测,与R-CNN等方法使用全连接层给出预测结果不同,SSD使用较小的卷积计算得到预测结果.对于每一层feature map,使用一个卷积核计算得到各个default boxes属于某一类的分数,使用另一个卷积核得到在各个default boxes位置的基础上的偏差.</p><h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><h4 id="匹配策略"><a href="#匹配策略" class="headerlink" title="匹配策略"></a>匹配策略</h4><p>在进行训练的时候,需要决定哪一个default boxes与ground truth相关联,只有被选中的default boxes才会参与训练.所采取的策略为:<strong>首先将每一个ground truth和与其覆盖率最大的default boxes进行匹配,接着将与ground truth的jaccard重合率高于设定阈值的default boxes视为匹配</strong>,这样,在第一步保证每一个ground truth都会有匹配的default boxes的基础上,第二步使得多个default boxes可以匹配同一个ground truth.这一设定简化了学习问题,使得网络可以对多个重合的default boxes给出较高的预测分数,而不是仅仅选择具有最高重合率的一个.<br>匹配代码如下:</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># ./layers/box_utils.py</span><span class="token keyword">def</span> <span class="token function">point_form</span><span class="token punctuation">(</span>boxes<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># 将(cx, cy, w, h) 形式的box坐标转换成 (xmin, ymin, xmax, ymax) 形式</span>    <span class="token keyword">return</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span> <span class="token punctuation">(</span>boxes<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">-</span> boxes<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token operator">/</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment" spellcheck="true"># xmin, ymin</span>                    <span class="token punctuation">(</span>boxes<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">+</span> boxes<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token operator">/</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># xmax, ymax</span><span class="token keyword">def</span> <span class="token function">intersect</span><span class="token punctuation">(</span>box_a<span class="token punctuation">,</span> box_b<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># box_a: (truths), (tensor:[num_obj, 4])</span>    <span class="token comment" spellcheck="true"># box_b: (priors), (tensor:[num_priors, 4], 即[8732, 4])</span>    <span class="token comment" spellcheck="true"># return: (tensor:[num_obj, num_priors]) box_a 与 box_b 两个集合中任意两个 box 的交集, 其中res[i][j]代表box_a中第i个box与box_b中第j个box的交集.(非对称矩阵)</span>    <span class="token comment" spellcheck="true"># 思路: 先将两个box的维度扩展至相同维度: [num_obj, num_priors, 4], 然后计算面积的交集</span>    <span class="token comment" spellcheck="true"># 两个box的交集可以看成是一个新的box, 该box的左上角坐标是box_a和box_b左上角坐标的较大值, 右下角坐标是box_a和box_b的右下角坐标的较小值</span>    A <span class="token operator">=</span> box_a<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>    B <span class="token operator">=</span> box_b<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># box_a 左上角/右下角坐标 expand以后, 维度会变成(A,B,2), 其中, 具体可看 expand 的相关原理. box_b也是同理, 这样做是为了得到a中某个box与b中某个box的左上角(min_xy)的较大者(max)</span>    <span class="token comment" spellcheck="true"># unsqueeze 为增加维度的数量, expand 为扩展维度的大小</span>    min_xy <span class="token operator">=</span> torch<span class="token punctuation">.</span>max<span class="token punctuation">(</span>box_a<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>expand<span class="token punctuation">(</span>A<span class="token punctuation">,</span>B<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                        box_b<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>expand<span class="token punctuation">(</span>A<span class="token punctuation">,</span>B<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 在box_a的 A 和 2 之间增加一个维度, 并将维度扩展到 B. box_b 同理</span>    <span class="token comment" spellcheck="true"># 求右下角(max_xy)的较小者(min)</span>    max_xy <span class="token operator">=</span> torch<span class="token punctuation">.</span>min<span class="token punctuation">(</span>box_a<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>expand<span class="token punctuation">(</span>A<span class="token punctuation">,</span>B<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                        box_b<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>expand<span class="token punctuation">(</span>A<span class="token punctuation">,</span>B<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    inter <span class="token operator">=</span> torch<span class="token punctuation">.</span>clamp<span class="token punctuation">(</span><span class="token punctuation">(</span>max_xy<span class="token punctuation">,</span> min_xy<span class="token punctuation">)</span><span class="token punctuation">,</span> min<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 右下角减去左上角, 如果为负值, 说明没有交集, 置为0</span>    <span class="token keyword">return</span> inter<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">*</span> inter<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token comment" spellcheck="true"># 高×宽, 返回交集的面积, shape 刚好为 [A, B]</span><span class="token keyword">def</span> <span class="token function">jaccard</span><span class="token punctuation">(</span>box_a<span class="token punctuation">,</span> box_b<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># A ∩ B / A ∪ B = A ∩ B / (area(A) + area(B) - A ∩ B)</span>    <span class="token comment" spellcheck="true"># box_a: (truths), (tensor:[num_obj, 4])</span>    <span class="token comment" spellcheck="true"># box_b: (priors), (tensor:[num_priors, 4], 即[8732, 4])</span>    <span class="token comment" spellcheck="true"># return: (tensor:[num_obj, num_priors]), 代表了 box_a 和 box_b 两个集合中任意两个 box之间的交并比</span>    inter <span class="token operator">=</span> intersect<span class="token punctuation">(</span>box_a<span class="token punctuation">,</span> box_b<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 求任意两个box的交集面积, shape为[A, B], 即[num_obj, num_priors]</span>    area_a <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>box_a<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token operator">-</span>box_a<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span>box_a<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token operator">-</span>box_a<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>expand_as<span class="token punctuation">(</span>inter<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># [A,B]</span>    area_b <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>box_b<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token operator">-</span>box_b<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span>box_b<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token operator">-</span>box_b<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>expand_as<span class="token punctuation">(</span>inter<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># [A,B], 这里会将A中的元素复制B次</span>    union <span class="token operator">=</span> area_a <span class="token operator">+</span> area_b <span class="token operator">-</span> inter    <span class="token keyword">return</span> inter <span class="token operator">/</span> union <span class="token comment" spellcheck="true"># [A, B], 返回任意两个box之间的交并比, res[i][j] 代表box_a中的第i个box与box_b中的第j个box之间的交并比.</span><span class="token keyword">def</span> <span class="token function">encode</span><span class="token punctuation">(</span>matched<span class="token punctuation">,</span> priors<span class="token punctuation">,</span> variances<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># 对边框坐标进行编码, 需要宽度方差和高度方差两个参数, 具体公式可以参见原文公式(2)</span>    <span class="token comment" spellcheck="true"># matched: [num_priors,4] 存储的是与priorbox匹配的gtbox的坐标. 形式为(xmin, ymin, xmax, ymax)</span>    <span class="token comment" spellcheck="true"># priors: [num_priors, 4] 存储的是priorbox的坐标. 形式为(cx, cy, w, h)</span>    <span class="token comment" spellcheck="true"># return : encoded boxes: [num_priors, 4]</span>    g_cxy <span class="token operator">=</span> <span class="token punctuation">(</span>matched<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">+</span> matched<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">2</span> <span class="token operator">-</span> priors<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token comment" spellcheck="true"># 用互相匹配的gtbox的中心坐标减去priorbox的中心坐标, 获得中心坐标的偏移量</span>    g_cxy <span class="token operator">/=</span> <span class="token punctuation">(</span>variances<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">*</span>priors<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 令中心坐标分别除以 d_i^w 和 d_i^h, 正如原文公式所示</span>    <span class="token comment" spellcheck="true">#variances[0]为0.1, 令其分别乘以w和h, 得到d_i^w 和 d_i^h</span>    g_wh <span class="token operator">=</span> <span class="token punctuation">(</span>matched<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">-</span> matched<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">/</span> priors<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token comment" spellcheck="true"># 令互相匹配的gtbox的宽高除以priorbox的宽高.</span>    g_wh <span class="token operator">=</span> torch<span class="token punctuation">.</span>log<span class="token punctuation">(</span>g_wh<span class="token punctuation">)</span> <span class="token operator">/</span> variances<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token comment" spellcheck="true"># 这里这个variances[1]=0.2 不太懂是为什么.</span>    <span class="token keyword">return</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>g_cxy<span class="token punctuation">,</span> g_wh<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 将编码后的中心坐标和宽高``连接起来, 返回 [num_priors, 4]</span><span class="token keyword">def</span> <span class="token function">match</span><span class="token punctuation">(</span>threshold<span class="token punctuation">,</span> truths<span class="token punctuation">,</span> priors<span class="token punctuation">,</span> variances<span class="token punctuation">,</span> labels<span class="token punctuation">,</span> loc_t<span class="token punctuation">,</span> conf_t<span class="token punctuation">,</span> idx<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># threshold: (float) 确定是否匹配的交并比阈值</span>    <span class="token comment" spellcheck="true"># truths: (tensor: [num_obj, 4]) 存储真实 box 的边框坐标</span>    <span class="token comment" spellcheck="true"># priors: (tensor: [num_priors, 4], 即[8732, 4]), 存储推荐框的坐标, 注意, 此时的框是 default box, 而不是 SSD 网络预测出来的框的坐标, 预测的结果存储在 loc_data中, 其 shape 为[num_obj, 8732, 4].</span>    <span class="token comment" spellcheck="true"># variances: cfg['variance'], [0.1, 0.2], 用于将坐标转换成方便训练的形式(参考RCNN系列对边框坐标的处理)</span>    <span class="token comment" spellcheck="true"># labels: (tensor: [num_obj]), 代表了每个真实 box 对应的类别的编号</span>    <span class="token comment" spellcheck="true"># loc_t: (tensor: [batches, 8732, 4]),</span>    <span class="token comment" spellcheck="true"># conf_t: (tensor: [batches, 8732]),</span>    <span class="token comment" spellcheck="true"># idx: batches 中图片的序号, 标识当前正在处理的 image 在 batches 中的序号</span>    overlaps <span class="token operator">=</span> jaccard<span class="token punctuation">(</span>truths<span class="token punctuation">,</span> point_form<span class="token punctuation">(</span>priors<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># [A, B], 返回任意两个box之间的交并比, overlaps[i][j] 代表box_a中的第i个box与box_b中的第j个box之间的交并比.</span>    <span class="token comment" spellcheck="true"># 二部图匹配(Bipartite Matching)</span>    <span class="token comment" spellcheck="true"># [num_objs,1], 得到对于每个 gt box 来说的匹配度最高的 prior box, 前者存储交并比, 后者存储prior box在num_priors中的位置</span>    best_prior_overlap<span class="token punctuation">,</span> best_prior_idx <span class="token operator">=</span> overlaps<span class="token punctuation">.</span>max<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># keepdim=True, 因此shape为[num_objs,1]</span>    <span class="token comment" spellcheck="true"># [1, num_priors], 即[1,8732], 同理, 得到对于每个 prior box 来说的匹配度最高的 gt box</span>    best_truth_overlap<span class="token punctuation">,</span> best_truth_idx <span class="token operator">=</span> overlaps<span class="token punctuation">.</span>max<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    best_prior_idx<span class="token punctuation">.</span>squeeze_<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 上面特意保留了维度(keepdim=True), 这里又都把维度 squeeze/reduce 了, 实际上只需用默认的 keepdim=False 就可以自动 squeeze/reduce 维度.</span>    best_prior_overlap<span class="token punctuation">.</span>squeeze_<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>    best_truth_idx<span class="token punctuation">.</span>squeeze_<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>    best_truth_overlap<span class="token punctuation">.</span>squeeze_<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>    best_truth_overlap<span class="token punctuation">.</span>index_fill_<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> best_prior_idx<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 维度压缩后变为[num_priors], best_prior_idx 维度为[num_objs],</span>    <span class="token comment" spellcheck="true"># 该语句会将与gt box匹配度最好的prior box 的交并比置为 2, 确保其最大, 以免防止某些 gtbox 没有匹配的 priorbox.</span>    <span class="token comment" spellcheck="true"># 假想一种极端情况, 所有的priorbox与某个gtbox(标记为G)的交并比为1, 而其他gtbox分别有一个交并比</span>    <span class="token comment" spellcheck="true"># 最高的priorbox, 但是肯定小于1(因为其他的gtbox与G的交并比肯定小于1), 这样一来, 就会使得所有</span>    <span class="token comment" spellcheck="true"># 的priorbox都与G匹配, 为了防止这种情况, 我们将那些对gtbox来说, 具有最高交并比的priorbox,</span>    <span class="token comment" spellcheck="true"># 强制进行互相匹配, 即令best_truth_idx[best_prior_idx[j]] = j, 详细见下面的for循环</span>    <span class="token comment" spellcheck="true"># 注意!!: 因为 gt box 的数量要远远少于 prior box 的数量, 因此, 同一个 gt box 会与多个 prior box 匹配.</span>    <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span>best_prior_idx<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment" spellcheck="true"># range:0~num_obj-1</span>        best_truth_idx<span class="token punctuation">[</span>best_prior_idx<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> j        <span class="token comment" spellcheck="true"># best_prior_idx[j] 代表与box_a的第j个box交并比最高的 prior box 的下标, 将与该 gtbox</span>        <span class="token comment" spellcheck="true"># 匹配度最好的 prior box 的下标改为j, 由此,完成了该 gtbox 与第j个 prior box 的匹配.</span>        <span class="token comment" spellcheck="true"># 这里的循环只会进行num_obj次, 剩余的匹配为 best_truth_idx 中原本的值.</span>        <span class="token comment" spellcheck="true"># 这里处理的情况是, priorbox中第i个box与gtbox中第k个box的交并比最高,</span>        <span class="token comment" spellcheck="true"># 即 best_truth_idx[i]= k</span>        <span class="token comment" spellcheck="true"># 但是对于best_prior_idx[k]来说, 它却与priorbox的第l个box有着最高的交并比,</span>        <span class="token comment" spellcheck="true"># 即best_prior_idx[k]=l</span>        <span class="token comment" spellcheck="true"># 而对于gtbox的另一个边框gtbox[j]来说, 它与priorbox[i]的交并比最大,</span>        <span class="token comment" spellcheck="true"># 即但是对于best_prior_idx[j] = i.</span>        <span class="token comment" spellcheck="true"># 那么, 此时, 我们就应该将best_truth_idx[i]= k 修改成 best_truth_idx[i]= j.</span>        <span class="token comment" spellcheck="true"># 即令 priorbox[i] 与 gtbox[j]对应.</span>        <span class="token comment" spellcheck="true"># 这样做的原因: 防止某个gtbox没有匹配的 prior box.</span>    mathes <span class="token operator">=</span> truths<span class="token punctuation">[</span>best_truth_idx<span class="token punctuation">]</span>    <span class="token comment" spellcheck="true"># truths 的shape 为[num_objs, 4], 而best_truth_idx是一个指示下标的列表, 列表长度为 8732,</span>    <span class="token comment" spellcheck="true"># 列表中的下标范围为0~num_objs-1, 代表的是与每个priorbox匹配的gtbox的下标</span>    <span class="token comment" spellcheck="true"># 上面的表达式会返回一个shape为 [num_priors, 4], 即 [8732, 4] 的tensor, 代表的就是与每个priorbox匹配的gtbox的坐标值.</span>    conf <span class="token operator">=</span> labels<span class="token punctuation">[</span>best_truth_idx<span class="token punctuation">]</span><span class="token operator">+</span><span class="token number">1</span> <span class="token comment" spellcheck="true"># 与上面的语句道理差不多, 这里得到的是每个prior box匹配的类别编号, shape 为[8732]</span>    conf<span class="token punctuation">[</span>best_truth_overlap <span class="token operator">&lt;</span> threshold<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span> <span class="token comment" spellcheck="true"># 将与gtbox的交并比小于阈值的置为0 , 即认为是非物体框</span>    loc <span class="token operator">=</span> encode<span class="token punctuation">(</span>matches<span class="token punctuation">,</span> priors<span class="token punctuation">,</span> variances<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 返回编码后的中心坐标和宽高.</span>    loc_t<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">=</span> loc <span class="token comment" spellcheck="true"># 设置第idx张图片的gt编码坐标信息</span>    conf_t<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">=</span> conf <span class="token comment" spellcheck="true"># 设置第idx张图片的编号信息.(大于0即为物体编号, 认为有物体, 小于0认为是背景)</span></code></pre><p><strong>代码流程为</strong>:</p><ol><li>计算出每一个ground truth与每一个default boxes的jaccard overlap;</li><li>挑出与每一个ground truth最匹配(重复度最高)的default boxes;</li><li>挑出与每一个default boxes最匹配的ground truth;</li><li>注意,最终的匹配结果要保证在每一个ground truth都有与之匹配的default boxes的基础上,可以存在多个default boxes匹配同一个ground truth,这就是<pre><code>for j in range(best_prior_idx.size(0)):   best_truth_idx[best_prior_idx[j]] = j</code></pre> 这一for循环完成的功能.</li><li>将重复率低于阈值的标记为背景目标.</li></ol><h4 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h4><p>模型的整体损失函数如下:</p><center><br>$L ( x , c , l , g ) = \frac { 1 } { N } \left( L _ { c o n f } ( x , c ) + \alpha L _ { l o c } ( x , l , g ) \right)$<br></center><p>其中N表示匹配的default boxes的数目,其中定位误差的计算方式如下:</p><center><br>$L _ { l o c } ( x , l , g ) = \sum _ { i \in P o s } ^ { N } \sum _ { m \in { c x , c y , w , h } } x _ { i j } ^ { k } \operatorname { smooth } _ { \mathrm { LI } } \left( l _ { i } ^ { m } - \hat { g } _ { j } ^ { m } \right)$<br><br>$\hat { g } _ { j } ^ { c x } = \left( g _ { j } ^ { c x } - d _ { i } ^ { c x } \right) / d _ { i } ^ { w } \quad \hat { g } _ { j } ^ { c y } = \left( g _ { j } ^ { c y } - d _ { i } ^ { c y } \right) / d _ { i } ^ { h }$<br><br>$\hat { g } _ { j } ^ { w } = \log \left( \frac { g _ { j } ^ { w } } { d _ { i } ^ { w } } \right) \quad \hat { g } _ { j } ^ { h } = \log \left( \frac { g _ { j } ^ { h } } { d _ { i } ^ { h } } \right)$<br></center><p>与Faster R-CNN类似,预测相对于default boxes的中心坐标的偏差,以及其宽和高.其中$x_ij^p$表示,将第i个default boxes与类别p的第j个ground truth进行匹配,这里,要将ground truth转换为相对于default boxes的偏移量.<br>置信度损失如下:</p><center><br>$L _ { c o n f } ( x , c ) = - \sum _ { i \in P o s } ^ { N } x _ { i j } ^ { p } \log \left( \hat { c } _ { i } ^ { p } \right) - \sum _ { i \in N e g } \log \left( \hat { c } _ { i } ^ { 0 } \right) \quad  where  \quad \hat { c } _ { i } ^ { p } = \frac { \exp \left( c _ { i } ^ { p } \right) } { \sum _ { p } \exp \left( c _ { i } ^ { p } \right) }$<br></center><p>其中$\alpha$设置为1.<br>代码如下:</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># layers/modules/multibox_loss.py</span><span class="token keyword">class</span> <span class="token class-name">MultiBoxLoss</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># 计算目标:</span>    <span class="token comment" spellcheck="true"># 输出那些与真实框的iou大于一定阈值的框的下标.</span>    <span class="token comment" spellcheck="true"># 根据与真实框的偏移量输出localization目标</span>    <span class="token comment" spellcheck="true"># 用难样例挖掘算法去除大量负样本(默认正负样本比例为1:3)</span>    <span class="token comment" spellcheck="true"># 目标损失:</span>    <span class="token comment" spellcheck="true"># L(x,c,l,g) = (Lconf(x,c) + αLloc(x,l,g)) / N</span>    <span class="token comment" spellcheck="true"># 参数:</span>    <span class="token comment" spellcheck="true"># c: 类别置信度(class confidences)</span>    <span class="token comment" spellcheck="true"># l: 预测的框(predicted boxes)</span>    <span class="token comment" spellcheck="true"># g: 真实框(ground truth boxes)</span>    <span class="token comment" spellcheck="true"># N: 匹配到的框的数量(number of matched default boxes)</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_classes<span class="token punctuation">,</span> overlap_thresh<span class="token punctuation">,</span> prior_for_matching<span class="token punctuation">,</span> bkg_label<span class="token punctuation">,</span> neg_mining<span class="token punctuation">,</span> neg_pos<span class="token punctuation">,</span> neg_overlap<span class="token punctuation">,</span> encode_target<span class="token punctuation">,</span> use_gpu<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>MultiBoxLoss<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>use_gpu <span class="token operator">=</span> use_gpu        self<span class="token punctuation">.</span>num_classes<span class="token operator">=</span> num_classes <span class="token comment" spellcheck="true"># 列表数</span>        self<span class="token punctuation">.</span>threshold <span class="token operator">=</span> overlap_thresh <span class="token comment" spellcheck="true"># 交并比阈值, 0.5</span>        self<span class="token punctuation">.</span>background_label <span class="token operator">=</span> bkg_label <span class="token comment" spellcheck="true"># 背景标签, 0</span>        self<span class="token punctuation">.</span>use_prior_for_matching <span class="token operator">=</span> prior_for_matching <span class="token comment" spellcheck="true"># True 没卵用</span>        self<span class="token punctuation">.</span>do_neg_mining <span class="token operator">=</span> neg_mining <span class="token comment" spellcheck="true"># True, 没卵用</span>        self<span class="token punctuation">.</span>negpos_ratio <span class="token operator">=</span> neg_pos <span class="token comment" spellcheck="true"># 负样本和正样本的比例, 3:1</span>        self<span class="token punctuation">.</span>neg_overlap <span class="token operator">=</span> neg_overlap <span class="token comment" spellcheck="true"># 0.5 判定负样本的阈值.</span>        self<span class="token punctuation">.</span>encode_target <span class="token operator">=</span> encode_target <span class="token comment" spellcheck="true"># False 没卵用</span>        self<span class="token punctuation">.</span>variance <span class="token operator">=</span> cfg<span class="token punctuation">[</span><span class="token string">"variance"</span><span class="token punctuation">]</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> predictions<span class="token punctuation">,</span> targets<span class="token punctuation">)</span><span class="token punctuation">:</span>        loc_data<span class="token punctuation">,</span> conf_data<span class="token punctuation">,</span> priors <span class="token operator">=</span> predictions        <span class="token comment" spellcheck="true"># loc_data: [batch_size, 8732, 4]</span>        <span class="token comment" spellcheck="true"># conf_data: [batch_size, 8732, 21]</span>        <span class="token comment" spellcheck="true"># priors: [8732, 4] default box 对于任意的图片, 都是相同的, 因此无需带有 batch 维度</span>        num <span class="token operator">=</span> loc_data<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># num = batch_size</span>        priors <span class="token operator">=</span> priors<span class="token punctuation">[</span><span class="token punctuation">:</span>loc_data<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token comment" spellcheck="true"># loc_data.size(1) = 8732, 因此 priors 维持不变</span>        num_priors <span class="token operator">=</span> <span class="token punctuation">(</span>priors<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># num_priors = 8732</span>        num_classes <span class="token operator">=</span> self<span class="token punctuation">.</span>num_classes <span class="token comment" spellcheck="true"># num_classes = 21 (默认为voc数据集)</span>        <span class="token comment" spellcheck="true"># 将priors(default boxes)和ground truth boxes匹配</span>        loc_t <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span>num<span class="token punctuation">,</span> num_priors<span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># shape:[batch_size, 8732, 4]</span>        conf_t <span class="token operator">=</span> torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span>num<span class="token punctuation">,</span> num_priors<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># shape:[batch_size, 8732]</span>        <span class="token keyword">for</span> idx <span class="token keyword">in</span> range<span class="token punctuation">(</span>num<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token comment" spellcheck="true"># targets是列表, 列表的长度为batch_size, 列表中每个元素为一个 tensor,</span>            <span class="token comment" spellcheck="true"># 其 shape 为 [num_objs, 5], 其中 num_objs 为当前图片中物体的数量, 第二维前4个元素为边框坐标, 最后一个元素为类别编号(1~20)</span>            truths <span class="token operator">=</span> targets<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data <span class="token comment" spellcheck="true"># [num_objs, 4]</span>            labels <span class="token operator">=</span> targets<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data <span class="token comment" spellcheck="true"># [num_objs] 使用的是 -1, 而不是 -1:, 因此, 返回的维度变少了</span>            defaults <span class="token operator">=</span> priors<span class="token punctuation">.</span>data <span class="token comment" spellcheck="true"># [8732, 4]</span>            <span class="token comment" spellcheck="true"># from ..box_utils import match</span>            <span class="token comment" spellcheck="true"># 关键函数, 实现候选框与真实框之间的匹配, 注意是候选框而不是预测结果框! 这个函数实现较为复杂, 会在后面着重讲解</span>            match<span class="token punctuation">(</span>self<span class="token punctuation">.</span>threshold<span class="token punctuation">,</span> truths<span class="token punctuation">,</span> defaults<span class="token punctuation">,</span> self<span class="token punctuation">.</span>variance<span class="token punctuation">,</span> labels<span class="token punctuation">,</span> loc_t<span class="token punctuation">,</span> conf_t<span class="token punctuation">,</span> idx<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 注意! 要清楚 Python 中的参数传递机制, 此处在函数内部会改变 loc_t, conf_t 的值, 关于 match 的详细讲解可以看后面的代码解析</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>use_gpu<span class="token punctuation">:</span>            loc_t <span class="token operator">=</span> loc_t<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>            conf_t <span class="token operator">=</span> conf_t<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 用Variable封装loc_t, 新版本的 PyTorch 无需这么做, 只需要将 requires_grad 属性设置为 True 就行了</span>        loc_t <span class="token operator">=</span> Variable<span class="token punctuation">(</span>loc_t<span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>        conf_t <span class="token operator">=</span> Variable<span class="token punctuation">(</span>conf_t<span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>        pos <span class="token operator">=</span> conf_t <span class="token operator">></span> <span class="token number">0</span> <span class="token comment" spellcheck="true"># 筛选出 >0 的box下标(大部分都是=0的)</span>        num_pos <span class="token operator">=</span> pos<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 求和, 取得满足条件的box的数量, [batch_size, num_gt_threshold]</span>        <span class="token comment" spellcheck="true"># 位置(localization)损失函数, 使用 Smooth L1 函数求损失</span>        <span class="token comment" spellcheck="true"># loc_data:[batch, num_priors, 4]</span>        <span class="token comment" spellcheck="true"># pos: [batch, num_priors]</span>        <span class="token comment" spellcheck="true"># pos_idx: [batch, num_priors, 4], 复制下标成坐标格式, 以便获取坐标值</span>        pos_idx <span class="token operator">=</span> pos<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>pos<span class="token punctuation">.</span>dim<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>expand_as<span class="token punctuation">(</span>loc_data<span class="token punctuation">)</span>        loc_p <span class="token operator">=</span> loc_data<span class="token punctuation">[</span>pos_idx<span class="token punctuation">]</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 获取预测结果值</span>        loc_t <span class="token operator">=</span> loc_t<span class="token punctuation">[</span>pos_idx<span class="token punctuation">]</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 获取gt值</span>        loss_l <span class="token operator">=</span> F<span class="token punctuation">.</span>smooth_l1_loss<span class="token punctuation">(</span>loc_p<span class="token punctuation">,</span> loc_t<span class="token punctuation">,</span> size_average<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 计算损失</span>        <span class="token comment" spellcheck="true"># 计算最大的置信度, 以进行难负样本挖掘</span>        <span class="token comment" spellcheck="true"># conf_data: [batch, num_priors, num_classes]</span>        <span class="token comment" spellcheck="true"># batch_conf: [batch, num_priors, num_classes]</span>        batch_conf <span class="token operator">=</span> conf_data<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_classes<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># reshape</span>        <span class="token comment" spellcheck="true"># conf_t: [batch, num_priors]</span>        <span class="token comment" spellcheck="true"># loss_c: [batch*num_priors, 1], 计算每个priorbox预测后的损失</span>        loss_c <span class="token operator">=</span> log_sum_exp<span class="token punctuation">(</span>batch_conf<span class="token punctuation">)</span> <span class="token operator">-</span> batch_conf<span class="token punctuation">.</span>gather<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> conf_t<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 难负样本挖掘, 按照loss进行排序, 取loss最大的负样本参与更新</span>        loss_c<span class="token punctuation">[</span>pos<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span> <span class="token comment" spellcheck="true"># 将所有的pos下标的box的loss置为0(pos指示的是正样本的下标)</span>        <span class="token comment" spellcheck="true"># 将 loss_c 的shape 从 [batch*num_priors, 1] 转换成 [batch, num_priors]</span>        loss_c <span class="token operator">=</span> loss_c<span class="token punctuation">.</span>view<span class="token punctuation">(</span>num<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># reshape</span>        <span class="token comment" spellcheck="true"># 进行降序排序, 并获取到排序的下标</span>        _<span class="token punctuation">,</span> loss_idx <span class="token operator">=</span> loss_c<span class="token punctuation">.</span>sort<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> descending<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 将下标进行升序排序, 并获取到下标的下标</span>        _<span class="token punctuation">,</span> idx_rank <span class="token operator">=</span> loss_idx<span class="token punctuation">.</span>sort<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># num_pos: [batch, 1], 统计每个样本中的obj个数</span>        num_pos <span class="token operator">=</span> pos<span class="token punctuation">.</span>long<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 根据obj的个数, 确定负样本的个数(正样本的3倍)</span>        num_neg <span class="token operator">=</span> torch<span class="token punctuation">.</span>clamp<span class="token punctuation">(</span>self<span class="token punctuation">.</span>negpos_ratio<span class="token operator">*</span>num_pos<span class="token punctuation">,</span> max<span class="token operator">=</span>pos<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 获取到负样本的下标</span>        neg <span class="token operator">=</span> idx_rank <span class="token operator">&lt;</span> num_neg<span class="token punctuation">.</span>expand_as<span class="token punctuation">(</span>idx_rank<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 计算包括正样本和负样本的置信度损失</span>        <span class="token comment" spellcheck="true"># pos: [batch, num_priors]</span>        <span class="token comment" spellcheck="true"># pos_idx: [batch, num_priors, num_classes]</span>        pos_idx <span class="token operator">=</span> pos<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>expand_as<span class="token punctuation">(</span>conf_data<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># neg: [batch, num_priors]</span>        <span class="token comment" spellcheck="true"># neg_idx: [batch, num_priors, num_classes]</span>        neg_idx <span class="token operator">=</span> neg<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>expand_as<span class="token punctuation">(</span>conf_data<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 按照pos_idx和neg_idx指示的下标筛选参与计算损失的预测数据</span>        conf_p <span class="token operator">=</span> conf_data<span class="token punctuation">[</span><span class="token punctuation">(</span>pos_idx<span class="token operator">+</span>neg_idx<span class="token punctuation">)</span><span class="token punctuation">.</span>gt<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_classes<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 按照pos_idx和neg_idx筛选目标数据</span>        targets_weighted <span class="token operator">=</span> conf_t<span class="token punctuation">[</span><span class="token punctuation">(</span>pos<span class="token operator">+</span>neg<span class="token punctuation">)</span><span class="token punctuation">.</span>gt<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">]</span>        <span class="token comment" spellcheck="true"># 计算二者的交叉熵</span>        loss_c <span class="token operator">=</span> F<span class="token punctuation">.</span>cross_entropy<span class="token punctuation">(</span>conf_p<span class="token punctuation">,</span> targets_weighted<span class="token punctuation">,</span> size_average<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 将损失函数归一化后返回</span>        N <span class="token operator">=</span> num_pos<span class="token punctuation">.</span>data<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span>        loss_l <span class="token operator">=</span> loss_l <span class="token operator">/</span> N        loss_c <span class="token operator">=</span> loss_c <span class="token operator">/</span> N        <span class="token keyword">return</span> loss_l<span class="token punctuation">,</span> loss_c</code></pre><h4 id="确定default-boxes的尺度以及比率"><a href="#确定default-boxes的尺度以及比率" class="headerlink" title="确定default boxes的尺度以及比率"></a>确定default boxes的尺度以及比率</h4><p>实验表明使用低层的feature maps可以提高语义分割质量,因为底层的feature maps包含输入目标的细节信息.<br>来自于一个网络不同层的feature maps具有不同的感受野,在SSD网络中,default boxes不需要与每一层的真实的感受野严格匹配.作者将default boxes的大小设计为与特定尺度的目标相关联.假设在模型中使用了m层特征图.每一层特征图的default boxes的尺度计算如下:</p><center><br>$s _ { k } = s _ { \min } + \frac { s _ { \max } - s _ { \min } } { m - 1 } ( k - 1 ) , \quad k \in [ 1 , m ]$<br></center><p>其中$s_{min}$为$0.2$,$s_{max}$为$0.9$,分别代表最低、最高层的尺度.<br>对于,每一层中的default又引入了五种不同的比率,即:</p><center><br>${ 1,2,3 , \frac { 1 } { 2 } , \frac { 1 } { 3 }}$<br></center><p>依据比率，得出宽的计算公式为:</p><center><br>$w _ { k } ^ { a } = s _ { k } \sqrt { a _ { r } }$<br></center><p>高的计算公式为:</p><center><br>$h _ { k } ^ { a } = s _ { k } / \sqrt { a _ { r } }$<br></center><p>对于比率1,又额外定义了一个尺度,计算如下:</p><center><br>$s _ { k } ^ { \prime } = \sqrt { S _ { k } S _ { k + 1 } }$<br></center><p>这样,每一层特征图的每一个位置上便有六个不同比率的default boxes,将每一个位置上的6个default boxes的中心坐标设置为:</p><center><br>$\left( \frac { i + 0.5 } { \left| f _ { k } \right| } , \frac { j + 0.5 } { \left| f _ { k } \right| } \right)$<br></center><p>其中 $\left| f _ { k } \right|$表示第k个特征图的大小，$i , j \in \left[ 0 , \left| f _ { k } \right|\right.]$,对应特征图上所有可能的位置点.</p><p>实际中,不同的数据集适用于不同的尺度以及比例,若数据集中包含有更多的小目标,则需要设计更多的小尺度default boxes,相应的,若包含有更多的大目标,则需要设计更多的大尺度default boxes.<br>实现这一功能的代码如下:借鉴自:<a href="https://hellozhaozheng.github.io/z_post/PyTorch-SSD/#MultiBox," title="代码出处" target="_blank" rel="noopener">代码出处 </a></p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># `layers/functions/prior_box.py`</span><span class="token keyword">class</span> <span class="token class-name">PriorBox</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># 所谓priorbox实际上就是网格中每一个cell推荐的box</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> cfg<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 在SSD的init中, cfg=(coco, voc)[num_classes=21]</span>        <span class="token comment" spellcheck="true"># coco, voc的相关配置都来自于data/cfg.py 文件</span>        super<span class="token punctuation">(</span>PriorBox<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>image_size <span class="token operator">=</span> cfg<span class="token punctuation">[</span><span class="token string">"min_dim"</span><span class="token punctuation">]</span>        self<span class="token punctuation">.</span>num_priors <span class="token operator">=</span> len<span class="token punctuation">(</span>cfg<span class="token punctuation">[</span><span class="token string">"aspect_ratios"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>variance <span class="token operator">=</span> cfg<span class="token punctuation">[</span><span class="token string">"variance"</span><span class="token punctuation">]</span> <span class="token operator">or</span> <span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">]</span>        self<span class="token punctuation">.</span>min_sizes <span class="token operator">=</span> cfg<span class="token punctuation">[</span><span class="token string">"min_sizes"</span><span class="token punctuation">]</span>        self<span class="token punctuation">.</span>max_sizes <span class="token operator">=</span> cfg<span class="token punctuation">[</span><span class="token string">"max_sizes"</span><span class="token punctuation">]</span>        self<span class="token punctuation">.</span>steps <span class="token operator">=</span> cfg<span class="token punctuation">[</span><span class="token string">"steps"</span><span class="token punctuation">]</span>        self<span class="token punctuation">.</span>aspect_ratios <span class="token operator">=</span> cfg<span class="token punctuation">[</span><span class="token string">"aspect_ratios"</span><span class="token punctuation">]</span>        self<span class="token punctuation">.</span>clip <span class="token operator">=</span> cfg<span class="token punctuation">[</span><span class="token string">"clip"</span><span class="token punctuation">]</span>        self<span class="token punctuation">.</span>version <span class="token operator">=</span> cfg<span class="token punctuation">[</span><span class="token string">"name"</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> v <span class="token keyword">in</span> self<span class="token punctuation">.</span>variance<span class="token punctuation">:</span>            <span class="token keyword">if</span> v <span class="token operator">&lt;=</span> <span class="token number">0</span><span class="token punctuation">:</span>                <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">"Variances must be greater than 0"</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        mean <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> k<span class="token punctuation">,</span> f <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>self<span class="token punctuation">.</span>feature_maps<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment" spellcheck="true"># 存放的是feature map的尺寸:38,19,10,5,3,1</span>            <span class="token comment" spellcheck="true"># from itertools import product as product</span>            <span class="token keyword">for</span> i<span class="token punctuation">,</span> j <span class="token keyword">in</span> product<span class="token punctuation">(</span>range<span class="token punctuation">(</span>f<span class="token punctuation">)</span><span class="token punctuation">,</span> repeat<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                <span class="token comment" spellcheck="true"># 这里实际上可以用最普通的for循环嵌套来代替, 主要目的是产生anchor的坐标(i,j)</span>                f_k <span class="token operator">=</span> self<span class="token punctuation">.</span>image_size <span class="token operator">/</span> self<span class="token punctuation">.</span>steps<span class="token punctuation">[</span>k<span class="token punctuation">]</span> <span class="token comment" spellcheck="true"># steps=[8,16,32,64,100,300]. f_k大约为feature map的尺寸</span>                <span class="token comment" spellcheck="true"># 求得center的坐标, 浮点类型. 实际上, 这里也可以直接使用整数类型的 `f`, 计算上没太大差别</span>                cx <span class="token operator">=</span> <span class="token punctuation">(</span>j <span class="token operator">+</span> <span class="token number">0.5</span><span class="token punctuation">)</span> <span class="token operator">/</span> f_k                cy <span class="token operator">=</span> <span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">0.5</span><span class="token punctuation">)</span> <span class="token operator">/</span> f_k <span class="token comment" spellcheck="true"># 这里一定要特别注意 i,j 和cx, cy的对应关系, 因为cy对应的是行, 所以应该零cy与i对应.</span>                <span class="token comment" spellcheck="true"># aspect_ratios 为1时对应的box</span>                s_k <span class="token operator">=</span> self<span class="token punctuation">.</span>min_sizes<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token operator">/</span>self<span class="token punctuation">.</span>image_size                mean <span class="token operator">+=</span> <span class="token punctuation">[</span>cx<span class="token punctuation">,</span> cy<span class="token punctuation">,</span> s_k<span class="token punctuation">,</span> s_k<span class="token punctuation">]</span>                <span class="token comment" spellcheck="true"># 根据原文, 当 aspect_ratios 为1时, 会有一个额外的 box, 如下:</span>                <span class="token comment" spellcheck="true"># rel size: sqrt(s_k * s_(k+1))</span>                s_k_prime <span class="token operator">=</span> sqrt<span class="token punctuation">(</span>s_k <span class="token operator">*</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>max_sizes<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token operator">/</span>self<span class="token punctuation">.</span>image_size<span class="token punctuation">)</span><span class="token punctuation">)</span>                mean <span class="token operator">+=</span> <span class="token punctuation">[</span>cx<span class="token punctuation">,</span> cy<span class="token punctuation">,</span> s_k_prime<span class="token punctuation">,</span> s_k_prime<span class="token punctuation">]</span>                <span class="token comment" spellcheck="true"># 其余(2, 或 2,3)的宽高比(aspect ratio)</span>                <span class="token keyword">for</span> ar <span class="token keyword">in</span> self<span class="token punctuation">.</span>aspect_ratios<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">:</span>                    mean <span class="token operator">+=</span> <span class="token punctuation">[</span>cx<span class="token punctuation">,</span> cy<span class="token punctuation">,</span> s_k<span class="token operator">*</span>sqrt<span class="token punctuation">(</span>ar<span class="token punctuation">)</span><span class="token punctuation">,</span> s_k<span class="token operator">/</span>sqrt<span class="token punctuation">(</span>ar<span class="token punctuation">)</span><span class="token punctuation">]</span>                    mean <span class="token operator">+=</span> <span class="token punctuation">[</span>cx<span class="token punctuation">,</span> cy<span class="token punctuation">,</span> s_k<span class="token operator">/</span>sqrt<span class="token punctuation">(</span>ar<span class="token punctuation">)</span><span class="token punctuation">,</span> s_k<span class="token operator">*</span>sqrt<span class="token punctuation">(</span>ar<span class="token punctuation">)</span><span class="token punctuation">]</span>                <span class="token comment" spellcheck="true"># 综上, 每个卷积特征图谱上每个像素点最终产生的 box 数量要么为4, 要么为6, 根据不同情况可自行修改.</span>        output <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span>mean<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>clip<span class="token punctuation">:</span>            output<span class="token punctuation">.</span>clamp_<span class="token punctuation">(</span>max<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> min<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># clamp_ 是clamp的原地执行版本</span>        <span class="token keyword">return</span> output <span class="token comment" spellcheck="true"># 输出default box坐标(可以理解为anchor box)</span></code></pre><h4 id="Hard-negative-mining"><a href="#Hard-negative-mining" class="headerlink" title="Hard negative mining"></a>Hard negative mining</h4><p>这一策略主要用于解决正负样本数目不均衡的问题,在进行边框匹配之后,大多数的default boxes都是负样本.这一结果会导致样本不平衡.因而在训练时,没有使用所有的负样本,而是首先依据每一个default box的置信度损失进行排序,选出最高的几个,使得正负样本的比例为1:3.使用选出的样本进行训练.</p><h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><table><thead><tr><th>模型</th><th>mAP</th><th>FPS</th></tr></thead><tbody><tr><td>SSD 300</td><td>74.3%</td><td>59</td></tr><tr><td>SSD 512</td><td>76.9%</td><td>-</td></tr><tr><td>Faster R-CNN</td><td>73.2%</td><td>7</td></tr><tr><td>YOLOV1</td><td>63.4%</td><td>45</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
          <category> 目标检测 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 目标检测 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ResNet论文解读</title>
      <link href="/2019/04/30/resnet-lun-wen-jie-du/"/>
      <url>/2019/04/30/resnet-lun-wen-jie-du/</url>
      
        <content type="html"><![CDATA[<h2 id="Deep-Residual-Learning-for-Image-Recogition"><a href="#Deep-Residual-Learning-for-Image-Recogition" class="headerlink" title="Deep Residual Learning for Image Recogition"></a>Deep Residual Learning for Image Recogition</h2><hr><h2 id="作者"><a href="#作者" class="headerlink" title="作者"></a>作者</h2><p><strong>Kaiming He</strong>    Xiangyu Zhang       Shaoqing Ren    Jian Sun</p><p><strong>何凯明大佬</strong></p><center><br><br><img src="http://kaiminghe.com/img/me.jpg" alt=""><br><br></center><h2 id="内容"><a href="#内容" class="headerlink" title="内容"></a>内容</h2><p>这篇论文主要用于解决网络层数加深时,模型的训练问题.</p><h3 id="深度网络的退化问题"><a href="#深度网络的退化问题" class="headerlink" title="深度网络的退化问题"></a>深度网络的退化问题</h3><p>如下图所示,为历年ISLVRC竞赛中取得冠军的各个网络结构,观察该图片可知,随着网络层数的增加,模型的复杂度不断提升,进而可以提取更为丰富的特征,因而也得到了更好的结果.</p><center><br><img src="/2019/04/30/resnet-lun-wen-jie-du/ISLVRC冠军结构.jpg" title="ISLVRC冠军结构"><br></center><p>但事实上,模型的表达能力和模型复杂度并不是成正比关系的,在论文中,作者指出,随着深度的增加,模型出现了退化问题(Degradation problem),如下图所示.</p><center><br><br><img src="/2019/04/30/resnet-lun-wen-jie-du/模型退化问题.jpg" title="模型退化问题"><br><br></center><p>网络深度增加时，网络准确度出现饱和，甚至出现下降.这一问题并不是由过拟合所导致的,因为在图中,56层网络的训练误差同样很大.</p><p>在深层网络存在着梯度消失或者爆炸的问题，这使得深度学习模型很难训练。但是现在已经存在一些技术手段,如BatchNorm来缓解这个问题。因此，出现深度网络的退化问题是非常令人诧异的。</p><h3 id="残差学习"><a href="#残差学习" class="headerlink" title="残差学习"></a>残差学习</h3><p>深度网络的退化问题至少说明深度网络不容易训练。但是我们考虑这样一个事实：现在你有一个浅层网络，你想通过向上堆积新层来建立深层网络，一个极端情况是这些增加的层什么也不学习，仅仅复制浅层网络的特征，即这样新层是恒等映射（Identity mapping）。在这种情况下，深层网络应该至少和浅层网络性能一样，不应该出现退化现象。</p><p>为了解决这一问题,在本文中作者提出了残差学习的思想.对于一个堆积层结构（几层堆积而成）当输入为$x$时其学习到的特征记为$H(x)$，现在我们希望其可以学习到残差$F(x)=H(x)-x$，这样其实原始的学习特征是$F(x)+x$。之所以这样是因为残差学习相比原始特征直接学习更容易。当残差为0时，此时堆积层仅仅做了恒等映射，至少网络性能不会下降，实际上残差不会为0，这也会使得堆积层在输入特征基础上学习到新的特征，从而拥有更好的性能。残差学习的结构如下图所示。这有点类似与电路中的“短路”，所以是一种短路连接（shortcut connection）。</p><center><br><br><img src="/2019/04/30/resnet-lun-wen-jie-du/残差模块.jpg" title="残差模块"><br><br></center><p>从数学角度解释残差学习更为容易的原因.</p><p>将残差单元表示为:</p><center><br><br>$y_l=h(x_l)+F(x_l, W_l)$<br><br>$x_{l+1}=f(y_l)$<br><br></center><p>其中,$h(x_l)$表示恒等映射,$F(x_l, W_l)$表示残差映射,$f$为ReLU激活函数,那么从浅层$l$到深层$L$的特征为:</p><center><br><br>$x_L=x_l+\sum_{i=l}^{L-1}F(x_i, W_i)$<br><br></center><p>使用链式求导法则可以得到损失相对于第$x_l$层的梯度为:</p><center><br><br>$\frac{\partial loss}{\partial x_l} = \frac{\partial loss}{partial x_L} \cdot \frac{\partial x_L}{\partial x_l} =  \frac{\partial loss}{\partial x_L} \cdot (1 + \frac{\partial}{\partial x_l} \sum_{i=l}^{L-1}F(x_i, W_i))$<br><br></center><p>由上式我们可以发现,小括号中的1表明短路机制可以无损地传播梯度，而另外一项残差梯度则需要经过带有weights的层，梯度不是直接传递过来的。残差梯度不会那么巧全为-1，而且就算其比较小，有1的存在也不会导致梯度消失。所以残差学习会更容易(上面的推导并不是严格的证明)。</p><h3 id="ResNet的网络结构"><a href="#ResNet的网络结构" class="headerlink" title="ResNet的网络结构"></a>ResNet的网络结构</h3><p>ResNet网络是参考了VGG19网络，在其基础上进行了修改，并通过短路机制加入了残差单元，如图所示。变化主要体现在ResNet直接使用stride=2的卷积做下采样，并且用global average pool层替换了全连接层。ResNet的一个重要设计原则是：<strong>当feature map大小降低一半时，feature map的数量增加一倍</strong>，这保持了网络层的复杂度。从图中可以看到，ResNet相比普通网络每两层间增加了短路机制，这就形成了残差学习，其中虚线表示feature map数量发生了改变。图中展示的34-layer的ResNet，还可以构建更深的网络如表所示。从表中可以看到，对于18-layer和34-layer的ResNet，其进行的两层间的残差学习，当网络更深时，其进行的是三层间的残差学习，三层卷积核分别是1x1，3x3和1x1，一个值得注意的是隐含层的feature map数量是比较小的，并且是输出feature map数量的1/4。</p><center><br><img src="/2019/04/30/resnet-lun-wen-jie-du/resnet结构.jpg" title="resnet结构"><br>ResNet网络结构<br><br></center><center><br><img src="/2019/04/30/resnet-lun-wen-jie-du/不同的resnet结构.jpg" title="不同的resnet结构"><br>不同的ResNet网络结构<br><br></center><h4 id="残差单元"><a href="#残差单元" class="headerlink" title="残差单元"></a>残差单元</h4><p>ResNet使用两种残差单元，如图所示。左图对应的是浅层网络，而右图对应的是深层网络。对于短路连接，当输入和输出维度一致时，可以直接将输入加到输出上。但是当维度不一致时（对应的是维度增加一倍），这就不能直接相加。有两种策略：（1）采用zero-padding增加维度，此时一般要先做一个downsample，可以采用strde=2的pooling，这样不会增加参数；（2）采用新的映射（projection shortcut），一般采用1x1的卷积(可以改变维度)，这样会增加参数，也会增加计算量。短路连接除了直接使用恒等映射，当然都可以采用projection shortcut。</p><center><br><img src="/2019/04/30/resnet-lun-wen-jie-du/残差单元.jpg" title="残差单元"><br>残差单元示意图(左侧为浅层网络使用的残差单元,右侧为深层网络)<br><br></center><h2 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h2><p>如图所示,左侧为不使用残差模块的普通深度网络,右侧为ResNet.</p><center><br><img src="/2019/04/30/resnet-lun-wen-jie-du/结果对比.jpg" title="结果对比"><br>结果示意图<br><br></center><p>从图中我们可以看出,在左侧,未使用残差模块的网络明显出现了退化现象,而右侧则无此问题.</p><h2 id="一种更为优秀的残差模块"><a href="#一种更为优秀的残差模块" class="headerlink" title="一种更为优秀的残差模块"></a>一种更为优秀的残差模块</h2><p>采用前置激活可以提升残差模块的性能,如图所示:</p><center><br><img src="/2019/04/30/resnet-lun-wen-jie-du/残差模块改进.jpg" title="残差模块改进"><br><br></center>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
          <category> 经典网络结构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 论文阅读 </tag>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2019/01/27/hello-world/"/>
      <url>/2019/01/27/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre class=" language-bash"><code class="language-bash">$ hexo new <span class="token string">"My New Post"</span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre class=" language-bash"><code class="language-bash">$ hexo server</code></pre><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre class=" language-bash"><code class="language-bash">$ hexo generate</code></pre><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre class=" language-bash"><code class="language-bash">$ hexo deploy</code></pre><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
